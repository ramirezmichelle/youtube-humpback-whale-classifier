/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
2022-07-13 16:53:31.371620: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with "NOT_FOUND: Could not locate the credentials file.". Retrieving token from GCE failed with "FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata".
WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your
local data directory. If you'd instead prefer to read directly from our public
GCS bucket (recommended if you're running on GCP), you can instead pass
`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.
Dl Completed...:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  6.33 file/s]
[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...
Dl Completed...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  8.30 file/s]
2022-07-13 16:53:33.127562: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-07-13 16:53:37.682950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14649 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:06:00.0, compute capability: 7.0
2022-07-13 16:53:37.684652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14649 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:07:00.0, compute capability: 7.0
2022-07-13 16:53:37.686075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14649 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:0a:00.0, compute capability: 7.0
2022-07-13 16:53:37.687447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14649 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:0b:00.0, compute capability: 7.0
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')
Number of devices: 4
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
Epoch 1/12
2022-07-13 16:55:06.278580: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:547] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
2022-07-13 16:55:14.500839: I tensorflow/stream_executor/cuda/cuda_dnn.cc:379] Loaded cuDNN version 8400
2022-07-13 16:55:15.495239: I tensorflow/stream_executor/cuda/cuda_dnn.cc:379] Loaded cuDNN version 8400
2022-07-13 16:55:16.550833: I tensorflow/stream_executor/cuda/cuda_dnn.cc:379] Loaded cuDNN version 8400
2022-07-13 16:55:17.438950: I tensorflow/stream_executor/cuda/cuda_dnn.cc:379] Loaded cuDNN version 8400
233/235 [============================>.] - ETA: 0s - loss: 0.3388 - accuracy: 0.9067
Learning rate for epoch 1 is 0.0010000000474974513
235/235 [==============================] - 15s 8ms/step - loss: 0.3377 - accuracy: 0.9070 - lr: 0.0010
Epoch 2/12
235/235 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.9712
Learning rate for epoch 2 is 0.0010000000474974513
235/235 [==============================] - 2s 6ms/step - loss: 0.1017 - accuracy: 0.9712 - lr: 0.0010
Epoch 3/12
234/235 [============================>.] - ETA: 0s - loss: 0.0684 - accuracy: 0.9803
Learning rate for epoch 3 is 0.0010000000474974513
235/235 [==============================] - 2s 6ms/step - loss: 0.0683 - accuracy: 0.9803 - lr: 0.0010
Epoch 4/12
233/235 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9871
Learning rate for epoch 4 is 9.999999747378752e-05
235/235 [==============================] - 2s 7ms/step - loss: 0.0477 - accuracy: 0.9872 - lr: 1.0000e-04
Epoch 5/12
230/235 [============================>.] - ETA: 0s - loss: 0.0448 - accuracy: 0.9878
Learning rate for epoch 5 is 9.999999747378752e-05
235/235 [==============================] - 2s 6ms/step - loss: 0.0450 - accuracy: 0.9877 - lr: 1.0000e-04
Epoch 6/12
233/235 [============================>.] - ETA: 0s - loss: 0.0432 - accuracy: 0.9882
Learning rate for epoch 6 is 9.999999747378752e-05
235/235 [==============================] - 2s 7ms/step - loss: 0.0433 - accuracy: 0.9882 - lr: 1.0000e-04
Epoch 7/12
227/235 [===========================>..] - ETA: 0s - loss: 0.0420 - accuracy: 0.9886
Learning rate for epoch 7 is 9.999999747378752e-05
235/235 [==============================] - 2s 7ms/step - loss: 0.0418 - accuracy: 0.9886 - lr: 1.0000e-04
Epoch 8/12
232/235 [============================>.] - ETA: 0s - loss: 0.0398 - accuracy: 0.9895
Learning rate for epoch 8 is 9.999999747378752e-06
235/235 [==============================] - 2s 7ms/step - loss: 0.0397 - accuracy: 0.9895 - lr: 1.0000e-05
Epoch 9/12
233/235 [============================>.] - ETA: 0s - loss: 0.0394 - accuracy: 0.9897
Learning rate for epoch 9 is 9.999999747378752e-06
235/235 [==============================] - 2s 6ms/step - loss: 0.0394 - accuracy: 0.9897 - lr: 1.0000e-05
Epoch 10/12
235/235 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9898
Learning rate for epoch 10 is 9.999999747378752e-06
235/235 [==============================] - 2s 7ms/step - loss: 0.0392 - accuracy: 0.9898 - lr: 1.0000e-05
Epoch 11/12
229/235 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9898
Learning rate for epoch 11 is 9.999999747378752e-06
235/235 [==============================] - 2s 7ms/step - loss: 0.0391 - accuracy: 0.9898 - lr: 1.0000e-05
Epoch 12/12
229/235 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 0.9897
Learning rate for epoch 12 is 9.999999747378752e-06
235/235 [==============================] - 2s 7ms/step - loss: 0.0389 - accuracy: 0.9898 - lr: 1.0000e-05
2022-07-13 16:57:07.137164: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:547] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.
40/40 [==============================] - 3s 9ms/step - loss: 0.0495 - accuracy: 0.9834
Eval loss: 0.049512457102537155, Eval accuracy: 0.9833999872207642
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 0s 0us/step
11501568/11490434 [==============================] - 0s 0us/step
Epoch 1/10

1563/1563 [==============================] - 6s 3ms/step - loss: 0.2280 - sparse_categorical_accuracy: 0.9311 - val_loss: 0.1347 - val_sparse_categorical_accuracy: 0.9583
Epoch 2/10


1563/1563 [==============================] - 5s 3ms/step - loss: 0.0951 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.0944 - val_sparse_categorical_accuracy: 0.9726
Epoch 3/10

1563/1563 [==============================] - 5s 3ms/step - loss: 0.0601 - sparse_categorical_accuracy: 0.9811 - val_loss: 0.1007 - val_sparse_categorical_accuracy: 0.9719
Epoch 4/10


1563/1563 [==============================] - 5s 3ms/step - loss: 0.0428 - sparse_categorical_accuracy: 0.9861 - val_loss: 0.0886 - val_sparse_categorical_accuracy: 0.9773
Epoch 5/10

1563/1563 [==============================] - 5s 3ms/step - loss: 0.0338 - sparse_categorical_accuracy: 0.9893 - val_loss: 0.0919 - val_sparse_categorical_accuracy: 0.9781
Epoch 6/10

1563/1563 [==============================] - 5s 3ms/step - loss: 0.0300 - sparse_categorical_accuracy: 0.9897 - val_loss: 0.1019 - val_sparse_categorical_accuracy: 0.9757
Epoch 7/10

1563/1563 [==============================] - 5s 3ms/step - loss: 0.0232 - sparse_categorical_accuracy: 0.9918 - val_loss: 0.1001 - val_sparse_categorical_accuracy: 0.9792
Epoch 8/10


1563/1563 [==============================] - 5s 3ms/step - loss: 0.0225 - sparse_categorical_accuracy: 0.9926 - val_loss: 0.1083 - val_sparse_categorical_accuracy: 0.9802
Epoch 9/10

1563/1563 [==============================] - 5s 3ms/step - loss: 0.0210 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.1205 - val_sparse_categorical_accuracy: 0.9757
Epoch 10/10

1563/1563 [==============================] - 5s 3ms/step - loss: 0.0176 - sparse_categorical_accuracy: 0.9942 - val_loss: 0.1223 - val_sparse_categorical_accuracy: 0.9768

313/313 [==============================] - 1s 2ms/step - loss: 0.1126 - sparse_categorical_accuracy: 0.9782
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Number of devices: 1
2022-07-13 17:03:06.167835: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:547] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.
Epoch 1/12
  1/938 [..............................] - ETA: 45:49 - loss: 2.3131 - accuracy: 0.1094WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_train_batch_end` time: 0.0040s). Check your callbacks.
 68/938 [=>............................] - ETA: 3s - loss: 0.8084 - accuracy: 0.7734

938/938 [==============================] - ETA: 0s - loss: 0.2143 - accuracy: 0.9370
Learning rate for epoch 1 is 0.0010000000474974513
938/938 [==============================] - 7s 4ms/step - loss: 0.2143 - accuracy: 0.9370 - lr: 0.0010
Epoch 2/12
933/938 [============================>.] - ETA: 0s - loss: 0.0692 - accuracy: 0.9796
Learning rate for epoch 2 is 0.0010000000474974513
938/938 [==============================] - 4s 4ms/step - loss: 0.0691 - accuracy: 0.9796 - lr: 0.0010
Epoch 3/12
586/938 [=================>............] - ETA: 1s - loss: 0.0491 - accuracy: 0.9849
127/938 [===>..........................] - ETA: 3s - loss: 0.0355 - accuracy: 0.9904
671/938 [====================>.........] - ETA: 1s - loss: 0.0269 - accuracy: 0.9929
201/938 [=====>........................] - ETA: 2s - loss: 0.0292 - accuracy: 0.9925
730/938 [======================>.......] - ETA: 0s - loss: 0.0240 - accuracy: 0.9939
285/938 [========>.....................] - ETA: 2s - loss: 0.0249 - accuracy: 0.9932
820/938 [=========================>....] - ETA: 0s - loss: 0.0211 - accuracy: 0.9948
438/938 [=============>................] - ETA: 1s - loss: 0.0222 - accuracy: 0.9944
926/938 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9953
496/938 [==============>...............] - ETA: 1s - loss: 0.0189 - accuracy: 0.9951
 56/938 [>.............................] - ETA: 3s - loss: 0.0215 - accuracy: 0.9944
582/938 [=================>............] - ETA: 1s - loss: 0.0176 - accuracy: 0.9957
  1/938 [..............................] - ETA: 39s - loss: 0.0442 - accuracy: 0.9844
554/938 [================>.............] - ETA: 1s - loss: 0.0179 - accuracy: 0.9957
115/938 [==>...........................] - ETA: 2s - loss: 0.0257 - accuracy: 0.9929
656/938 [===================>..........] - ETA: 1s - loss: 0.0173 - accuracy: 0.9959
210/938 [=====>........................] - ETA: 2s - loss: 0.0207 - accuracy: 0.9948
746/938 [======================>.......] - ETA: 0s - loss: 0.0167 - accuracy: 0.9961
938/938 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9964
938/938 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9964
938/938 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9964
 14/235 [>.............................] - ETA: 0s - loss: 0.1296 - accuracy: 0.9654
233/235 [============================>.] - ETA: 0s - loss: 0.0709 - accuracy: 0.9802
175/235 [=====================>........] - ETA: 0s - loss: 0.0477 - accuracy: 0.9867
  1/235 [..............................] - ETA: 10s - loss: 0.0483 - accuracy: 0.9844
223/235 [===========================>..] - ETA: 0s - loss: 0.0423 - accuracy: 0.9888
132/235 [===============>..............] - ETA: 0s - loss: 0.0430 - accuracy: 0.9885
 64/235 [=======>......................] - ETA: 0s - loss: 0.0437 - accuracy: 0.9885
231/235 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9889
231/235 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9889
ckpt_2.data-00000-of-00001   ckpt_8.index- ETA: 0s - loss: 0.0414 - accuracy: 0.9889
40/40 [==============================] - 2s 4ms/step - loss: 0.0531 - accuracy: 0.9819
40/40 [==============================] - 2s 4ms/step - loss: 0.0531 - accuracy: 0.9819
2022-07-13 17:06:42.729949: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:547] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.
40/40 [==============================] - 2s 4ms/step - loss: 0.0531 - accuracy: 0.9819
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
2022-07-13 17:19:14.194598: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorSliceDataset/_2"
op: "TensorSliceDataset"
input: "Placeholder/_0"
input: "Placeholder/_1"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_FLOAT
      type: DT_FLOAT
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 50000
  }
}
attr {
  key: "is_files"
  value {
    b: false
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\026TensorSliceDataset:522"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
        dim {
          size: 784
        }
      }
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
    }
  }
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
    }
  }
    return f(*args, **kwargs)args, kwargs, options=options)localhost/replica:0/task:0/device:GPU:0',)
    return f(*args, **kwargs)args, kwargs, options=options)localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Error reported to Coordinator: Input 0 of layer "sequential_5" is incompatible with the layer: expected shape=(None, 28, 28, 1), found shape=(None, 784)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/coordinator.py", line 293, in stop_on_exception
    yield
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py", line 342, in run
    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py", line 689, in wrapper
    return converted_call(f, args, kwargs, options=options)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py", line 377, in converted_call
    return _call_unconverted(f, args, kwargs, options)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py", line 458, in _call_unconverted
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/keras/engine/training.py", line 1000, in run_step
    outputs = model.train_step(data)
  File "/usr/local/lib/python3.8/dist-packages/keras/engine/training.py", line 859, in train_step
    y_pred = self(x, training=True)
  File "/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py", line 264, in assert_input_compatibility
    raise ValueError(f'Input {input_index} of layer "{layer_name}" is '

    raise ValueError(f'Input {input_index} of layer "{layer_name}" is 'plica:0/task:0/device:GPU:0',)
(60000, 28, 28)Error(f'Input {input_index} of layer "{layer_name}" is 'plica:0/task:0/device:GPU:0',)
(60000,)
(60000, 28, 28)Error(f'Input {input_index} of layer "{layer_name}" is 'plica:0/task:0/device:GPU:0',)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
(60000,)
(60000, 784)
(60000,)
(60000, 28, 28)Error(f'Input {input_index} of layer "{layer_name}" is 'plica:0/task:0/device:GPU:0',)
(60000, 784)low:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Number of devices: 1
(60000, 28, 28)
(60000,)
(60000, 784)low:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
(60000,)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Number of devices: 1
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Number of devices: 1
(60000, 28, 28)
(60000,)
(60000, 784)
(60000,)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Number of devices: 1
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
(60000, 28, 28)
(60000,)
(60000, 784)
(60000,)
<BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Number of devices: 1
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Number of devices: 1
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Number of devices: 1
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
(60000, 28, 28)
(60000,)
(60000, 784)
(60000,)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Number of devices: 1
(60000, 28, 28) <class 'numpy.ndarray'>
(60000,)
(60000, 784)
(60000,)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Number of devices: 1
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Number of devices: 1
2022-07-13 17:32:52.607112: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorSliceDataset/_2"
op: "TensorSliceDataset"
input: "Placeholder/_0"
input: "Placeholder/_1"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_FLOAT
      type: DT_FLOAT
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 50000
  }
}
attr {
  key: "is_files"
  value {
    b: false
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\026TensorSliceDataset:588"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
        dim {
          size: 784
        }
      }
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
    }
  }
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
    }
  }
}
Epoch 1/20
 84/196 [===========>..................] - ETA: 0s - loss: 0.5609 - sparse_categorical_accuracy: 0.8488
2022-07-13 17:32:56.733497: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorSliceDataset/_2"
op: "TensorSliceDataset"
input: "Placeholder/_0"
input: "Placeholder/_1"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_FLOAT
      type: DT_FLOAT
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 10000
  }
}
attr {
  key: "is_files"
  value {
    b: false
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\026TensorSliceDataset:590"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
        dim {
          size: 784
        }
      }
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
    }
  }
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
    }
  }

196/196 [==============================] - 5s 12ms/step - loss: 0.3733 - sparse_categorical_accuracy: 0.8969 - val_loss: 0.1611 - val_sparse_categorical_accuracy: 0.9550
Epoch 2/20
196/196 [==============================] - 1s 6ms/step - loss: 0.1432 - sparse_categorical_accuracy: 0.9579 - val_loss: 0.1135 - val_sparse_categorical_accuracy: 0.9656
Epoch 3/20
196/196 [==============================] - 1s 6ms/step - loss: 0.0932 - sparse_categorical_accuracy: 0.9728 - val_loss: 0.1015 - val_sparse_categorical_accuracy: 0.9690
Epoch 4/20
196/196 [==============================] - 1s 6ms/step - loss: 0.0675 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.0947 - val_sparse_categorical_accuracy: 0.9706
Epoch 5/20
196/196 [==============================] - 1s 6ms/step - loss: 0.0515 - sparse_categorical_accuracy: 0.9850 - val_loss: 0.0897 - val_sparse_categorical_accuracy: 0.9730
Epoch 6/20
196/196 [==============================] - 1s 5ms/step - loss: 0.0407 - sparse_categorical_accuracy: 0.9884 - val_loss: 0.0808 - val_sparse_categorical_accuracy: 0.9754
Epoch 7/20
196/196 [==============================] - 1s 6ms/step - loss: 0.0325 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0776 - val_sparse_categorical_accuracy: 0.9763
Epoch 8/20
196/196 [==============================] - 1s 6ms/step - loss: 0.0261 - sparse_categorical_accuracy: 0.9929 - val_loss: 0.0852 - val_sparse_categorical_accuracy: 0.9754
Epoch 9/20
196/196 [==============================] - 1s 6ms/step - loss: 0.0202 - sparse_categorical_accuracy: 0.9945 - val_loss: 0.0829 - val_sparse_categorical_accuracy: 0.9770
Epoch 10/20
196/196 [==============================] - 1s 5ms/step - loss: 0.0155 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.0857 - val_sparse_categorical_accuracy: 0.9771
Epoch 11/20
196/196 [==============================] - 1s 6ms/step - loss: 0.0127 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.0919 - val_sparse_categorical_accuracy: 0.9776
Epoch 12/20
196/196 [==============================] - 1s 5ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0936 - val_sparse_categorical_accuracy: 0.9765
Epoch 13/20
196/196 [==============================] - 1s 6ms/step - loss: 0.0085 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0950 - val_sparse_categorical_accuracy: 0.9769
Epoch 14/20
196/196 [==============================] - 1s 5ms/step - loss: 0.0120 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0884 - val_sparse_categorical_accuracy: 0.9780
Epoch 15/20
196/196 [==============================] - 1s 6ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.1110 - val_sparse_categorical_accuracy: 0.9733
Epoch 16/20
196/196 [==============================] - 1s 6ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.1079 - val_sparse_categorical_accuracy: 0.9757
Epoch 17/20
196/196 [==============================] - 1s 5ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.1285 - val_sparse_categorical_accuracy: 0.9720
Epoch 18/20
196/196 [==============================] - 1s 6ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.1047 - val_sparse_categorical_accuracy: 0.9763
Epoch 19/20
196/196 [==============================] - 1s 6ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.1284 - val_sparse_categorical_accuracy: 0.9730
Epoch 20/20
185/196 [===========================>..] - ETA: 0s - loss: 0.0070 - sparse_categorical_accuracy: 0.9975
2022-07-13 17:33:26.291308: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorSliceDataset/_2"
op: "TensorSliceDataset"
input: "Placeholder/_0"
input: "Placeholder/_1"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_FLOAT
      type: DT_FLOAT
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 10000
  }
}
attr {
  key: "is_files"
  value {
    b: false
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\026TensorSliceDataset:592"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
        dim {
          size: 784
        }
      }
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
    }
  }
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
    }
  }
196/196 [==============================] - 1s 6ms/step - loss: 0.0070 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.1054 - val_sparse_categorical_accuracy: 0.9777
40/40 [==============================] - 0s 3ms/step - loss: 0.1041 - sparse_categorical_accuracy: 0.9770
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Number of devices: 1
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Number of devices: 1
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')
Number of devices: 4
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')
Number of devices: 4
2022-07-13 17:47:44.029468: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorSliceDataset/_2"
op: "TensorSliceDataset"
input: "Placeholder/_0"
input: "Placeholder/_1"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_FLOAT
      type: DT_FLOAT
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 50000
  }
}
attr {
  key: "is_files"
  value {
    b: false
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\026TensorSliceDataset:990"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
        dim {
          size: 784
        }
      }
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
    }
  }
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
    }
  }
}
INFO:tensorflow:Error reported to Coordinator: Shapes (None, 1) and (None, 10) are incompatible
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/coordinator.py", line 293, in stop_on_exception
    yield
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py", line 342, in run
    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py", line 689, in wrapper
    return converted_call(f, args, kwargs, options=options)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py", line 377, in converted_call
    return _call_unconverted(f, args, kwargs, options)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py", line 458, in _call_unconverted
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/keras/engine/training.py", line 1000, in run_step
    outputs = model.train_step(data)
  File "/usr/local/lib/python3.8/dist-packages/keras/engine/training.py", line 860, in train_step
    loss = self.compute_loss(x, y, y_pred, sample_weight)
  File "/usr/local/lib/python3.8/dist-packages/keras/engine/training.py", line 918, in compute_loss
    return self.compiled_loss(
  File "/usr/local/lib/python3.8/dist-packages/keras/engine/compile_utils.py", line 201, in __call__
    loss_value = loss_obj(y_t, y_p, sample_weight=sw)
  File "/usr/local/lib/python3.8/dist-packages/keras/losses.py", line 141, in __call__
    losses = call_fn(y_true, y_pred)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py", line 689, in wrapper
    return converted_call(f, args, kwargs, options=options)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py", line 331, in converted_call
    return _call_unconverted(f, args, kwargs, options, False)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py", line 458, in _call_unconverted
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/keras/losses.py", line 245, in call
    return ag_fn(y_true, y_pred, **self._fn_kwargs)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/usr/local/lib/python3.8/dist-packages/keras/losses.py", line 1789, in categorical_crossentropy
    return backend.categorical_crossentropy(
  File "/usr/local/lib/python3.8/dist-packages/keras/backend.py", line 5083, in categorical_crossentropy
    target.shape.assert_is_compatible_with(output.shape)
ValueError: Shapes (None, 1) and (None, 10) are incompatible
Epoch 1/2
INFO:tensorflow:Error reported to Coordinator: Shapes (None, 1) and (None, 10) are incompatible
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/coordinator.py", line 293, in stop_on_exception
    yield
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py", line 342, in run
    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py", line 689, in wrapper
    return converted_call(f, args, kwargs, options=options)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py", line 377, in converted_call
    return _call_unconverted(f, args, kwargs, options)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py", line 458, in _call_unconverted
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/keras/engine/training.py", line 1000, in run_step
    outputs = model.train_step(data)
  File "/usr/local/lib/python3.8/dist-packages/keras/engine/training.py", line 860, in train_step
    loss = self.compute_loss(x, y, y_pred, sample_weight)
  File "/usr/local/lib/python3.8/dist-packages/keras/engine/training.py", line 918, in compute_loss
    return self.compiled_loss(
  File "/usr/local/lib/python3.8/dist-packages/keras/engine/compile_utils.py", line 201, in __call__
    loss_value = loss_obj(y_t, y_p, sample_weight=sw)
  File "/usr/local/lib/python3.8/dist-packages/keras/losses.py", line 141, in __call__
    losses = call_fn(y_true, y_pred)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py", line 689, in wrapper
    return converted_call(f, args, kwargs, options=options)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py", line 331, in converted_call
    return _call_unconverted(f, args, kwargs, options, False)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py", line 458, in _call_unconverted
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/keras/losses.py", line 245, in call
    return ag_fn(y_true, y_pred, **self._fn_kwargs)
  File "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/usr/local/lib/python3.8/dist-packages/keras/losses.py", line 1789, in categorical_crossentropy
    return backend.categorical_crossentropy(
  File "/usr/local/lib/python3.8/dist-packages/keras/backend.py", line 5083, in categorical_crossentropy
    target.shape.assert_is_compatible_with(output.shape)
ValueError: Shapes (None, 1) and (None, 10) are incompatible
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Number of devices: 1
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Number of devices: 1
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Training matrix shape (60000, 784)
Testing matrix shape (10000, 784)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Number of devices: 1
Training matrix shape (60000, 784)
Testing matrix shape (10000, 784)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
Number of devices: 1
2022-07-13 17:53:42.666365: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorSliceDataset/_2"
op: "TensorSliceDataset"
input: "Placeholder/_0"
input: "Placeholder/_1"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_FLOAT
      type: DT_FLOAT
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 60000
  }
}
attr {
  key: "is_files"
  value {
    b: false
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\027TensorSliceDataset:1034"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
        dim {
          size: 784
        }
      }
      shape {
        dim {
          size: 10
        }
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
    }
  }
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
    }
  }
}
Training matrix shape (60000, 784)
Testing matrix shape (10000, 784)
Epoch 1/10
235/235 [==============================] - 4s 4ms/step - loss: 0.3162 - accuracy: 0.9065
Epoch 2/10
235/235 [==============================] - 1s 4ms/step - loss: 0.1213 - accuracy: 0.9628
Epoch 3/10
235/235 [==============================] - 1s 4ms/step - loss: 0.0832 - accuracy: 0.9741
Epoch 4/10
235/235 [==============================] - 1s 4ms/step - loss: 0.0633 - accuracy: 0.9800
Epoch 5/10
235/235 [==============================] - 1s 4ms/step - loss: 0.0517 - accuracy: 0.9840
Epoch 6/10
235/235 [==============================] - 1s 4ms/step - loss: 0.0407 - accuracy: 0.9868
Epoch 7/10
235/235 [==============================] - 1s 4ms/step - loss: 0.0360 - accuracy: 0.9876
Epoch 8/10
235/235 [==============================] - 1s 4ms/step - loss: 0.0314 - accuracy: 0.9896
Epoch 9/10
235/235 [==============================] - 1s 4ms/step - loss: 0.0262 - accuracy: 0.9910
Epoch 10/10
235/235 [==============================] - 1s 4ms/step - loss: 0.0238 - accuracy: 0.9917
2022-07-13 17:53:59.515720: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorSliceDataset/_2"
op: "TensorSliceDataset"
input: "Placeholder/_0"
input: "Placeholder/_1"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_FLOAT
      type: DT_FLOAT
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 10000
  }
}
attr {
  key: "is_files"
  value {
    b: false
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\027TensorSliceDataset:1036"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
        dim {
          size: 784
        }
      }
      shape {
        dim {
          size: 10
        }
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
    }
  }
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_FLOAT
        }
      }
    }
  }
}
40/40 [==============================] - 2s 3ms/step - loss: 0.0782 - accuracy: 0.9791
Epoch 1/12
2022-07-13 17:57:23.443704: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:547] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.
107/118 [==========================>...] - ETA: 0s - loss: 0.4847 - accuracy: 0.8693
Learning rate for epoch 1 is 0.0010000000474974513
118/118 [==============================] - 4s 8ms/step - loss: 0.4613 - accuracy: 0.8753 - lr: 0.0010
Epoch 2/12
111/118 [===========================>..] - ETA: 0s - loss: 0.1572 - accuracy: 0.9546
Learning rate for epoch 2 is 0.0010000000474974513
118/118 [==============================] - 1s 7ms/step - loss: 0.1556 - accuracy: 0.9550 - lr: 0.0010
Epoch 3/12
114/118 [===========================>..] - ETA: 0s - loss: 0.1008 - accuracy: 0.9714
Learning rate for epoch 3 is 0.0010000000474974513
118/118 [==============================] - 1s 5ms/step - loss: 0.1005 - accuracy: 0.9715 - lr: 0.0010
Epoch 4/12
118/118 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.9794
Learning rate for epoch 4 is 9.999999747378752e-05
118/118 [==============================] - 1s 5ms/step - loss: 0.0749 - accuracy: 0.9794 - lr: 1.0000e-04
Epoch 5/12
107/118 [==========================>...] - ETA: 0s - loss: 0.0722 - accuracy: 0.9802
Learning rate for epoch 5 is 9.999999747378752e-05
118/118 [==============================] - 1s 5ms/step - loss: 0.0716 - accuracy: 0.9802 - lr: 1.0000e-04
Epoch 6/12
109/118 [==========================>...] - ETA: 0s - loss: 0.0698 - accuracy: 0.9809
Learning rate for epoch 6 is 9.999999747378752e-05
118/118 [==============================] - 1s 5ms/step - loss: 0.0693 - accuracy: 0.9810 - lr: 1.0000e-04
Epoch 7/12
108/118 [==========================>...] - ETA: 0s - loss: 0.0669 - accuracy: 0.9813
Learning rate for epoch 7 is 9.999999747378752e-05
118/118 [==============================] - 1s 5ms/step - loss: 0.0671 - accuracy: 0.9814 - lr: 1.0000e-04
Epoch 8/12
117/118 [============================>.] - ETA: 0s - loss: 0.0647 - accuracy: 0.9823
Learning rate for epoch 8 is 9.999999747378752e-06
118/118 [==============================] - 1s 5ms/step - loss: 0.0648 - accuracy: 0.9822 - lr: 1.0000e-05
Epoch 9/12
116/118 [============================>.] - ETA: 0s - loss: 0.0644 - accuracy: 0.9825
Learning rate for epoch 9 is 9.999999747378752e-06
118/118 [==============================] - 1s 5ms/step - loss: 0.0645 - accuracy: 0.9825 - lr: 1.0000e-05
Epoch 10/12
118/118 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.9826
Learning rate for epoch 10 is 9.999999747378752e-06
118/118 [==============================] - 1s 5ms/step - loss: 0.0643 - accuracy: 0.9826 - lr: 1.0000e-05
Epoch 11/12
117/118 [============================>.] - ETA: 0s - loss: 0.0640 - accuracy: 0.9826
Learning rate for epoch 11 is 9.999999747378752e-06
118/118 [==============================] - 1s 5ms/step - loss: 0.0640 - accuracy: 0.9826 - lr: 1.0000e-05
Epoch 12/12
117/118 [============================>.] - ETA: 0s - loss: 0.0638 - accuracy: 0.9828
Learning rate for epoch 12 is 9.999999747378752e-06
118/118 [==============================] - 1s 5ms/step - loss: 0.0638 - accuracy: 0.9827 - lr: 1.0000e-05
checkpoint		     ckpt_4.data-00000-of-00001
ckpt_1.data-00000-of-00001   ckpt_4.index
ckpt_1.index		     ckpt_5.data-00000-of-00001
ckpt_10.data-00000-of-00001  ckpt_5.index
ckpt_10.index		     ckpt_6.data-00000-of-00001
ckpt_11.data-00000-of-00001  ckpt_6.index
ckpt_11.index		     ckpt_7.data-00000-of-00001
ckpt_12.data-00000-of-00001  ckpt_7.index
ckpt_12.index		     ckpt_8.data-00000-of-00001
ckpt_2.data-00000-of-00001   ckpt_8.index
ckpt_2.index		     ckpt_9.data-00000-of-00001
ckpt_3.data-00000-of-00001   ckpt_9.index
ckpt_3.index
2022-07-13 17:57:46.421135: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:547] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.
20/20 [==============================] - 2s 7ms/step - loss: 0.0713 - accuracy: 0.9778
Eval loss: 0.07125338912010193, Eval accuracy: 0.9778000116348267
2022-07-13 17:59:00.298751: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:547] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.
Epoch 1/12
55/60 [==========================>...] - ETA: 0s - loss: 0.7018 - accuracy: 0.8279
Learning rate for epoch 1 is 0.0010000000474974513
60/60 [==============================] - 4s 16ms/step - loss: 0.6672 - accuracy: 0.8352 - lr: 0.0010
Epoch 2/12
57/60 [===========================>..] - ETA: 0s - loss: 0.2337 - accuracy: 0.9319
Learning rate for epoch 2 is 0.0010000000474974513
60/60 [==============================] - 0s 7ms/step - loss: 0.2319 - accuracy: 0.9327 - lr: 0.0010
Epoch 3/12
54/60 [==========================>...] - ETA: 0s - loss: 0.1666 - accuracy: 0.9525
Learning rate for epoch 3 is 0.0010000000474974513
60/60 [==============================] - 0s 7ms/step - loss: 0.1643 - accuracy: 0.9531 - lr: 0.0010
Epoch 4/12
54/60 [==========================>...] - ETA: 0s - loss: 0.1304 - accuracy: 0.9646
Learning rate for epoch 4 is 9.999999747378752e-05
60/60 [==============================] - 0s 7ms/step - loss: 0.1305 - accuracy: 0.9645 - lr: 1.0000e-04
Epoch 5/12
56/60 [===========================>..] - ETA: 0s - loss: 0.1254 - accuracy: 0.9657
Learning rate for epoch 5 is 9.999999747378752e-05
60/60 [==============================] - 0s 6ms/step - loss: 0.1260 - accuracy: 0.9657 - lr: 1.0000e-04
Epoch 6/12
56/60 [===========================>..] - ETA: 0s - loss: 0.1224 - accuracy: 0.9665
Learning rate for epoch 6 is 9.999999747378752e-05
60/60 [==============================] - 0s 6ms/step - loss: 0.1222 - accuracy: 0.9666 - lr: 1.0000e-04
Epoch 7/12
55/60 [==========================>...] - ETA: 0s - loss: 0.1188 - accuracy: 0.9676
Learning rate for epoch 7 is 9.999999747378752e-05
60/60 [==============================] - 0s 6ms/step - loss: 0.1183 - accuracy: 0.9678 - lr: 1.0000e-04
Epoch 8/12
53/60 [=========================>....] - ETA: 0s - loss: 0.1159 - accuracy: 0.9684
Learning rate for epoch 8 is 9.999999747378752e-06
60/60 [==============================] - 0s 7ms/step - loss: 0.1155 - accuracy: 0.9687 - lr: 1.0000e-05
Epoch 9/12
54/60 [==========================>...] - ETA: 0s - loss: 0.1152 - accuracy: 0.9686
Learning rate for epoch 9 is 9.999999747378752e-06
60/60 [==============================] - 0s 6ms/step - loss: 0.1151 - accuracy: 0.9688 - lr: 1.0000e-05
Epoch 10/12
55/60 [==========================>...] - ETA: 0s - loss: 0.1148 - accuracy: 0.9688
Learning rate for epoch 10 is 9.999999747378752e-06
60/60 [==============================] - 0s 6ms/step - loss: 0.1147 - accuracy: 0.9690 - lr: 1.0000e-05
Epoch 11/12
55/60 [==========================>...] - ETA: 0s - loss: 0.1139 - accuracy: 0.9690
Learning rate for epoch 11 is 9.999999747378752e-06
60/60 [==============================] - 0s 6ms/step - loss: 0.1143 - accuracy: 0.9689 - lr: 1.0000e-05
Epoch 12/12
55/60 [==========================>...] - ETA: 0s - loss: 0.1138 - accuracy: 0.9691
Learning rate for epoch 12 is 9.999999747378752e-06
60/60 [==============================] - 0s 6ms/step - loss: 0.1139 - accuracy: 0.9692 - lr: 1.0000e-05
2022-07-13 17:59:50.395897: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:547] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.
10/10 [==============================] - 2s 14ms/step - loss: 0.1135 - accuracy: 0.9672
Eval loss: 0.11345194280147552, Eval accuracy: 0.967199981212616
Epoch 1/12
2022-07-13 18:01:29.717291: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:547] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.
2022-07-13 18:01:33.884990: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.
1/1 [==============================] - ETA: 0s - loss: 2.2957 - accuracy: 0.0876
Learning rate for epoch 1 is 0.0010000000474974513
1/1 [==============================] - 5s 5s/step - loss: 2.2957 - accuracy: 0.0876 - lr: 0.0010
Epoch 2/12
1/1 [==============================] - ETA: 0s - loss: 2.1474 - accuracy: 0.2637
Learning rate for epoch 2 is 0.0010000000474974513
1/1 [==============================] - 2s 2s/step - loss: 2.1474 - accuracy: 0.2637 - lr: 0.0010
Epoch 3/12
1/1 [==============================] - ETA: 0s - loss: 2.0066 - accuracy: 0.4128
Learning rate for epoch 3 is 0.0010000000474974513
1/1 [==============================] - 1s 1s/step - loss: 2.0066 - accuracy: 0.4128 - lr: 0.0010
Epoch 4/12
1/1 [==============================] - ETA: 0s - loss: 1.8617 - accuracy: 0.5437
Learning rate for epoch 4 is 9.999999747378752e-05
1/1 [==============================] - 1s 601ms/step - loss: 1.8617 - accuracy: 0.5437 - lr: 1.0000e-04
Epoch 5/12
1/1 [==============================] - ETA: 0s - loss: 1.8466 - accuracy: 0.5576
Learning rate for epoch 5 is 9.999999747378752e-05
1/1 [==============================] - 1s 606ms/step - loss: 1.8466 - accuracy: 0.5576 - lr: 1.0000e-04
Epoch 6/12
1/1 [==============================] - ETA: 0s - loss: 1.8307 - accuracy: 0.5755
Learning rate for epoch 6 is 9.999999747378752e-05
1/1 [==============================] - 1s 514ms/step - loss: 1.8307 - accuracy: 0.5755 - lr: 1.0000e-04
Epoch 7/12
1/1 [==============================] - ETA: 0s - loss: 1.8144 - accuracy: 0.5936
Learning rate for epoch 7 is 9.999999747378752e-05
1/1 [==============================] - 1s 534ms/step - loss: 1.8144 - accuracy: 0.5936 - lr: 1.0000e-04
Epoch 8/12
1/1 [==============================] - ETA: 0s - loss: 1.7981 - accuracy: 0.6117
Learning rate for epoch 8 is 9.999999747378752e-06
1/1 [==============================] - 1s 625ms/step - loss: 1.7981 - accuracy: 0.6117 - lr: 1.0000e-05
Epoch 9/12
1/1 [==============================] - ETA: 0s - loss: 1.7964 - accuracy: 0.6133
Learning rate for epoch 9 is 9.999999747378752e-06
1/1 [==============================] - 1s 600ms/step - loss: 1.7964 - accuracy: 0.6133 - lr: 1.0000e-05
Epoch 10/12
1/1 [==============================] - ETA: 0s - loss: 1.7948 - accuracy: 0.6153
Learning rate for epoch 10 is 9.999999747378752e-06
1/1 [==============================] - 1s 624ms/step - loss: 1.7948 - accuracy: 0.6153 - lr: 1.0000e-05
Epoch 11/12
1/1 [==============================] - ETA: 0s - loss: 1.7931 - accuracy: 0.6167
Learning rate for epoch 11 is 9.999999747378752e-06
1/1 [==============================] - 1s 626ms/step - loss: 1.7931 - accuracy: 0.6167 - lr: 1.0000e-05
Epoch 12/12
1/1 [==============================] - ETA: 0s - loss: 1.7914 - accuracy: 0.6188
Learning rate for epoch 12 is 9.999999747378752e-06
1/1 [==============================] - 1s 611ms/step - loss: 1.7914 - accuracy: 0.6188 - lr: 1.0000e-05
Epoch 1/12
1/1 [==============================] - ETA: 0s - loss: 1.7897 - accuracy: 0.6205
Learning rate for epoch 1 is 0.0010000000474974513
1/1 [==============================] - 1s 612ms/step - loss: 1.7897 - accuracy: 0.6205 - lr: 0.0010
Epoch 2/12
2022-07-13 18:06:51.720581: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:547] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.
1/1 [==============================] - ETA: 0s - loss: 1.6365 - accuracy: 0.7316
Learning rate for epoch 2 is 0.0010000000474974513
1/1 [==============================] - 1s 540ms/step - loss: 1.6365 - accuracy: 0.7316 - lr: 0.0010
Epoch 3/12
1/1 [==============================] - ETA: 0s - loss: 1.4964 - accuracy: 0.7609
Learning rate for epoch 3 is 0.0010000000474974513
1/1 [==============================] - 1s 525ms/step - loss: 1.4964 - accuracy: 0.7609 - lr: 0.0010
Epoch 4/12
1/1 [==============================] - ETA: 0s - loss: 1.3550 - accuracy: 0.7793
Learning rate for epoch 4 is 9.999999747378752e-05
1/1 [==============================] - 1s 666ms/step - loss: 1.3550 - accuracy: 0.7793 - lr: 1.0000e-04
Epoch 5/12
1/1 [==============================] - ETA: 0s - loss: 1.3405 - accuracy: 0.7808
Learning rate for epoch 5 is 9.999999747378752e-05
1/1 [==============================] - 1s 623ms/step - loss: 1.3405 - accuracy: 0.7808 - lr: 1.0000e-04
Epoch 6/12
1/1 [==============================] - ETA: 0s - loss: 1.3256 - accuracy: 0.7824
Learning rate for epoch 6 is 9.999999747378752e-05
1/1 [==============================] - 1s 1s/step - loss: 1.3256 - accuracy: 0.7824 - lr: 1.0000e-04
Epoch 7/12
1/1 [==============================] - ETA: 0s - loss: 1.3104 - accuracy: 0.7844
Learning rate for epoch 7 is 9.999999747378752e-05
1/1 [==============================] - 1s 542ms/step - loss: 1.3104 - accuracy: 0.7844 - lr: 1.0000e-04
Epoch 8/12
1/1 [==============================] - ETA: 0s - loss: 1.2950 - accuracy: 0.7859
Learning rate for epoch 8 is 9.999999747378752e-06
1/1 [==============================] - 1s 632ms/step - loss: 1.2950 - accuracy: 0.7859 - lr: 1.0000e-05
Epoch 9/12
1/1 [==============================] - ETA: 0s - loss: 1.2935 - accuracy: 0.7860
Learning rate for epoch 9 is 9.999999747378752e-06
1/1 [==============================] - 1s 603ms/step - loss: 1.2935 - accuracy: 0.7860 - lr: 1.0000e-05
Epoch 10/12
1/1 [==============================] - ETA: 0s - loss: 1.2919 - accuracy: 0.7863
Learning rate for epoch 10 is 9.999999747378752e-06
1/1 [==============================] - 1s 552ms/step - loss: 1.2919 - accuracy: 0.7863 - lr: 1.0000e-05
Epoch 11/12
1/1 [==============================] - ETA: 0s - loss: 1.2903 - accuracy: 0.7864
Learning rate for epoch 11 is 9.999999747378752e-06
1/1 [==============================] - 1s 605ms/step - loss: 1.2903 - accuracy: 0.7864 - lr: 1.0000e-05
Epoch 12/12
1/1 [==============================] - ETA: 0s - loss: 1.2887 - accuracy: 0.7864
Learning rate for epoch 12 is 9.999999747378752e-06
1/1 [==============================] - 1s 520ms/step - loss: 1.2887 - accuracy: 0.7864 - lr: 1.0000e-05