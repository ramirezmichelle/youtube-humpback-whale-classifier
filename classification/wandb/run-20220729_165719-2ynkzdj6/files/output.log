2022-07-29 16:57:24.790339: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-07-29 16:57:31.561889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14649 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:06:00.0, compute capability: 7.0
2022-07-29 16:57:31.564536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14649 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:07:00.0, compute capability: 7.0
2022-07-29 16:57:31.566949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14649 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:0a:00.0, compute capability: 7.0
2022-07-29 16:57:31.569288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14649 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:0b:00.0, compute capability: 7.0
2022-07-29 16:57:31.571661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 14649 MB memory:  -> device: 4, name: Tesla V100-SXM2-16GB, pci bus id: 0000:85:00.0, compute capability: 7.0
2022-07-29 16:57:31.574029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 14649 MB memory:  -> device: 5, name: Tesla V100-SXM2-16GB, pci bus id: 0000:86:00.0, compute capability: 7.0
2022-07-29 16:57:31.576335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 14649 MB memory:  -> device: 6, name: Tesla V100-SXM2-16GB, pci bus id: 0000:89:00.0, compute capability: 7.0
2022-07-29 16:57:31.578685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 14649 MB memory:  -> device: 7, name: Tesla V100-SXM2-16GB, pci bus id: 0000:8a:00.0, compute capability: 7.0
8 Physical GPUs, 8 Logical GPUs
2022-07-29 16:57:44.246112: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.
2022-07-29 16:57:45.319652: I tensorflow/stream_executor/cuda/cuda_dnn.cc:379] Loaded cuDNN version 8400
2022-07-29 16:57:46.490667: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.
Model: "feature_extractor"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_2 (InputLayer)        [(None, 224, 224, 3)]     0
 tf.__operators__.getitem (S  (None, 224, 224, 3)      0
 licingOpLambda)
 tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0
 vgg16 (Functional)          (None, 512)               14714688
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
0
50
100
150
200
250
300
350
Done loading frames in 362.70917987823486 seconds.
(364,)
(364, 461, 512)
(291, 461, 512)
(73, 461, 512)
Epoch 1/15

8/8 [==============================] - 12s 486ms/step - loss: 0.6126 - accuracy: 0.6853 - val_loss: 0.4628 - val_accuracy: 0.7797
Epoch 2/15
8/8 [==============================] - 1s 135ms/step - loss: 0.3688 - accuracy: 0.8534 - val_loss: 0.5891 - val_accuracy: 0.7627
Epoch 3/15
8/8 [==============================] - 1s 139ms/step - loss: 0.3055 - accuracy: 0.8664 - val_loss: 0.4354 - val_accuracy: 0.8305
Epoch 4/15
8/8 [==============================] - 1s 134ms/step - loss: 0.1777 - accuracy: 0.9310 - val_loss: 0.4508 - val_accuracy: 0.7966
Epoch 5/15
8/8 [==============================] - 1s 136ms/step - loss: 0.0958 - accuracy: 0.9655 - val_loss: 0.6413 - val_accuracy: 0.7966
Epoch 6/15
8/8 [==============================] - 1s 138ms/step - loss: 0.0573 - accuracy: 0.9784 - val_loss: 0.4874 - val_accuracy: 0.8305
Done training.
3/3 [==============================] - 0s 43ms/step - loss: 0.4625 - accuracy: 0.7945
Test Metrics - Loss: 0.4625420868396759, Accuracy: 0.7945205569267273
Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5
80142336/80134624 [==============================] - 2s 0us/step
80150528/80134624 [==============================] - 2s 0us/step
Model: "feature_extractor"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_5 (InputLayer)        [(None, 224, 224, 3)]     0
 tf.__operators__.getitem_1   (None, 224, 224, 3)      0
 (SlicingOpLambda)
 tf.nn.bias_add_1 (TFOpLambd  (None, 224, 224, 3)      0
 a)
 vgg19 (Functional)          (None, 512)               20024384
=================================================================
Total params: 20,024,384
Trainable params: 20,024,384
Non-trainable params: 0
