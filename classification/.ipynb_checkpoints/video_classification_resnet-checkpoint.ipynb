{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f82e8f2",
   "metadata": {},
   "source": [
    "# Classifying YouTube Videos for Humpback Whale Encounters - Keras CNN-RNN (ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22dfc985",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b400c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import pickle\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b33c8308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngc workspace path (where we keep our data)\n",
    "workspace_path = '/mount/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e01707a",
   "metadata": {},
   "source": [
    "# Start WandB Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a977d8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmicheller\u001b[0m (\u001b[33mepg\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/youtube-humpback-whale-classifier/classification/wandb/run-20220713_203704-2aa3nsny</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/epg/whale-classification-inception/runs/2aa3nsny\" target=\"_blank\">frosty-glade-15</a></strong> to <a href=\"https://wandb.ai/epg/whale-classification-inception\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "#start wandb session for metric logging\n",
    "wandb.login() \n",
    "\n",
    "wandb.init(project=\"whale-classification-inception\")\n",
    "\n",
    "wandb.run.name = \"resnet50-feature-ext-distributed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97afadf4",
   "metadata": {},
   "source": [
    "# Checking GPUs Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b37ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs available:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs available: \", len(tf.config.list_physical_devices('GPU'))) #1 if we select GPU mode in Colab Notebook, 0 if running on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573a1ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/physical_device:GPU:0\n",
      "/physical_device:GPU:1\n",
      "/physical_device:GPU:2\n",
      "/physical_device:GPU:3\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "# gpus = tf.config.list_logical_devices('GPU')\n",
    "\n",
    "for gpu in gpus:\n",
    "    print(gpu.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0ba52c",
   "metadata": {},
   "source": [
    "# Load Dataset in + Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5794e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "MAX_NUM_FRAMES = 461\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b79d03b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset in\n",
    "data = pd.read_csv(workspace_path + '/downloaded_videos.csv')\n",
    "y = data.pop('relevant')\n",
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "21d17836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataset to tf.data.Dataset\n",
    "data_tf = tf.data.Dataset.from_tensor_slices((\n",
    "    X['renamed_title'].values, \n",
    "    y.values\n",
    ")).batch(91)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "764bdabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "batch_0_video_names = list(data_tf.as_numpy_iterator())[batch_idx][0]\n",
    "batch_0_labels = list(data_tf.as_numpy_iterator())[batch_idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b610de86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['video_0000.mp4',\n",
       " 'video_0001.mp4',\n",
       " 'video_0002.mp4',\n",
       " 'video_0003.mp4',\n",
       " 'video_0004.mp4']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_0_video_names\n",
    "\n",
    "videos = [video_name.decode(\"utf-8\") for video_name in batch_0_video_names]\n",
    "videos[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c43f51",
   "metadata": {},
   "source": [
    "461 frames of size 224 x 224 with RGB color channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff5816a",
   "metadata": {},
   "source": [
    "# Load Frames + Extract Features with CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6adb0d3",
   "metadata": {},
   "source": [
    "## ResNet50 (CNN-RNN) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76913cc0",
   "metadata": {},
   "source": [
    "### Distributed Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9706963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from feature_extraction import load_frames, prepare_all_videos\n",
    "from feature_extraction import Extraction\n",
    "from cnn import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "88a7f322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of devices: 4\n",
      "Setting strategy scope...\n",
      "\n",
      "Extracting Frames..\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Done Extracting Frames.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "#set up tf.Dataset\n",
    "BATCH_SIZE = 91 #number of videos per each batch\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE * strategy.num_replicas_in_sync\n",
    "\n",
    "data_tf = tf.data.Dataset.from_tensor_slices((\n",
    "    X['renamed_title'].values, \n",
    "    y.values\n",
    ")).batch(GLOBAL_BATCH_SIZE) #each gpu will get 91 examples from the batch\n",
    "\n",
    "\n",
    "# Open a strategy scope.\n",
    "print('Setting strategy scope...\\n')\n",
    "with strategy.scope():\n",
    "    ConvNet = CNN(224)\n",
    "    feature_extractor = ConvNet.ResNet50() #might want to move this out of scope \n",
    "    ext = Extraction(feature_extractor)\n",
    "    \n",
    "#extract frame features\n",
    "print('Extracting Frames..\\n')\n",
    "start = time.time()\n",
    "ext.prepare_all_videos(data_tf, MAX_NUM_FRAMES, NUM_FEATURES) #not working properly - each GPU (or single GPU is getting all batches :( )})\n",
    "stop = time.time()\n",
    "print('Done Extracting Frames.\\n')\n",
    "\n",
    "# print(f\"Time to extract frames with Distribute Strategy: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fc976c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      " ['video_0000.mp4', 'video_0001.mp4', 'video_0002.mp4', 'video_0003.mp4', 'video_0004.mp4', 'video_0006.mp4', 'video_0007.mp4', 'video_0008.mp4', 'video_0009.mp4', 'video_0010.mp4', 'video_0011.mp4', 'video_0014.mp4', 'video_0017.mp4', 'video_0018.mp4', 'video_0019.mp4', 'video_0020.mp4', 'video_0021.mp4', 'video_0023.mp4', 'video_0024.mp4', 'video_0025.mp4', 'video_0026.mp4', 'video_0027.mp4', 'video_0028.mp4', 'video_0029.mp4', 'video_0030.mp4', 'video_0031.mp4', 'video_0032.mp4', 'video_0033.mp4', 'video_0034.mp4', 'video_0035.mp4', 'video_0036.mp4', 'video_0037.mp4', 'video_0039.mp4', 'video_0040.mp4', 'video_0041.mp4', 'video_0042.mp4', 'video_0043.mp4', 'video_0044.mp4', 'video_0046.mp4', 'video_0047.mp4', 'video_0048.mp4', 'video_0049.mp4', 'video_0050.mp4', 'video_0051.mp4', 'video_0052.mp4', 'video_0053.mp4', 'video_0054.mp4', 'video_0055.mp4', 'video_0057.mp4', 'video_0058.mp4', 'video_0060.mp4', 'video_0061.mp4', 'video_0065.mp4', 'video_0066.mp4', 'video_0067.mp4', 'video_0068.mp4', 'video_0070.mp4', 'video_0071.mp4', 'video_0072.mp4', 'video_0075.mp4', 'video_0078.mp4', 'video_0079.mp4', 'video_0080.mp4', 'video_0083.mp4', 'video_0084.mp4', 'video_0085.mp4', 'video_0088.mp4', 'video_0089.mp4', 'video_0090.mp4', 'video_0091.mp4', 'video_0092.mp4', 'video_0094.mp4', 'video_0095.mp4', 'video_0096.mp4', 'video_0098.mp4', 'video_0099.mp4', 'video_0100.mp4', 'video_0103.mp4', 'video_0105.mp4', 'video_0106.mp4', 'video_0107.mp4', 'video_0108.mp4', 'video_0110.mp4', 'video_0111.mp4', 'video_0112.mp4', 'video_0113.mp4', 'video_0116.mp4', 'video_0117.mp4', 'video_0118.mp4', 'video_0119.mp4', 'video_0121.mp4'] \n",
      "\n",
      "\n",
      "1 \n",
      " ['video_0122.mp4', 'video_0123.mp4', 'video_0126.mp4', 'video_0127.mp4', 'video_0128.mp4', 'video_0129.mp4', 'video_0131.mp4', 'video_0132.mp4', 'video_0133.mp4', 'video_0134.mp4', 'video_0135.mp4', 'video_0136.mp4', 'video_0137.mp4', 'video_0138.mp4', 'video_0139.mp4', 'video_0140.mp4', 'video_0141.mp4', 'video_0142.mp4', 'video_0143.mp4', 'video_0144.mp4', 'video_0145.mp4', 'video_0146.mp4', 'video_0147.mp4', 'video_0148.mp4', 'video_0150.mp4', 'video_0151.mp4', 'video_0152.mp4', 'video_0153.mp4', 'video_0154.mp4', 'video_0155.mp4', 'video_0156.mp4', 'video_0158.mp4', 'video_0159.mp4', 'video_0161.mp4', 'video_0162.mp4', 'video_0163.mp4', 'video_0164.mp4', 'video_0165.mp4', 'video_0166.mp4', 'video_0167.mp4', 'video_0168.mp4', 'video_0169.mp4', 'video_0170.mp4', 'video_0171.mp4', 'video_0172.mp4', 'video_0173.mp4', 'video_0174.mp4', 'video_0175.mp4', 'video_0176.mp4', 'video_0177.mp4', 'video_0178.mp4', 'video_0180.mp4', 'video_0181.mp4', 'video_0182.mp4', 'video_0183.mp4', 'video_0184.mp4', 'video_0185.mp4', 'video_0186.mp4', 'video_0188.mp4', 'video_0189.mp4', 'video_0190.mp4', 'video_0191.mp4', 'video_0192.mp4', 'video_0194.mp4', 'video_0195.mp4', 'video_0196.mp4', 'video_0197.mp4', 'video_0198.mp4', 'video_0199.mp4', 'video_0200.mp4', 'video_0202.mp4', 'video_0203.mp4', 'video_0204.mp4', 'video_0205.mp4', 'video_0207.mp4', 'video_0208.mp4', 'video_0209.mp4', 'video_0210.mp4', 'video_0211.mp4', 'video_0214.mp4', 'video_0216.mp4', 'video_0217.mp4', 'video_0218.mp4', 'video_0219.mp4', 'video_0220.mp4', 'video_0221.mp4', 'video_0222.mp4', 'video_0223.mp4', 'video_0224.mp4', 'video_0225.mp4', 'video_0226.mp4'] \n",
      "\n",
      "\n",
      "2 \n",
      " ['video_0227.mp4', 'video_0228.mp4', 'video_0229.mp4', 'video_0230.mp4', 'video_0231.mp4', 'video_0233.mp4', 'video_0234.mp4', 'video_0236.mp4', 'video_0237.mp4', 'video_0239.mp4', 'video_0240.mp4', 'video_0241.mp4', 'video_0242.mp4', 'video_0243.mp4', 'video_0244.mp4', 'video_0245.mp4', 'video_0246.mp4', 'video_0247.mp4', 'video_0248.mp4', 'video_0249.mp4', 'video_0250.mp4', 'video_0251.mp4', 'video_0252.mp4', 'video_0253.mp4', 'video_0254.mp4', 'video_0255.mp4', 'video_0256.mp4', 'video_0257.mp4', 'video_0258.mp4', 'video_0260.mp4', 'video_0261.mp4', 'video_0262.mp4', 'video_0263.mp4', 'video_0264.mp4', 'video_0265.mp4', 'video_0266.mp4', 'video_0267.mp4', 'video_0268.mp4', 'video_0269.mp4', 'video_0270.mp4', 'video_0271.mp4', 'video_0272.mp4', 'video_0273.mp4', 'video_0274.mp4', 'video_0275.mp4', 'video_0276.mp4', 'video_0277.mp4', 'video_0279.mp4', 'video_0280.mp4', 'video_0281.mp4', 'video_0282.mp4', 'video_0283.mp4', 'video_0284.mp4', 'video_0285.mp4', 'video_0286.mp4', 'video_0287.mp4', 'video_0290.mp4', 'video_0291.mp4', 'video_0292.mp4', 'video_0293.mp4', 'video_0294.mp4', 'video_0295.mp4', 'video_0296.mp4', 'video_0297.mp4', 'video_0299.mp4', 'video_0300.mp4', 'video_0301.mp4', 'video_0302.mp4', 'video_0303.mp4', 'video_0304.mp4', 'video_0305.mp4', 'video_0307.mp4', 'video_0308.mp4', 'video_0309.mp4', 'video_0310.mp4', 'video_0311.mp4', 'video_0312.mp4', 'video_0313.mp4', 'video_0314.mp4', 'video_0315.mp4', 'video_0317.mp4', 'video_0318.mp4', 'video_0319.mp4', 'video_0320.mp4', 'video_0321.mp4', 'video_0323.mp4', 'video_0324.mp4', 'video_0325.mp4', 'video_0326.mp4', 'video_0327.mp4', 'video_0328.mp4'] \n",
      "\n",
      "\n",
      "3 \n",
      " ['video_0329.mp4', 'video_0330.mp4', 'video_0331.mp4', 'video_0332.mp4', 'video_0333.mp4', 'video_0334.mp4', 'video_0335.mp4', 'video_0336.mp4', 'video_0337.mp4', 'video_0338.mp4', 'video_0339.mp4', 'video_0340.mp4', 'video_0341.mp4', 'video_0342.mp4', 'video_0343.mp4', 'video_0344.mp4', 'video_0345.mp4', 'video_0346.mp4', 'video_0347.mp4', 'video_0348.mp4', 'video_0349.mp4', 'video_0350.mp4', 'video_0352.mp4', 'video_0353.mp4', 'video_0354.mp4', 'video_0355.mp4', 'video_0356.mp4', 'video_0357.mp4', 'video_0358.mp4', 'video_0359.mp4', 'video_0361.mp4', 'video_0362.mp4', 'video_0363.mp4', 'video_0364.mp4', 'video_0365.mp4', 'video_0366.mp4', 'video_0367.mp4', 'video_0368.mp4', 'video_0369.mp4', 'video_0370.mp4', 'video_0371.mp4', 'video_0372.mp4', 'video_0373.mp4', 'video_0375.mp4', 'video_0376.mp4', 'video_0377.mp4', 'video_0378.mp4', 'video_0379.mp4', 'video_0380.mp4', 'video_0381.mp4', 'video_0382.mp4', 'video_0383.mp4', 'video_0384.mp4', 'video_0386.mp4', 'video_0387.mp4', 'video_0389.mp4', 'video_0390.mp4', 'video_0391.mp4', 'video_0392.mp4', 'video_0393.mp4', 'video_0395.mp4', 'video_0396.mp4', 'video_0397.mp4', 'video_0398.mp4', 'video_0399.mp4', 'video_0401.mp4', 'video_0402.mp4', 'video_0403.mp4', 'video_0404.mp4', 'video_0405.mp4', 'video_0406.mp4', 'video_0407.mp4', 'video_0408.mp4', 'video_0409.mp4', 'video_0410.mp4', 'video_0412.mp4', 'video_0413.mp4', 'video_0415.mp4', 'video_0416.mp4', 'video_0417.mp4', 'video_0418.mp4', 'video_0420.mp4', 'video_0421.mp4', 'video_0422.mp4', 'video_0423.mp4', 'video_0424.mp4', 'video_0425.mp4', 'video_0427.mp4', 'video_0428.mp4', 'video_0429.mp4', 'video_0430.mp4'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# videos = [video_name.numpy().decode(\"utf-8\") \n",
    "# batch_num = 0\n",
    "\n",
    "i = 0\n",
    "for video_names, label in data_tf:\n",
    "    for batch in video_names:\n",
    "#         print(i, batch)\n",
    "        videos = [video.numpy().decode(\"utf-8\") for video in batch]\n",
    "        print(i, '\\n', videos, '\\n\\n')\n",
    "        i += 1\n",
    "    #print(video_names[batch_num][0])\n",
    "\n",
    "# batch_names = [video_names[batch_num] for video_names, label in data_tf.take(2)]\n",
    "# batch_names\n",
    "\n",
    "i = 0\n",
    "for video_names, label in data_tf:\n",
    "    for batch in video_names:\n",
    "        videos = [video.numpy().decode(\"utf-8\") for video in batch]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5487f4c6",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68ca85c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 2s 0us/step\n",
      "94781440/94765736 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fc869dc3a90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from feature_extraction import load_frames, prepare_all_videos\n",
    "from cnn import CNN\n",
    "\n",
    "#create CNN Feature Extractor\n",
    "ConvNet = CNN(IMG_SIZE)\n",
    "feature_extractor = ConvNet.ResNet50()\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07af7f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_0000.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 14:12:30.869519: I tensorflow/stream_executor/cuda/cuda_dnn.cc:379] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to extract frames with single GPU: 288.7691180706024s\n"
     ]
    }
   ],
   "source": [
    "#begin keeping track of time to extract ALL frames using a single GPU\n",
    "start = time.time()\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    (frame_features, frame_masks), labels = prepare_all_videos(X, y, MAX_NUM_FRAMES, NUM_FEATURES, feature_extractor)\n",
    "    \n",
    "stop = time.time()\n",
    "\n",
    "print(f\"Time to extract frames with single GPU: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23eeac37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08021364390850066"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#took 5 hours to extract features from frames with the GPU context set above\n",
    "(stop-start)/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fe8216e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame features shape:  (5, 461, 2048)\n",
      "Frame masks shape:  (5, 461)\n",
      "Number of Labels:  5\n"
     ]
    }
   ],
   "source": [
    "print('Frame features shape: ', frame_features.shape)\n",
    "print('Frame masks shape: ', frame_masks.shape)\n",
    "print('Number of Labels: ', len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ffb398",
   "metadata": {},
   "source": [
    "# Training RNN Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b41427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split data into 80% train, 20% test. Both test and train contain balanced class proportions (half rel, half not rel) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79712ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 111ms/step - loss: 0.4789 - accuracy: 1.0000\n",
      "Loss: 0.4788905084133148, Accuracy: 1.0\n",
      "F1: [1.], Precision: [1.], Recall: [1.]\n"
     ]
    }
   ],
   "source": [
    "from rnn import RNN\n",
    "from sklearn import metrics\n",
    "\n",
    "rnn_model = RNN()\n",
    "\n",
    "train_index = list(X_train.index)\n",
    "test_index = list(X_test.index)\n",
    "\n",
    "#index data accordingly\n",
    "train_features, train_masks, train_labels = frame_features[train_index], frame_masks[train_index], np.array(labels)[train_index]\n",
    "test_features, test_masks, test_labels = frame_features[test_index], frame_masks[test_index], np.array(labels)[test_index]\n",
    "\n",
    "#reshape label arrays as horizontal arrays\n",
    "train_labels = np.reshape(train_labels, (train_labels.shape[0], 1))\n",
    "test_labels = np.reshape(test_labels, (test_labels.shape[0], 1))\n",
    "\n",
    "#create and compile model\n",
    "rnn_model.build_model(MAX_NUM_FRAMES, NUM_FEATURES)\n",
    "rnn_model.compile_model(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n",
    "\n",
    "#train model - 20 epochs gave us 75% accuracy on train\n",
    "history = rnn_model.fit(train_features, train_masks, train_labels, num_epochs=50, verbose=0)\n",
    "\n",
    "#evaluate model on test set\n",
    "loss, accuracy = rnn_model.evaluate(test_features, test_masks, test_labels)\n",
    "\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
    "\n",
    "#get f1, precision, recall, support metrics\n",
    "y_pred = rnn_model.predict(test_features, test_masks)\n",
    "y_true = test_labels.flatten()\n",
    "\n",
    "cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "precision, recall, f1, support =  metrics.precision_recall_fscore_support(y_true, y_pred)\n",
    "\n",
    "print(f\"F1: {f1}, Precision: {precision}, Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "178173d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Logging WandB metrics.\n"
     ]
    }
   ],
   "source": [
    "#log training and validation metrics on wandb\n",
    "for epoch, train_loss in enumerate(history.history['loss']):\n",
    "    wandb.log({'training_loss': train_loss, \"epoch\": epoch})\n",
    "    \n",
    "for epoch, train_acc in enumerate(history.history['accuracy']):\n",
    "    wandb.log({'training_accuracy': train_acc, \"epoch\": epoch})\n",
    "    \n",
    "for epoch, val_loss in enumerate(history.history['val_loss']):\n",
    "    wandb.log({'val_loss': val_loss, \"epoch\": epoch})\n",
    "    \n",
    "for epoch, val_acc in enumerate(history.history['val_accuracy']):\n",
    "    wandb.log({'val_accuracy': val_acc, \"epoch\": epoch})\n",
    "    \n",
    "print('Done Logging WandB metrics.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "06aa279a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot confusion matrix\n",
    "sns.heatmap(cm, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Inception CNN-RNN Predictions Results')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d6a2d7",
   "metadata": {},
   "source": [
    "# Diving Deeper into Inference Misclassifications\n",
    "\n",
    "- Figure out which examples got misclassified\n",
    "- Put together df with Video Name, True Label, Pred Label, Video Snippet (Put frames together so we know what exact content the NN was working with - checkout DALI frame reading)\n",
    "- Visualize False Positives and False Negatives on WandB as Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a701d859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>True Relevant Label</th>\n",
       "      <th>Pred Relevant Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video_0241.mp4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video_0040.mp4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video_0020.mp4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video_0410.mp4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video_0071.mp4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File  True Relevant Label  Pred Relevant Label\n",
       "0  video_0241.mp4                False                False\n",
       "1  video_0040.mp4                 True                 True\n",
       "2  video_0020.mp4                 True                 True\n",
       "3  video_0410.mp4                False                False\n",
       "4  video_0071.mp4                 True                 True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = pd.DataFrame({'File': X.loc[test_index].renamed_title.tolist(), \n",
    "                       'True Relevant Label': y.loc[test_index].tolist(),\n",
    "                       'Pred Relevant Label': list(map(bool, y_pred))})\n",
    "print(test_results.shape)\n",
    "test_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620aa7e7",
   "metadata": {},
   "source": [
    "### Plotting False Positives on WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fabf6082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Positives (True Label = 0 ; Pred Label = 1)\n",
    "false_positives = test_results[(test_results[\"True Relevant Label\"] == False) & (test_results[\"Pred Relevant Label\"] == True)].copy(deep=True)\n",
    "\n",
    "clip_folder = workspace_path + \"/video_clips/\"\n",
    "\n",
    "#get wandb video objects\n",
    "for i, row in false_positives.iterrows():\n",
    "    video_clip = clip_folder + row['File'].replace('_', '_clip_')\n",
    "    false_positives.at[i, ('video_clip')] = wandb.Video(video_clip, fps=4, format=\"gif\")\n",
    "\n",
    "#create wandb table with all information\n",
    "table = wandb.Table(dataframe=false_positives)\n",
    "wandb.log({\"Videos Mistaken for Humpback Whales (False Postives)\": table})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935918b4",
   "metadata": {},
   "source": [
    "### Plotting False Negatives on WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9fc8151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Negatives (True Label = 1 ; Pred Label = 0)\n",
    "false_negatives = test_results[(test_results[\"True Relevant Label\"] == True) & (test_results[\"Pred Relevant Label\"] == False)].copy(deep = True)\n",
    "\n",
    "clip_folder = workspace_path + \"/video_clips/\"\n",
    "\n",
    "#get wandb video objects\n",
    "for i, row in false_negatives.iterrows():\n",
    "    video_clip = clip_folder + row['File'].replace('_', '_clip_')\n",
    "    false_negatives.at[i, ('video_clip')] = wandb.Video(video_clip, fps=4, format=\"gif\")\n",
    "\n",
    "#create wandb table with all information\n",
    "table = wandb.Table(dataframe=false_negatives)\n",
    "wandb.log({\"Videos Mistaken as NOT Having Humpback Whales (False Negatives)\": table})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d304310",
   "metadata": {},
   "source": [
    "# Close WandB Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b40d832e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">solar-serenity-9</strong>: <a href=\"https://wandb.ai/epg/whale-classification-inception/runs/3p3f7bq2\" target=\"_blank\">https://wandb.ai/epg/whale-classification-inception/runs/3p3f7bq2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220713_132931-3p3f7bq2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
