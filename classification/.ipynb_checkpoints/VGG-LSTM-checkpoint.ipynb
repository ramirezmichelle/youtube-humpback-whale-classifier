{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fac4a0df",
   "metadata": {},
   "source": [
    "# VGG-LSTM for Video Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10098911",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import pickle\n",
    "import glob\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import seaborn as sns\n",
    "\n",
    " \n",
    "# adding video-download folder to the system path\n",
    "sys.path.insert(0, '/workspace/youtube-humpback-whale-classifier/video-download')\n",
    " \n",
    "# importing read_frames_hdf5 function\n",
    "from hdf5_data_loading import read_frames_hdf5\n",
    "\n",
    "#ngc workspace path (where we keep our data)\n",
    "workspace_path = '/mount/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98a7bd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmicheller\u001b[0m (\u001b[33mepg\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/youtube-humpback-whale-classifier/classification/wandb/run-20220731_183147-1icxm3kr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/epg/whale-classification-inception/runs/1icxm3kr\" target=\"_blank\">electric-wildflower-51</a></strong> to <a href=\"https://wandb.ai/epg/whale-classification-inception\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "#start wandb session for metric logging\n",
    "wandb.login() \n",
    "\n",
    "wandb.init(project=\"whale-classification-inception\")\n",
    "\n",
    "wandb.run.name = \"resnet-dist-LSTM\"\n",
    "\n",
    "# # !wandb login --relogin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f085484d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs available:  8\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs available: \", len(tf.config.list_physical_devices('GPU'))) #1 if we select GPU mode in Colab Notebook, 0 if running on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ea550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Physical GPUs, 8 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 18:31:50.138768: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-31 18:31:56.718024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14649 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:06:00.0, compute capability: 7.0\n",
      "2022-07-31 18:31:56.720643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14649 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:07:00.0, compute capability: 7.0\n",
      "2022-07-31 18:31:56.723046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14649 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:0a:00.0, compute capability: 7.0\n",
      "2022-07-31 18:31:56.725485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14649 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:0b:00.0, compute capability: 7.0\n",
      "2022-07-31 18:31:56.727850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 14649 MB memory:  -> device: 4, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:85:00.0, compute capability: 7.0\n",
      "2022-07-31 18:31:56.730194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 14649 MB memory:  -> device: 5, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:86:00.0, compute capability: 7.0\n",
      "2022-07-31 18:31:56.732514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 14649 MB memory:  -> device: 6, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:89:00.0, compute capability: 7.0\n",
      "2022-07-31 18:31:56.734826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 14649 MB memory:  -> device: 7, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "#limit GPU memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0dc4b6",
   "metadata": {},
   "source": [
    "## Load Frames + Get Features using Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff01c20d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "workspace_path = '/mount/data'\n",
    "hdf5_dir = Path(workspace_path + \"/frames_hdf5/\")   \n",
    "\n",
    "def read_frames_hdf5(video_clip_title):\n",
    "    \"\"\" Reads image from HDF5.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        num_images   number of images to read\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        images      images array, (N, 32, 32, 3) to be stored\n",
    "        labels      associated meta data, int label (N, 1)\n",
    "    \"\"\"\n",
    "    images, labels = [], []\n",
    "\n",
    "    # Open the HDF5 file\n",
    "    file = h5py.File(hdf5_dir / f\"{video_clip_title}.h5\", \"r+\")\n",
    "\n",
    "    images = np.array(file[\"/images\"]).astype(\"uint8\")\n",
    "    labels = np.array(file[\"/meta\"]).astype(\"uint8\")\n",
    "\n",
    "    yield images #, labels\n",
    "    \n",
    "def read_labels_hdf5(video_clip_title):\n",
    "    \"\"\" Reads image from HDF5.\n",
    "        Parameters:\n",
    "        ---------------\n",
    "        num_images   number of images to read\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        images      images array, (N, 32, 32, 3) to be stored\n",
    "        labels      associated meta data, int label (N, 1)\n",
    "    \"\"\"\n",
    "    images, labels = [], []\n",
    "\n",
    "    # Open the HDF5 file\n",
    "    file = h5py.File(hdf5_dir / f\"{video_clip_title}.h5\", \"r+\")\n",
    "\n",
    "    images = np.array(file[\"/images\"]).astype(\"uint8\")\n",
    "    labels = np.array(file[\"/meta\"]).astype(\"uint8\")\n",
    "\n",
    "    return labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0ba9bb8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#load dataset in\n",
    "data = pd.read_csv(workspace_path + '/downloaded_videos.csv')\n",
    "y = data.pop('relevant')\n",
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dc08028",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"feature_extractor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " vgg19 (Functional)          (None, 512)               20024384  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#when we limit GPU memory growth,feature extractor takes up 700MiB / 16160MiB\n",
    "#instead of 15096MiB / 16160MiB, which nearly exhausts all our GPU memory on GPU 0\n",
    "from cnn import CNN\n",
    "\n",
    "ConvNet = CNN(224)\n",
    "feature_extractor = ConvNet.VGG19()\n",
    "\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00a8602e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 19:59:26.058640: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2022-07-29 19:59:27.127316: I tensorflow/stream_executor/cuda/cuda_dnn.cc:379] Loaded cuDNN version 8400\n",
      "2022-07-29 19:59:28.305819: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "Done loading frames in 403.59353852272034 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(364, 461, 512)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_names = [video.replace(\"_\", \"_clip_\").replace(\".mp4\", \"\") for video in list(X.renamed_title)]\n",
    "frames = [read_frames_hdf5(clip) for clip in clip_names]\n",
    "\n",
    "N = 364\n",
    "features = np.empty((N, 461, 512), dtype=np.float32)\n",
    "i = 0\n",
    "start = time.time()\n",
    "for frame_batch in frames:\n",
    "    features[i, ...] = feature_extractor.predict_on_batch(next(iter(frame_batch)))\n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "    i +=1\n",
    "\n",
    "stop = time.time()\n",
    "print(f'Done loading frames in {stop-start} seconds.')\n",
    "features.shape\n",
    "# frames = read_frames_hdf5('video_clip_0001')\n",
    "# res = feature_extractor.predict_on_batch(next(iter(frames)))\n",
    "# # res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0c8b2ed",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# labels = np.empty(N, dtype = np.uint8)\n",
    "labels = [read_labels_hdf5(clip) for clip in clip_names]\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c00ad26f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364,)\n",
      "(364, 461, 512)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4830eff2",
   "metadata": {},
   "source": [
    "## Distributed Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a21db22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading frames for video 0...\n",
      "Loading frames for video 50...\n",
      "Loading frames for video 100...\n",
      "Loading frames for video 150...\n",
      "Loading frames for video 200...\n",
      "Loading frames for video 250...\n",
      "Loading frames for video 300...\n",
      "Loading frames for video 350...\n",
      "Done loading frames in 103.13946032524109 seconds.\n",
      "(364, 461, 224, 224, 3)\n",
      "(364,)\n"
     ]
    }
   ],
   "source": [
    "#load dataset in\n",
    "data = pd.read_csv(workspace_path + '/downloaded_videos.csv')\n",
    "y = data.pop('relevant')\n",
    "X = data\n",
    "\n",
    "#load in frames for all videos\n",
    "start = time.time()\n",
    "\n",
    "N = X.shape[0] #number of videos in our dataset\n",
    "videos = np.empty((N, 461, 224, 224, 3), dtype=np.float32)\n",
    "labels = np.empty(N, dtype = np.uint8)\n",
    "\n",
    "for i, video in enumerate(list(X.renamed_title)):\n",
    "    if i % 50 == 0:\n",
    "        print(f'Loading frames for video {i}...')\n",
    "        \n",
    "    clip_name = video.replace(\"_\", \"_clip_\").replace(\".mp4\", \"\")\n",
    "    frames, frame_labels = read_frames_hdf5(clip_name) #returns frames array of shape (461, 224, 224, 3)\n",
    "    \n",
    "    videos[i, ...] = frames\n",
    "    labels[i] = frame_labels[0] #all frames have the same label since label is assigned to overall video\n",
    "\n",
    "stop = time.time()\n",
    "print(f'Done loading frames in {stop-start} seconds.')\n",
    "print(videos.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ff2a648",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 18:33:40.195592: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 101036802048 exceeds 10% of free system memory.\n",
      "2022-07-31 18:35:06.494314: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 101036802048 exceeds 10% of free system memory.\n",
      "2022-07-31 18:37:46.916193: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_UINT8\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 364\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\024TensorSliceDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 461\n",
      "        }\n",
      "        dim {\n",
      "          size: 224\n",
      "        }\n",
      "        dim {\n",
      "          size: 224\n",
      "        }\n",
      "        dim {\n",
      "          size: 3\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy(['/GPU:0', '/GPU:1'])\n",
    "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Batch the input data\n",
    "BUFFER_SIZE = videos.shape[0]\n",
    "BATCH_SIZE_PER_REPLICA = 1\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "\n",
    "# Create Datasets from the batches\n",
    "with tf.device(\"/device:CPU:0\"):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((videos, labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(1)\n",
    "\n",
    "# Create Distributed Datasets from the datasets\n",
    "dist_dataset = strategy.experimental_distribute_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588397b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "# Create the model architecture\n",
    "def create_model():\n",
    "    feature_extractor = keras.applications.ResNet101(\n",
    "                                                        weights      = 'imagenet',\n",
    "                                                        include_top  = False,\n",
    "                                                        pooling      = 'avg',\n",
    "                                                        input_shape  = (224, 224, 3)\n",
    "                                                    )\n",
    "\n",
    "    preprocess_input = keras.applications.resnet.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((224, 224, 3)) #try making this 461, 224, 224, 3\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "# Instead of model.compile, we're going to do custom training, so let's do that\n",
    "# within a strategy scope\n",
    "# Create the model within the scope\n",
    "with strategy.scope():\n",
    "    model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99753dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = videos[0]\n",
    "# t = t[None, ...]\n",
    "# t.shape\n",
    "\n",
    "# tf.squeeze(t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7055006e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 18:27:33.172471: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 101036802048 exceeds 10% of free system memory.\n",
      "Process wandb_internal:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/internal/internal.py\", line 160, in wandb_internal\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/spawn.py\", line 129, in _main\n",
      "    return self._bootstrap(parent_sentinel)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 333, in _bootstrap\n",
      "    threading._shutdown()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1388, in _shutdown\n",
      "    lock.acquire()\n",
      "KeyboardInterrupt\n",
      "Exception in thread NetStatThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py\", line 152, in check_network_status\n",
      "    status_response = self._interface.communicate_network_status()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/interface/interface.py\", line 138, in communicate_network_status\n",
      "    resp = self._communicate_network_status(status)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/interface/interface_shared.py\", line 405, in _communicate_network_status\n",
      "    resp = self._communicate(req, local=True)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/interface/interface_shared.py\", line 226, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/interface/interface_shared.py\", line 231, in _communicate_async\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n",
      "Exception in thread ChkStopThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py\", line 170, in check_status\n",
      "    status_response = self._interface.communicate_stop_status()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/interface/interface.py\", line 127, in communicate_stop_status\n",
      "    resp = self._communicate_stop_status(status)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/interface/interface_shared.py\", line 395, in _communicate_stop_status\n",
      "    resp = self._communicate(req, local=True)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/interface/interface_shared.py\", line 226, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/interface/interface_shared.py\", line 231, in _communicate_async\n",
      "    raise Exception(\"The wandb backend process has shutdown\")\n",
      "Exception: The wandb backend process has shutdown\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m###############\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Feature Loop \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m###############\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dist_dataset:\n\u001b[1;32m      6\u001b[0m     distributed_test_step(batch)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/input_lib.py:1180\u001b[0m, in \u001b[0;36mDistributedDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1174\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use this dataset, you need to pass this dataset to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1175\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClusterCoordinator.create_per_worker_dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1177\u001b[0m canonicalize_devices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_canonicalize_devices\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1178\u001b[0m                                \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1180\u001b[0m worker_iterators \u001b[38;5;241m=\u001b[39m \u001b[43m_create_iterators_per_worker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cloned_datasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcanonicalize_devices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcanonicalize_devices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m iterator \u001b[38;5;241m=\u001b[39m DistributedIterator(\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_workers,\n\u001b[1;32m   1187\u001b[0m     worker_iterators,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     enable_get_next_as_optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_get_next_as_optional,\n\u001b[1;32m   1191\u001b[0m     options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n\u001b[1;32m   1192\u001b[0m iterator\u001b[38;5;241m.\u001b[39m_element_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/input_lib.py:1819\u001b[0m, in \u001b[0;36m_create_iterators_per_worker\u001b[0;34m(worker_datasets, input_workers, options, canonicalize_devices)\u001b[0m\n\u001b[1;32m   1817\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(worker):\n\u001b[1;32m   1818\u001b[0m     worker_devices \u001b[38;5;241m=\u001b[39m input_workers\u001b[38;5;241m.\u001b[39mcompute_devices_for_worker(i)\n\u001b[0;32m-> 1819\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[43m_SingleWorkerOwnedDatasetIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1820\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworker_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1821\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1822\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworker_devices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1823\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcanonicalize_devices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcanonicalize_devices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1825\u001b[0m     iterators\u001b[38;5;241m.\u001b[39mappend(iterator)\n\u001b[1;32m   1826\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m iterators\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/input_lib.py:1723\u001b[0m, in \u001b[0;36m_SingleWorkerOwnedDatasetIterator.__init__\u001b[0;34m(self, dataset, worker, devices, components, element_spec, options, canonicalize_devices)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1722\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_message)\n\u001b[0;32m-> 1723\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_SingleWorkerOwnedDatasetIterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/input_lib.py:1547\u001b[0m, in \u001b[0;36m_SingleWorkerDatasetIteratorBase.__init__\u001b[0;34m(self, dataset, worker, devices, options)\u001b[0m\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39melement_spec\n\u001b[1;32m   1546\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options \u001b[38;5;241m=\u001b[39m options\n\u001b[0;32m-> 1547\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/input_lib.py:1754\u001b[0m, in \u001b[0;36m_SingleWorkerOwnedDatasetIterator._make_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1751\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorker device must be specified when creating an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1752\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mowned iterator.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_use_multi_device_iterator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options):\n\u001b[0;32m-> 1754\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_owned_multi_device_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/input_lib.py:1745\u001b[0m, in \u001b[0;36m_SingleWorkerOwnedDatasetIterator._create_owned_multi_device_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1736\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m multi_device_iterator_ops\u001b[38;5;241m.\u001b[39mOwnedMultiDeviceIterator(\n\u001b[1;32m   1737\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset,\n\u001b[1;32m   1738\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_devices,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1742\u001b[0m       prefetch_buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options\n\u001b[1;32m   1743\u001b[0m       \u001b[38;5;241m.\u001b[39mexperimental_per_replica_buffer_size)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_device_iterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedMultiDeviceIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_devices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:536\u001b[0m, in \u001b[0;36mOwnedMultiDeviceIterator.__init__\u001b[0;34m(self, dataset, devices, max_buffer_size, prefetch_buffer_size, source_device, components, element_spec)\u001b[0m\n\u001b[1;32m    530\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_device_iterator_resource, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deleter \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    531\u001b[0m       gen_dataset_ops\u001b[38;5;241m.\u001b[39manonymous_multi_device_iterator(\n\u001b[1;32m    532\u001b[0m           devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_devices, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset\u001b[38;5;241m.\u001b[39m_flat_structure))  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    534\u001b[0m   \u001b[38;5;66;03m# The incarnation ID is used to ensure consistency between the\u001b[39;00m\n\u001b[1;32m    535\u001b[0m   \u001b[38;5;66;03m# per-device iterators and the multi-device iterator.\u001b[39;00m\n\u001b[0;32m--> 536\u001b[0m   incarnation_id \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_device_iterator_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    538\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_multi_device_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_buffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_buffer_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m prototype_device_datasets \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, device \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_devices):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py:4014\u001b[0m, in \u001b[0;36mmulti_device_iterator_init\u001b[0;34m(dataset, multi_device_iterator, max_buffer_size, name)\u001b[0m\n\u001b[1;32m   4012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   4013\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4014\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4015\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMultiDeviceIteratorInit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_device_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4016\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_buffer_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   4018\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x7fc608d16040> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/backcall/backcall.py:104\u001b[0m, in \u001b[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 kwargs\u001b[38;5;241m.\u001b[39mpop(name)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_init.py:379\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    377\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mlog_code(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    378\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved code: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, res)\n\u001b[0;32m--> 379\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/wandb/sdk/interface/interface.py:609\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 609\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/wandb/sdk/interface/interface_shared.py:279\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/wandb/sdk/interface/interface_queue.py:49\u001b[0m, in \u001b[0;36mInterfaceQueue._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_check \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m---> 49\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe wandb backend process has shutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local:\n\u001b[1;32m     51\u001b[0m         record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mlocal \u001b[38;5;241m=\u001b[39m local\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# Test Steps Functions\n",
    "#######################\n",
    "@tf.function\n",
    "def distributed_test_step(dataset_inputs):\n",
    "    return strategy.run(test_step, args=(dataset_inputs,)) #invoke function on each replica\n",
    "\n",
    "def test_step(inputs):\n",
    "    images, labels = inputs\n",
    "    predictions = model(tf.squeeze(images), training=False)\n",
    "    \n",
    "###############\n",
    "# Feature Loop \n",
    "###############\n",
    "\n",
    "for batch in dist_dataset:\n",
    "    distributed_test_step(batch)\n",
    "#     frames, labels = batch\n",
    "#     predictions = model.predict_on_batch(frames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b49916",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b796ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "train_index = list(X_train.index)\n",
    "test_index = list(X_test.index)\n",
    "\n",
    "train_features, train_labels = features[train_index], labels[train_index]\n",
    "test_features, test_labels = features[test_index], labels[test_index]\n",
    "\n",
    "train_labels = np.reshape(train_labels, (train_labels.shape[0], 1))\n",
    "test_labels = np.reshape(test_labels, (test_labels.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29513bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 461, 512)\n",
      "(73, 461, 512)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc27f37",
   "metadata": {},
   "source": [
    "## Train RNN Model with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a450af21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9fd60cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import backend as K\n",
    "\n",
    "class attention(Layer):\n",
    "    def __init__(self, return_sequences=True):\n",
    "        self.return_sequences = return_sequences\n",
    "\n",
    "        super(attention,self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1), initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1), initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1))\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1))\n",
    "\n",
    "        super(attention,self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x*a\n",
    "        if self.return_sequences:\n",
    "            return output\n",
    "        \n",
    "        return K.sum(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dd416ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8/8 [==============================] - 12s 446ms/step - loss: 0.7062 - accuracy: 0.6207 - val_loss: 0.5372 - val_accuracy: 0.7288\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 1s 137ms/step - loss: 0.4535 - accuracy: 0.8017 - val_loss: 0.4359 - val_accuracy: 0.8305\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 1s 133ms/step - loss: 0.2726 - accuracy: 0.8879 - val_loss: 0.4562 - val_accuracy: 0.7966\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 1s 133ms/step - loss: 0.1724 - accuracy: 0.9310 - val_loss: 0.4946 - val_accuracy: 0.7966\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 1s 134ms/step - loss: 0.1898 - accuracy: 0.9224 - val_loss: 0.5141 - val_accuracy: 0.7797\n",
      "Done training.\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.4998 - accuracy: 0.7123\n",
      "Test Metrics - Loss: 0.49980178475379944, Accuracy: 0.7123287916183472\n"
     ]
    }
   ],
   "source": [
    "# recurrent_dropout does not allow training to use cuDNN kernel\n",
    "features_input       = keras.Input((461, 512))\n",
    "x                    = keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True))(features_input)\n",
    "x                    = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True))(x)\n",
    "x                    = attention(return_sequences=False)(x)\n",
    "x                    = Dropout(0.2)(x)\n",
    "output               = keras.layers.Dense(2, activation=\"softmax\")(x) #2 bc 2 class categories (0,1)\n",
    "model                = keras.Model(features_input, output)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "my_callbacks    = [keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", \n",
    "                                                 patience=3,\n",
    "                                                 mode=\"max\",\n",
    "                                                 min_delta = 0.01,\n",
    "                                                 restore_best_weights=True)]\n",
    "history = model.fit(train_features, \n",
    "                    train_labels,\n",
    "                    validation_split = 0.2,\n",
    "                    epochs = 15,\n",
    "                    callbacks = my_callbacks,\n",
    "                    verbose= 1)\n",
    "\n",
    "print('Done training.')\n",
    "\n",
    "loss, accuracy = model.evaluate(test_features, test_labels)\n",
    "print(f\"Test Metrics - Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bd42c",
   "metadata": {},
   "source": [
    "## Trying to Distribute Data + Run RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c61a1b73",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 23:17:29.071859: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_UINT8\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 291\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\027TensorSliceDataset:1273\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 461\n",
      "        }\n",
      "        dim {\n",
      "          size: 2048\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# global_batch_size = 91*4\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).batch(global_batch_size)\n",
    "# dist_dataset = strategy.experimental_distribute_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccfe6e0c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:3',)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 18:52:09.461372: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_438939\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\023FlatMapDataset:1215\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 24s 168ms/step - loss: 0.6002 - accuracy: 0.6838\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 156ms/step - loss: 0.4380 - accuracy: 0.8144\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 158ms/step - loss: 0.3579 - accuracy: 0.8385\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 159ms/step - loss: 0.2598 - accuracy: 0.8969\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 161ms/step - loss: 0.1619 - accuracy: 0.9450\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 161ms/step - loss: 0.1263 - accuracy: 0.9553\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 163ms/step - loss: 0.0747 - accuracy: 0.9759\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 162ms/step - loss: 0.0464 - accuracy: 0.9828\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.1414 - accuracy: 0.9416\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0721 - accuracy: 0.9794\n",
      "Done training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 18:52:48.197125: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_456275\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\023FlatMapDataset:1266\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 6s 79ms/step - loss: 0.6300 - accuracy: 0.8082\n",
      "Test Metrics - Loss: 0.6300287246704102, Accuracy: 0.8082191944122314\n"
     ]
    }
   ],
   "source": [
    "#training runs successfully when we specify just the first 3 GPUs (IDs 0,1,2)\n",
    "#once we add in GPU:3, we get a CUDNN_STATUS_BAD_PARAM error\n",
    "strategy = tf.distribute.MirroredStrategy(['/GPU:3'])\n",
    "\n",
    "with strategy.scope():\n",
    "    features_input       = keras.Input((461, 2048))\n",
    "    x                    = keras.layers.Bidirectional(keras.layers.LSTM(32, return_sequences=True))(features_input)\n",
    "    x                    = keras.layers.Bidirectional(keras.layers.LSTM(32, return_sequences=True))(x)\n",
    "    x                    = keras.layers.Bidirectional(keras.layers.LSTM(32, return_sequences=True))(x)\n",
    "    x                    = keras.layers.Bidirectional(keras.layers.LSTM(32))(x)\n",
    "\n",
    "    output               = keras.layers.Dense(2, activation=\"softmax\")(x) #2 bc 2 class categories (0,1)\n",
    "    model                = keras.Model(features_input, output)\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(train_features,\n",
    "                    train_labels,\n",
    "                    epochs = 10,\n",
    "                    verbose= 1)\n",
    "\n",
    "print('Done training.')\n",
    "\n",
    "loss, accuracy = model.evaluate(test_features, test_labels)\n",
    "print(f\"Test Metrics - Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747065c7",
   "metadata": {},
   "source": [
    "## Coursera Multi-GPU Strategy\n",
    "Resources\n",
    "- https://www.coursera.org/learn/custom-distributed-training-with-tensorflow/lecture/21zgD/multi-gpu-mirrored-strategy-code-walkthrough\n",
    "- https://github.com/y33-j3T/Coursera-Deep-Learning/blob/master/Custom%20and%20Distributed%20Training%20with%20Tensorflow/Week%204%20-%20Distributed%20Training/C2_W4_Lab_2_multi-GPU-mirrored-strategy.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639abffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c31335e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n",
      "Number of devices: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 16:44:02.293794: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_UINT8\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 291\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\026TensorSliceDataset:856\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 461\n",
      "        }\n",
      "        dim {\n",
      "          size: 2048\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 16:44:02.614581: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_UINT8\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 73\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\026TensorSliceDataset:859\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 461\n",
      "        }\n",
      "        dim {\n",
      "          size: 2048\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(32,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "Tensor(\"replica_1/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(32,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "Tensor(\"replica_2/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(32,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:2)\n",
      "Tensor(\"replica_3/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(32,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "# Note that it generally has a minimum of 8 cores, but if your GPU has\n",
    "# less, you need to set this. In this case one of my GPUs has 4 cores\n",
    "# os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"] = \"4\"\n",
    "\n",
    "# If the list of devices is not specified in the\n",
    "# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\n",
    "# If you have *different* GPUs in your system, you probably have to set up cross_device_ops like this\n",
    "# strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "strategy = tf.distribute.MirroredStrategy(['/GPU:0', '/GPU:1', '/GPU:2', '/GPU:3', '/GPU:4', '/GPU:5', '/GPU:6', '/GPU:7'])\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Batch the input data\n",
    "BUFFER_SIZE_TRAIN = train_features.shape[0]\n",
    "BUFFER_SIZE_TEST = test_features.shape[0]\n",
    "BATCH_SIZE_PER_REPLICA = 32\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "\n",
    "# Create Datasets from the batches\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).shuffle(BUFFER_SIZE_TRAIN).batch(GLOBAL_BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_features, test_labels)).shuffle(BUFFER_SIZE_TEST).batch(GLOBAL_BATCH_SIZE)\n",
    "\n",
    "train_dataset = train_dataset.prefetch(1)\n",
    "test_dataset = test_dataset.prefetch(1)\n",
    "\n",
    "# Create Distributed Datasets from the datasets\n",
    "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)\n",
    "\n",
    "# Create the model architecture\n",
    "def create_model():\n",
    "#     features_input       = keras.Input((461, 2048))\n",
    "#     x                    = keras.layers.Bidirectional(keras.layers.LSTM(32, return_sequences=True, recurrent_dropout=0.1, unroll=True))(features_input)\n",
    "#     x                    = keras.layers.Bidirectional(keras.layers.LSTM(32, recurrent_dropout=0.1, unroll=True))(x)\n",
    "\n",
    "#     output               = keras.layers.Dense(2)(x) #2 bc 2 class categories (0,1)\n",
    "#     model                = keras.Model(features_input, output)\n",
    "#     return model\n",
    "\n",
    "    features_input       = keras.Input((461, 2048))\n",
    "    x                    = keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True))(features_input)\n",
    "    x                    = keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True))(x)\n",
    "    x                    = attention(return_sequences=False)(x)\n",
    "    x                    = Dropout(0.2)(x)\n",
    "    output               = keras.layers.Dense(2, activation=\"softmax\")(x) #2 bc 2 class categories (0,1)\n",
    "    model                = keras.Model(features_input, output)\n",
    "    return model\n",
    "\n",
    "# Instead of model.compile, we're going to do custom training, so let's do that\n",
    "# within a strategy scope\n",
    "with strategy.scope():\n",
    "\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "    def compute_loss(labels, predictions):\n",
    "        per_example_loss = loss_object(labels, predictions)\n",
    "        print(per_example_loss)\n",
    "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
    "\n",
    "    # We'll just reduce by getting the average of the losses\n",
    "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "\n",
    "    # Accuracy on train and test will be SparseCategoricalAccuracy\n",
    "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "    # Optimizer will be Adam\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    # Create the model within the scope\n",
    "    model = create_model()\n",
    "\n",
    "\n",
    "###########################\n",
    "# Training Steps Functions\n",
    "###########################\n",
    "\n",
    "# `run` replicates the provided computation and runs it\n",
    "# with the distributed input.\n",
    "@tf.function\n",
    "def distributed_train_step(dataset_inputs):\n",
    "    per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n",
    "    #tf.print(per_replica_losses.values)\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "\n",
    "def train_step(inputs):\n",
    "    images, labels = inputs\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = compute_loss(labels, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_accuracy.update_state(labels, predictions)\n",
    "    return loss\n",
    "\n",
    "#######################\n",
    "# Test Steps Functions\n",
    "#######################\n",
    "@tf.function\n",
    "def distributed_test_step(dataset_inputs):\n",
    "    return strategy.run(test_step, args=(dataset_inputs,))\n",
    "\n",
    "def test_step(inputs):\n",
    "    images, labels = inputs\n",
    "\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss.update_state(t_loss)\n",
    "    test_accuracy.update_state(labels, predictions)\n",
    "\n",
    "\n",
    "###############\n",
    "# TRAINING LOOP\n",
    "###############\n",
    "\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    # Do Training\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for batch in train_dist_dataset:\n",
    "        total_loss += distributed_train_step(batch)\n",
    "        num_batches += 1\n",
    "    train_loss = total_loss / num_batches\n",
    "\n",
    "    # Do Testing\n",
    "    for batch in test_dist_dataset:\n",
    "        distributed_test_step(batch)\n",
    "\n",
    "    template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \" \"Test Accuracy: {}\")\n",
    "\n",
    "    print (template.format(epoch+1, train_loss, train_accuracy.result()*100, test_loss.result(), test_accuracy.result()*100))\n",
    "\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194a21c1",
   "metadata": {},
   "source": [
    "## WandB Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "505442cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Logging WandB metrics.\n"
     ]
    }
   ],
   "source": [
    "#log training and validation metrics on wandb\n",
    "for epoch, train_loss in enumerate(history.history['loss']):\n",
    "    wandb.log({'training_loss': train_loss, \"epoch\": epoch})\n",
    "    \n",
    "for epoch, train_acc in enumerate(history.history['accuracy']):\n",
    "    wandb.log({'training_accuracy': train_acc, \"epoch\": epoch})\n",
    "    \n",
    "for epoch, val_loss in enumerate(history.history['val_loss']):\n",
    "    wandb.log({'val_loss': val_loss, \"epoch\": epoch})\n",
    "    \n",
    "for epoch, val_acc in enumerate(history.history['val_accuracy']):\n",
    "    wandb.log({'val_accuracy': val_acc, \"epoch\": epoch})\n",
    "    \n",
    "print('Done Logging WandB metrics.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f34cde61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">helpful-dream-34</strong>: <a href=\"https://wandb.ai/epg/whale-classification-inception/runs/3dnifiv1\" target=\"_blank\">https://wandb.ai/epg/whale-classification-inception/runs/3dnifiv1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220727_135824-3dnifiv1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
