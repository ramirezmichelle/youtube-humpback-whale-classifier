{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5da070c",
   "metadata": {},
   "source": [
    "# TF Distribute Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccac70d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a6d6b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a788fb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmicheller\u001b[0m (\u001b[33mepg\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/youtube-humpback-whale-classifier/classification/wandb/run-20220713_162111-24ha9jps</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/epg/whale-classification-inception/runs/24ha9jps\" target=\"_blank\">young-dragon-11</a></strong> to <a href=\"https://wandb.ai/epg/whale-classification-inception\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "#start wandb session for metric logging\n",
    "wandb.login() \n",
    "\n",
    "wandb.init(project=\"whale-classification-inception\")\n",
    "\n",
    "wandb.run.name = \"tf-distributed-tutorial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51962454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngc workspace path (where we keep our data)\n",
    "workspace_path = '/mount/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec6e1b",
   "metadata": {},
   "source": [
    "## Mirrored Strategy Example\n",
    "https://www.tensorflow.org/tutorials/distribute/keras\n",
    "\n",
    "https://keras.io/guides/distributed_training/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a294c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.8/dist-packages (3.2.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (3.17.3)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (4.64.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (1.21.1)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (21.4.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (1.12.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (1.15.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (0.12.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (0.18.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (0.3.4)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (1.7.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2021.10.8)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.56.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a726a423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5cf949",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c3db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, info = tensorflow_datasets.load(name='mnist', with_info=True, as_supervised=True)\n",
    "\n",
    "mnist_train, mnist_test = datasets['train'], datasets['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506a7234",
   "metadata": {},
   "source": [
    "### Define Distribution Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3198b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfad3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2ec62b",
   "metadata": {},
   "source": [
    "### Set the Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also do info.splits.total_num_examples to get the total\n",
    "# number of examples in the dataset.\n",
    "\n",
    "num_train_examples = info.splits['train'].num_examples\n",
    "num_test_examples = info.splits['test'].num_examples\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7add68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image /= 255\n",
    "\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc01ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7720df15",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a63109",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(10)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d393bd",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09292b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint directory to store the checkpoints.\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Define the name of the checkpoint files.\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9714f76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for decaying the learning rate.\n",
    "# You can define any decay function you need.\n",
    "def decay(epoch):\n",
    "  if epoch < 3:\n",
    "    return 1e-3\n",
    "  elif epoch >= 3 and epoch < 7:\n",
    "    return 1e-4\n",
    "  else:\n",
    "    return 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7384bdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a callback for printing the learning rate at the end of each epoch.\n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('\\nLearning rate for epoch {} is {}'.format(        epoch + 1, model.optimizer.lr.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ad109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the callbacks together.\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "                                       save_weights_only=True),\n",
    "    tf.keras.callbacks.LearningRateScheduler(decay),\n",
    "    PrintLR()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fde8cb",
   "metadata": {},
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa220436",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 12\n",
    "\n",
    "model.fit(train_dataset, epochs=EPOCHS, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1887eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the checkpoint directory.\n",
    "!ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e72cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "eval_loss, eval_acc = model.evaluate(eval_dataset)\n",
    "\n",
    "print('Eval loss: {}, Eval accuracy: {}'.format(eval_loss, eval_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
