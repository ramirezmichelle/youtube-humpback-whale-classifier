{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f495d93",
   "metadata": {},
   "source": [
    "# Implementing C3D Model for Video Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908a4f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import pickle\n",
    "import glob\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import seaborn as sns\n",
    "\n",
    " \n",
    "# adding video-download folder to the system path\n",
    "sys.path.insert(0, '/workspace/youtube-humpback-whale-classifier/video-download')\n",
    " \n",
    "# importing read_frames_hdf5 function\n",
    "from hdf5_data_loading import read_frames_hdf5\n",
    "\n",
    "#ngc workspace path (where we keep our data)\n",
    "workspace_path = '/mount/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c2c267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "\n",
    "# #start wandb session for metric logging\n",
    "# wandb.login() \n",
    "\n",
    "# wandb.init(project=\"whale-classification-inception\")\n",
    "\n",
    "# wandb.run.name = \"resnet-data-distribution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed4ba7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs available:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs available: \", len(tf.config.list_physical_devices('GPU'))) #1 if we select GPU mode in Colab Notebook, 0 if running on local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2773de0e",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d478b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset in\n",
    "data = pd.read_csv(workspace_path + '/downloaded_videos.csv')\n",
    "y = data.pop('relevant')\n",
    "X = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f6319",
   "metadata": {},
   "source": [
    "## Load Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a91e6ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading frames for video 0...\n",
      "Loading frames for video 50...\n",
      "Loading frames for video 100...\n",
      "Loading frames for video 150...\n",
      "Loading frames for video 200...\n",
      "Loading frames for video 250...\n",
      "Loading frames for video 300...\n",
      "Loading frames for video 350...\n",
      "Done loading frames in 111.9125657081604 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(364, 30, 224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in frames for all videos\n",
    "start = time.time()\n",
    "\n",
    "N = X.shape[0] #number of videos in our dataset\n",
    "videos = np.empty((N, 30, 224, 224, 3), dtype=np.uint8)\n",
    "labels = np.empty(N, dtype = np.uint8)\n",
    "\n",
    "for i, video in enumerate(list(X.renamed_title)):\n",
    "    if i % 50 == 0:\n",
    "        print(f'Loading frames for video {i}...')\n",
    "        \n",
    "    clip_name = video.replace(\"_\", \"_clip_\").replace(\".mp4\", \"\")\n",
    "    frames, frame_labels = read_frames_hdf5(clip_name) #returns frames array of shape (461, 224, 224, 3)\n",
    "    \n",
    "    videos[i, ...] = frames[15:45] #shortened videos bc of memory issue - each video is reduced to 30 frames\n",
    "    labels[i] = frame_labels[0] #all frames have the same label since label is assigned to overall video\n",
    "\n",
    "stop = time.time()\n",
    "print(f'Done loading frames in {stop-start} seconds.')\n",
    "videos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea406577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # videos[0][15:45].shape\n",
    "\n",
    "# short_videos = np.empty((364, 30, 224, 224, 3), dtype=np.uint8)\n",
    "# for i in range(364):\n",
    "#     short_videos[i, ...] = videos[i][15:45]\n",
    "# short_videos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056e75ea",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a43927dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "train_index = list(X_train.index)\n",
    "test_index = list(X_test.index)\n",
    "\n",
    "# index data accordingly\n",
    "train_videos, train_labels = videos[train_index], labels[train_index]\n",
    "test_videos, test_labels = videos[test_index], labels[test_index]\n",
    "\n",
    "# reshape label arrays as horizontal arrays\n",
    "train_labels = np.reshape(train_labels, (train_labels.shape[0], 1))\n",
    "test_labels = np.reshape(test_labels, (test_labels.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "314fd298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 30, 224, 224, 3)\n",
      "(73, 30, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_videos.shape)\n",
    "print(test_videos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1d29506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "291/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba9c418",
   "metadata": {},
   "source": [
    "## Converting Data into TF Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37a330c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 15:14:48.739529: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-25 15:14:52.165608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14649 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:85:00.0, compute capability: 7.0\n",
      "2022-07-25 15:14:52.167792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14649 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:86:00.0, compute capability: 7.0\n",
      "2022-07-25 15:14:52.169766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14649 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:89:00.0, compute capability: 7.0\n",
      "2022-07-25 15:14:52.171784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14649 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "train_tf = tf.data.Dataset.from_tensor_slices((train_videos, train_labels)).batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e442fc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 30, 224, 224, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(None, 1), dtype=tf.uint8, name=None))>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16df316",
   "metadata": {},
   "source": [
    "## Build C3D Video Classification Model\n",
    "\n",
    "Resources\n",
    "- https://towardsdatascience.com/step-by-step-implementation-3d-convolutional-neural-network-in-keras-12efbdd7b130\n",
    "- https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7410867&tag=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48f0d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "# print(os.getenv('TF_GPU_ALLOCATOR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bc8c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization\n",
    "# from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84c5ed7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 15:15:11.794184: I tensorflow/stream_executor/cuda/cuda_dnn.cc:379] Loaded cuDNN version 8400\n",
      "2022-07-25 15:15:16.788252: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-25 15:15:16.788360: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2022-07-25 15:15:36.523621: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.75GiB (rounded to 2954391552)requested by op model/conv3d_3/Conv3D\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-07-25 15:15:36.523711: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
      "2022-07-25 15:15:36.523737: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 48, Chunks in use: 47. 12.0KiB allocated for chunks. 11.8KiB in use in bin. 1013B client-requested in use in bin.\n",
      "2022-07-25 15:15:36.523752: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 4, Chunks in use: 4. 2.0KiB allocated for chunks. 2.0KiB in use in bin. 1.8KiB client-requested in use in bin.\n",
      "2022-07-25 15:15:36.523766: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 7, Chunks in use: 7. 7.2KiB allocated for chunks. 7.2KiB in use in bin. 7.0KiB client-requested in use in bin.\n",
      "2022-07-25 15:15:36.523780: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 12, Chunks in use: 12. 24.0KiB allocated for chunks. 24.0KiB in use in bin. 24.0KiB client-requested in use in bin.\n",
      "2022-07-25 15:15:36.523793: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-25 15:15:36.523805: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-25 15:15:36.523846: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 9, Chunks in use: 9. 167.5KiB allocated for chunks. 167.5KiB in use in bin. 156.8KiB client-requested in use in bin.\n",
      "2022-07-25 15:15:36.523861: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-25 15:15:36.523873: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-25 15:15:36.523886: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-25 15:15:36.523898: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-25 15:15:36.523911: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 2, Chunks in use: 2. 1.69MiB allocated for chunks. 1.69MiB in use in bin. 1.69MiB client-requested in use in bin.\n",
      "2022-07-25 15:15:36.523925: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 1. 1.65MiB allocated for chunks. 1.65MiB in use in bin. 864.0KiB client-requested in use in bin.\n",
      "2022-07-25 15:15:36.523939: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 1, Chunks in use: 1. 3.38MiB allocated for chunks. 3.38MiB in use in bin. 3.38MiB client-requested in use in bin.\n",
      "2022-07-25 15:15:36.523953: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 4, Chunks in use: 4. 26.09MiB allocated for chunks. 26.09MiB in use in bin. 20.25MiB client-requested in use in bin.\n",
      "2022-07-25 15:15:36.523968: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 9, Chunks in use: 7. 108.09MiB allocated for chunks. 82.25MiB in use in bin. 71.25MiB client-requested in use in bin.\n",
      "2022-07-25 15:15:36.523983: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 8, Chunks in use: 8. 216.00MiB allocated for chunks. 216.00MiB in use in bin. 216.00MiB client-requested in use in bin.\n",
      "2022-07-25 15:15:36.523998: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 2, Chunks in use: 2. 85.18MiB allocated for chunks. 85.18MiB in use in bin. 78.68MiB client-requested in use in bin.\n",
      "2022-07-25 15:15:36.524016: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 3, Chunks in use: 3. 192.00MiB allocated for chunks. 192.00MiB in use in bin. 192.00MiB client-requested in use in bin.\n",
      "2022-07-25 15:15:36.524029: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-25 15:15:36.524044: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 9, Chunks in use: 7. 13.69GiB allocated for chunks. 10.73GiB in use in bin. 10.72GiB client-requested in use in bin.\n",
      "2022-07-25 15:15:36.524057: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 2.75GiB was 256.00MiB, Chunk State: \n",
      "2022-07-25 15:15:36.524077: I tensorflow/core/common_runtime/bfc_allocator.cc:1039]   Size: 1.17GiB | Requested Size: 21.99MiB | in_use: 0 | bin_num: 20, prev:   Size: 3.07GiB | Requested Size: 3.07GiB | in_use: 1 | bin_num: -1\n",
      "2022-07-25 15:15:36.524119: I tensorflow/core/common_runtime/bfc_allocator.cc:1039]   Size: 1.78GiB | Requested Size: 1.70GiB | in_use: 0 | bin_num: 20, prev:   Size: 1001.62MiB | Requested Size: 1001.62MiB | in_use: 1 | bin_num: -1, next:   Size: 1.78GiB | Requested Size: 1.78GiB | in_use: 1 | bin_num: -1\n",
      "2022-07-25 15:15:36.524131: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 15361376256\n",
      "2022-07-25 15:15:36.524146: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef2f8000000 of size 1314109440 next 1\n",
      "2022-07-25 15:15:36.524157: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653b800 of size 1280 next 2\n",
      "2022-07-25 15:15:36.524167: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653bd00 of size 512 next 3\n",
      "2022-07-25 15:15:36.524177: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653bf00 of size 256 next 4\n",
      "2022-07-25 15:15:36.524188: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c000 of size 256 next 5\n",
      "2022-07-25 15:15:36.524198: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c100 of size 256 next 6\n",
      "2022-07-25 15:15:36.524208: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c200 of size 256 next 7\n",
      "2022-07-25 15:15:36.524218: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c300 of size 256 next 8\n",
      "2022-07-25 15:15:36.524228: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c400 of size 256 next 9\n",
      "2022-07-25 15:15:36.524238: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c500 of size 256 next 12\n",
      "2022-07-25 15:15:36.524249: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c600 of size 256 next 13\n",
      "2022-07-25 15:15:36.524259: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c700 of size 512 next 14\n",
      "2022-07-25 15:15:36.524269: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c900 of size 256 next 17\n",
      "2022-07-25 15:15:36.524279: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653ca00 of size 256 next 18\n",
      "2022-07-25 15:15:36.524290: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653cb00 of size 1024 next 19\n",
      "2022-07-25 15:15:36.524300: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653cf00 of size 256 next 22\n",
      "2022-07-25 15:15:36.524310: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653d000 of size 256 next 23\n",
      "2022-07-25 15:15:36.524320: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653d100 of size 1024 next 26\n",
      "2022-07-25 15:15:36.524330: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653d500 of size 256 next 27\n",
      "2022-07-25 15:15:36.524341: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653d600 of size 256 next 28\n",
      "2022-07-25 15:15:36.524353: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653d700 of size 2048 next 29\n",
      "2022-07-25 15:15:36.524363: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653df00 of size 256 next 32\n",
      "2022-07-25 15:15:36.524373: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653e000 of size 256 next 33\n",
      "2022-07-25 15:15:36.524383: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653e100 of size 2048 next 36\n",
      "2022-07-25 15:15:36.524393: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653e900 of size 2048 next 38\n",
      "2022-07-25 15:15:36.524403: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653f100 of size 2048 next 40\n",
      "2022-07-25 15:15:36.524413: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653f900 of size 256 next 41\n",
      "2022-07-25 15:15:36.524423: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653fa00 of size 256 next 42\n",
      "2022-07-25 15:15:36.524434: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653fb00 of size 27392 next 10\n",
      "2022-07-25 15:15:36.524445: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346546600 of size 20736 next 11\n",
      "2022-07-25 15:15:36.524455: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654b700 of size 256 next 43\n",
      "2022-07-25 15:15:36.524465: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654b800 of size 256 next 44\n",
      "2022-07-25 15:15:36.524476: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654b900 of size 16384 next 46\n",
      "2022-07-25 15:15:36.524486: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654f900 of size 256 next 49\n",
      "2022-07-25 15:15:36.524496: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654fa00 of size 256 next 50\n",
      "2022-07-25 15:15:36.524508: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654fb00 of size 256 next 51\n",
      "2022-07-25 15:15:36.524518: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654fc00 of size 256 next 52\n",
      "2022-07-25 15:15:36.524528: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654fd00 of size 256 next 53\n",
      "2022-07-25 15:15:36.524539: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654fe00 of size 256 next 54\n",
      "2022-07-25 15:15:36.524550: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654ff00 of size 256 next 55\n",
      "2022-07-25 15:15:36.524560: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346550000 of size 256 next 56\n",
      "2022-07-25 15:15:36.524571: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346550100 of size 256 next 57\n",
      "2022-07-25 15:15:36.524581: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346550200 of size 256 next 58\n",
      "2022-07-25 15:15:36.524591: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346550300 of size 256 next 59\n",
      "2022-07-25 15:15:36.524602: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346550400 of size 20736 next 60\n",
      "2022-07-25 15:15:36.524612: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346555500 of size 256 next 61\n",
      "2022-07-25 15:15:36.524623: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346555600 of size 1728768 next 16\n",
      "2022-07-25 15:15:36.524644: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3466fb700 of size 884736 next 15\n",
      "2022-07-25 15:15:36.524655: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3467d3700 of size 512 next 62\n",
      "2022-07-25 15:15:36.524665: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3467d3900 of size 7077376 next 21\n",
      "2022-07-25 15:15:36.524676: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346e93700 of size 3538944 next 20\n",
      "2022-07-25 15:15:36.524686: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471f3700 of size 1024 next 63\n",
      "2022-07-25 15:15:36.524696: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471f3b00 of size 1024 next 65\n",
      "2022-07-25 15:15:36.524706: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471f3f00 of size 2048 next 67\n",
      "2022-07-25 15:15:36.524717: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471f4700 of size 2048 next 69\n",
      "2022-07-25 15:15:36.524729: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471f4f00 of size 2048 next 71\n",
      "2022-07-25 15:15:36.524739: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471f5700 of size 2048 next 73\n",
      "2022-07-25 15:15:36.524751: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471f5f00 of size 16384 next 74\n",
      "2022-07-25 15:15:36.524763: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471f9f00 of size 16384 next 76\n",
      "2022-07-25 15:15:36.524773: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471fdf00 of size 20736 next 77\n",
      "2022-07-25 15:15:36.524791: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef347203000 of size 256 next 78\n",
      "2022-07-25 15:15:36.524801: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef347203100 of size 884736 next 79\n",
      "2022-07-25 15:15:36.524814: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3472db100 of size 512 next 80\n",
      "2022-07-25 15:15:36.524825: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3472db300 of size 6128640 next 25\n",
      "2022-07-25 15:15:36.524836: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3478b3700 of size 7077888 next 24\n",
      "2022-07-25 15:15:36.524846: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef347f73700 of size 7077888 next 64\n",
      "2022-07-25 15:15:36.524858: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef348633700 of size 9699328 next 45\n",
      "2022-07-25 15:15:36.524869: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef348f73700 of size 11534336 next 31\n",
      "2022-07-25 15:15:36.524879: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef349a73700 of size 14155776 next 30\n",
      "2022-07-25 15:15:36.524890: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34a7f3700 of size 14155776 next 66\n",
      "2022-07-25 15:15:36.524905: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34b573700 of size 1024 next 81\n",
      "2022-07-25 15:15:36.524916: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34b573b00 of size 14154752 next 35\n",
      "2022-07-25 15:15:36.524930: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34c2f3700 of size 28311552 next 34\n",
      "2022-07-25 15:15:36.524940: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34ddf3700 of size 28311552 next 37\n",
      "2022-07-25 15:15:36.524953: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34f8f3700 of size 28311552 next 39\n",
      "2022-07-25 15:15:36.524964: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3513f3700 of size 28311552 next 68\n",
      "2022-07-25 15:15:36.524977: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef352ef3700 of size 28311552 next 70\n",
      "2022-07-25 15:15:36.524988: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3549f3700 of size 28311552 next 72\n",
      "2022-07-25 15:15:36.525001: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3564f3700 of size 1024 next 82\n",
      "2022-07-25 15:15:36.525011: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3564f3b00 of size 14155776 next 83\n",
      "2022-07-25 15:15:36.525025: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef357273b00 of size 2048 next 84\n",
      "2022-07-25 15:15:36.525035: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef357274300 of size 35124224 next 48\n",
      "2022-07-25 15:15:36.525049: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3593f3700 of size 67108864 next 47\n",
      "2022-07-25 15:15:36.525060: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef35d3f3700 of size 67108864 next 75\n",
      "2022-07-25 15:15:36.525073: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3613f3700 of size 2048 next 85\n",
      "2022-07-25 15:15:36.525083: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3613f3f00 of size 28311552 next 86\n",
      "2022-07-25 15:15:36.525096: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef362ef3f00 of size 2048 next 87\n",
      "2022-07-25 15:15:36.525108: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef362ef4700 of size 28311552 next 88\n",
      "2022-07-25 15:15:36.525118: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3649f4700 of size 2048 next 89\n",
      "2022-07-25 15:15:36.525128: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3649f4f00 of size 8388608 next 90\n",
      "2022-07-25 15:15:36.525139: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3651f4f00 of size 16384 next 91\n",
      "2022-07-25 15:15:36.525152: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3651f8f00 of size 67108864 next 92\n",
      "2022-07-25 15:15:36.525162: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691f8f00 of size 16384 next 93\n",
      "2022-07-25 15:15:36.525172: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fcf00 of size 256 next 94\n",
      "2022-07-25 15:15:36.525182: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd000 of size 256 next 95\n",
      "2022-07-25 15:15:36.525196: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd100 of size 256 next 96\n",
      "2022-07-25 15:15:36.525211: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd200 of size 256 next 97\n",
      "2022-07-25 15:15:36.525221: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd300 of size 256 next 98\n",
      "2022-07-25 15:15:36.525235: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd400 of size 256 next 99\n",
      "2022-07-25 15:15:36.525245: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd500 of size 256 next 100\n",
      "2022-07-25 15:15:36.525258: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd600 of size 256 next 101\n",
      "2022-07-25 15:15:36.525268: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd700 of size 256 next 106\n",
      "2022-07-25 15:15:36.525281: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd800 of size 256 next 107\n",
      "2022-07-25 15:15:36.525292: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd900 of size 256 next 108\n",
      "2022-07-25 15:15:36.525305: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7ef3691fda00 of size 256 next 110\n",
      "2022-07-25 15:15:36.525315: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fdb00 of size 256 next 111\n",
      "2022-07-25 15:15:36.525328: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fdc00 of size 256 next 112\n",
      "2022-07-25 15:15:36.525339: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7ef3691fdd00 of size 13545984 next 102\n",
      "2022-07-25 15:15:36.525352: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369ee8f00 of size 256 next 103\n",
      "2022-07-25 15:15:36.525362: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7ef369ee9000 of size 13547520 next 104\n",
      "2022-07-25 15:15:36.525373: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef36abd4800 of size 54190080 next 105\n",
      "2022-07-25 15:15:36.525387: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef36df82800 of size 1059803136 next 109\n",
      "2022-07-25 15:15:36.525401: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3ad237800 of size 1059803136 next 113\n",
      "2022-07-25 15:15:36.525412: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3ec4ec800 of size 1050276864 next 114\n",
      "2022-07-25 15:15:36.525425: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7ef42ae8bc00 of size 1915370496 next 115\n",
      "2022-07-25 15:15:36.525436: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef49d12f800 of size 1915370496 next 116\n",
      "2022-07-25 15:15:36.525450: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef50f3d3400 of size 1824921600 next 117\n",
      "2022-07-25 15:15:36.525465: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef57c034c00 of size 3296526336 next 118\n",
      "2022-07-25 15:15:36.525476: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7ef640804c00 of size 1260106752 next 18446744073709551615\n",
      "2022-07-25 15:15:36.525489: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
      "2022-07-25 15:15:36.525503: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 47 Chunks of size 256 totalling 11.8KiB\n",
      "2022-07-25 15:15:36.525518: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 4 Chunks of size 512 totalling 2.0KiB\n",
      "2022-07-25 15:15:36.525533: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 6 Chunks of size 1024 totalling 6.0KiB\n",
      "2022-07-25 15:15:36.525544: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-07-25 15:15:36.525559: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 12 Chunks of size 2048 totalling 24.0KiB\n",
      "2022-07-25 15:15:36.525574: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 5 Chunks of size 16384 totalling 80.0KiB\n",
      "2022-07-25 15:15:36.525586: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 20736 totalling 60.8KiB\n",
      "2022-07-25 15:15:36.525600: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 27392 totalling 26.8KiB\n",
      "2022-07-25 15:15:36.525615: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 884736 totalling 1.69MiB\n",
      "2022-07-25 15:15:36.525631: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1728768 totalling 1.65MiB\n",
      "2022-07-25 15:15:36.525642: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 3538944 totalling 3.38MiB\n",
      "2022-07-25 15:15:36.525657: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 6128640 totalling 5.84MiB\n",
      "2022-07-25 15:15:36.525672: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 7077376 totalling 6.75MiB\n",
      "2022-07-25 15:15:36.525684: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 7077888 totalling 13.50MiB\n",
      "2022-07-25 15:15:36.525698: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 8388608 totalling 8.00MiB\n",
      "2022-07-25 15:15:36.525713: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 9699328 totalling 9.25MiB\n",
      "2022-07-25 15:15:36.525725: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 11534336 totalling 11.00MiB\n",
      "2022-07-25 15:15:36.525740: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 14154752 totalling 13.50MiB\n",
      "2022-07-25 15:15:36.525755: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 14155776 totalling 40.50MiB\n",
      "2022-07-25 15:15:36.525770: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 8 Chunks of size 28311552 totalling 216.00MiB\n",
      "2022-07-25 15:15:36.525786: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 35124224 totalling 33.50MiB\n",
      "2022-07-25 15:15:36.525797: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 54190080 totalling 51.68MiB\n",
      "2022-07-25 15:15:36.525812: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 67108864 totalling 192.00MiB\n",
      "2022-07-25 15:15:36.525827: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1050276864 totalling 1001.62MiB\n",
      "2022-07-25 15:15:36.525842: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 1059803136 totalling 1.97GiB\n",
      "2022-07-25 15:15:36.525853: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1314109440 totalling 1.22GiB\n",
      "2022-07-25 15:15:36.525864: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1824921600 totalling 1.70GiB\n",
      "2022-07-25 15:15:36.525878: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1915370496 totalling 1.78GiB\n",
      "2022-07-25 15:15:36.525893: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 3296526336 totalling 3.07GiB\n",
      "2022-07-25 15:15:36.525909: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 11.32GiB\n",
      "2022-07-25 15:15:36.525924: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 15361376256 memory_limit_: 15361376256 available bytes: 0 curr_region_allocation_bytes_: 30722752512\n",
      "2022-07-25 15:15:36.525945: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
      "Limit:                     15361376256\n",
      "InUse:                     12158805248\n",
      "MaxInUse:                  14117751296\n",
      "NumAllocs:                         193\n",
      "MaxAllocSize:               3296526336\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-07-25 15:15:36.525970: W tensorflow/core/common_runtime/bfc_allocator.cc:474] **********************************___________***********************************************________\n",
      "2022-07-25 15:15:36.526037: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops_3d.cc:186 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[3,256,21,214,214] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/conv3d_3/Conv3D' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 707, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 502, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 491, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 398, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 722, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 389, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_16441/522401811.py\", line 34, in <cell line: 34>\n      history = c3d_model.fit(train_tf,\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv3d_3/Conv3D'\nOOM when allocating tensor with shape[3,256,21,214,214] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv3d_3/Conv3D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1423]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m c3d_model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel(inputs, output)\n\u001b[1;32m     31\u001b[0m c3d_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 34\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mc3d_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# history = c3d_model.fit(train_videos, \u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#                         train_labels,\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#                         validation_split = 0.2,\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#                         epochs = 16,\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#                         verbose= 1)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone training.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/conv3d_3/Conv3D' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 707, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 502, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 491, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 398, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 722, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 389, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_16441/522401811.py\", line 34, in <cell line: 34>\n      history = c3d_model.fit(train_tf,\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv3d_3/Conv3D'\nOOM when allocating tensor with shape[3,256,21,214,214] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/conv3d_3/Conv3D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1423]"
     ]
    }
   ],
   "source": [
    "#creating C3D Model\n",
    "\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# with strategy.scope():\n",
    "inputs = keras.Input(shape=(30, 224, 224, 3)) #full shape w/ batch dim = (None, 30, 224, 224, 3) \n",
    "\n",
    "x = Conv3D(64, kernel_size=(3,3,3), strides=(1,1,1))(inputs)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 1), strides=(1,1,1))(x)\n",
    "\n",
    "x = Conv3D(128, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2), strides=(1,1,1))(x)\n",
    "\n",
    "x = Conv3D(256, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = Conv3D(256, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2), strides=(1,1,1))(x)\n",
    "\n",
    "x = Conv3D(512, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = Conv3D(512, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2), strides=(1,1,1))(x)\n",
    "\n",
    "x = Conv3D(512, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = Conv3D(512, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2), strides=(1,1,1))(x)\n",
    "\n",
    "x = Dense(4096, activation=\"relu\")(x)\n",
    "output = Dense(4096, activation=\"softmax\")(x)\n",
    "\n",
    "c3d_model = keras.Model(inputs, output)\n",
    "\n",
    "c3d_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "history = c3d_model.fit(train_tf,\n",
    "                        epochs = 16,\n",
    "                        verbose= 1)\n",
    "\n",
    "# history = c3d_model.fit(train_videos, \n",
    "#                         train_labels,\n",
    "#                         validation_split = 0.2,\n",
    "#                         epochs = 16,\n",
    "#                         verbose= 1)\n",
    "\n",
    "print('Done training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c02aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
