{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d8170dd",
   "metadata": {},
   "source": [
    "# Implementing C3D Model for Video Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f299dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import pickle\n",
    "import glob\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import seaborn as sns\n",
    "\n",
    " \n",
    "# adding video-download folder to the system path\n",
    "sys.path.insert(0, '/workspace/youtube-humpback-whale-classifier/video-download')\n",
    " \n",
    "# importing read_frames_hdf5 function\n",
    "from hdf5_data_loading import read_frames_hdf5\n",
    "\n",
    "#ngc workspace path (where we keep our data)\n",
    "workspace_path = '/mount/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcee2d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: micheller (epg). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/youtube-humpback-whale-classifier/classification/wandb/run-20220726_185627-2pcmzsjd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/epg/whale-classification-inception/runs/2pcmzsjd\" target=\"_blank\">vibrant-bee-30</a></strong> to <a href=\"https://wandb.ai/epg/whale-classification-inception\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "#start wandb session for metric logging\n",
    "wandb.login() \n",
    "\n",
    "wandb.init(project=\"whale-classification-inception\")\n",
    "\n",
    "wandb.run.name = \"c3d-training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cc73826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs available:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs available: \", len(tf.config.list_physical_devices('GPU'))) #1 if we select GPU mode in Colab Notebook, 0 if running on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a62e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 4 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 18:56:41.114282: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-26 18:56:46.104443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14649 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:85:00.0, compute capability: 7.0\n",
      "2022-07-26 18:56:46.106576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14649 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:86:00.0, compute capability: 7.0\n",
      "2022-07-26 18:56:46.110866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14649 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:89:00.0, compute capability: 7.0\n",
      "2022-07-26 18:56:46.115902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14649 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "#limit GPU memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa7263c",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed1bef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset in\n",
    "data = pd.read_csv(workspace_path + '/downloaded_videos.csv')\n",
    "y = data.pop('relevant')\n",
    "X = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bfd57b",
   "metadata": {},
   "source": [
    "## Load Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8389af49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading frames for video 0...\n",
      "Loading frames for video 50...\n",
      "Loading frames for video 100...\n",
      "Loading frames for video 150...\n",
      "Loading frames for video 200...\n",
      "Loading frames for video 250...\n",
      "Loading frames for video 300...\n",
      "Loading frames for video 350...\n",
      "Done loading frames in 68.86091804504395 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(364, 30, 224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in frames for all videos\n",
    "start = time.time()\n",
    "\n",
    "N = X.shape[0] #number of videos in our dataset\n",
    "videos = np.empty((N, 30, 224, 224, 3), dtype=np.uint8)\n",
    "labels = np.empty(N, dtype = np.uint8)\n",
    "\n",
    "for i, video in enumerate(list(X.renamed_title)):\n",
    "    if i % 50 == 0:\n",
    "        print(f'Loading frames for video {i}...')\n",
    "        \n",
    "    clip_name = video.replace(\"_\", \"_clip_\").replace(\".mp4\", \"\")\n",
    "    frames, frame_labels = read_frames_hdf5(clip_name) #returns frames array of shape (461, 224, 224, 3)\n",
    "    \n",
    "    videos[i, ...] = frames[15:45] #shortened videos bc of memory issue - each video is reduced to 30 frames\n",
    "    labels[i] = frame_labels[0] #all frames have the same label since label is assigned to overall video\n",
    "\n",
    "stop = time.time()\n",
    "print(f'Done loading frames in {stop-start} seconds.')\n",
    "videos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcda3ab",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45e254c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "train_index = list(X_train.index)\n",
    "test_index = list(X_test.index)\n",
    "\n",
    "# index data accordingly\n",
    "train_videos, train_labels = videos[train_index], labels[train_index]\n",
    "test_videos, test_labels = videos[test_index], labels[test_index]\n",
    "\n",
    "# reshape label arrays as horizontal arrays\n",
    "train_labels = np.reshape(train_labels, (train_labels.shape[0], 1))\n",
    "test_labels = np.reshape(test_labels, (test_labels.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d24eef3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 30, 224, 224, 3)\n",
      "(73, 30, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_videos.shape)\n",
    "print(test_videos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad40bbc",
   "metadata": {},
   "source": [
    "## Converting Data into TF Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8b14e94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 23:37:27.760440: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-25 23:37:32.468881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14649 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:85:00.0, compute capability: 7.0\n",
      "2022-07-25 23:37:32.477385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14649 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:86:00.0, compute capability: 7.0\n",
      "2022-07-25 23:37:32.483364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14649 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:89:00.0, compute capability: 7.0\n",
      "2022-07-25 23:37:32.485297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14649 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 30, 224, 224, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(None, 1), dtype=tf.uint8, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_tf = tf.data.Dataset.from_tensor_slices((train_videos, train_labels)).batch(10)\n",
    "# train_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ffbd16",
   "metadata": {},
   "source": [
    "`GPU keeps allocating 15516MiB everytime we load any sort of data, which leads to running out of memory at model training`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd621be",
   "metadata": {},
   "source": [
    "## Build C3D Video Classification Model\n",
    "\n",
    "Resources\n",
    "- https://towardsdatascience.com/step-by-step-implementation-3d-convolutional-neural-network-in-keras-12efbdd7b130\n",
    "- https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7410867&tag=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71f63b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "# print(os.getenv('TF_GPU_ALLOCATOR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d7e0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946033e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 18:59:17.663543: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "2022-07-26 18:59:18.952483: I tensorflow/stream_executor/cuda/cuda_dnn.cc:379] Loaded cuDNN version 8400\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# fake_data = tf.random.normal((10, 30, 224, 224, 3))\n",
    "# fake_label = tf.random.normal((10,))\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((fake_data, fake_label)).batch(1)\n",
    "# print(\"Data ready\")\n",
    "\n",
    "inputs = keras.Input(shape=(30, 224, 224, 3)) #full shape w/ batch dim = (None, 30, 224, 224, 3)\n",
    "x = Conv3D(64, kernel_size=(3,3,3), strides=(1,1,1))(inputs)\n",
    "x = MaxPooling3D(pool_size=(1, 2, 2), strides=(1,1,1))(x)\n",
    "x = Conv3D(128, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2), strides=(1,1,1))(x)\n",
    "x = Conv3D(256, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = Conv3D(256, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "# x = MaxPooling3D(pool_size=(2, 2, 2), strides=(1,1,1))(x)\n",
    "# x = Conv3D(512, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "# x = Conv3D(512, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "# x = MaxPooling3D(pool_size=(2, 2, 2), strides=(1,1,1))(x)\n",
    "# x = Conv3D(512, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "# x = Conv3D(512, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2), strides=(1,1,1))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "output = Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "c3d_model = keras.Model(inputs, output)\n",
    "c3d_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# c3d_model.summary()\n",
    "\n",
    "history = c3d_model.fit(train_videos, train_labels,\n",
    "                        epochs = 5,\n",
    "                        verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d19f62e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">confused-hill-29</strong>: <a href=\"https://wandb.ai/epg/whale-classification-inception/runs/4pp8aigp\" target=\"_blank\">https://wandb.ai/epg/whale-classification-inception/runs/4pp8aigp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220726_183559-4pp8aigp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
