{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ddba950",
   "metadata": {},
   "source": [
    "# Classifying YouTube Videos for Humpback Whale Encounters - Keras CNN-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c518643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750819a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import pickle\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import seaborn as sns\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "856419da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngc workspace path (where we keep our data)\n",
    "workspace_path = '/mount/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79cec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start wandb session for metric logging\n",
    "wandb.login() \n",
    "\n",
    "wandb.init(project=\"whale-classification-inception\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6845968",
   "metadata": {},
   "source": [
    "# Inception V3 (CNN-RNN) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78cc202",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee7fe95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "MAX_NUM_FRAMES = 461\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb62ab17",
   "metadata": {},
   "source": [
    "461 frames of size 224 x 224 with RGB color channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef20e83",
   "metadata": {},
   "source": [
    "# Load Frames + Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "624fb37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction import load_frames, prepare_all_videos\n",
    "from cnn import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "babe1875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fc575b5e7f0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvNet = CNN(IMG_SIZE)\n",
    "feature_extractor = ConvNet.InceptionV3()\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f7c00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(workspace_path + '/downloaded_videos.csv')\n",
    "y = data.pop('relevant')\n",
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e045bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(frame_features, frame_masks), labels = prepare_all_videos(X, y, MAX_NUM_FRAMES, NUM_FEATURES, feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "def63ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame features shape:  (5, 461, 2048)\n",
      "Frame masks shape:  (5, 461)\n",
      "Number of Labels:  5\n"
     ]
    }
   ],
   "source": [
    "print('Frame features shape: ', frame_features.shape)\n",
    "print('Frame masks shape: ', frame_masks.shape)\n",
    "print('Number of Labels: ', len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61b278c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
