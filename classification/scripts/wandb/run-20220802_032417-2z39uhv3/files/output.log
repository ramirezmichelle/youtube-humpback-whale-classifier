Memory growth is now the same across all 8 available GPUs.
Loading data...
Video 0 ...
Video 50 ...
Video 100 ...
Video 150 ...
Video 200 ...
Video 250 ...
Video 300 ...
Video 350 ...
2022-08-02 03:25:35.124661: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-08-02 03:25:41.556236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14649 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:06:00.0, compute capability: 7.0
2022-08-02 03:25:41.558764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14649 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:07:00.0, compute capability: 7.0
2022-08-02 03:25:41.561110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14649 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:0a:00.0, compute capability: 7.0
2022-08-02 03:25:41.563453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14649 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:0b:00.0, compute capability: 7.0
2022-08-02 03:25:41.565772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 14649 MB memory:  -> device: 4, name: Tesla V100-SXM2-16GB, pci bus id: 0000:85:00.0, compute capability: 7.0
2022-08-02 03:25:41.568078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 14649 MB memory:  -> device: 5, name: Tesla V100-SXM2-16GB, pci bus id: 0000:86:00.0, compute capability: 7.0
2022-08-02 03:25:41.570383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 14649 MB memory:  -> device: 6, name: Tesla V100-SXM2-16GB, pci bus id: 0000:89:00.0, compute capability: 7.0
2022-08-02 03:25:41.572681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 14649 MB memory:  -> device: 7, name: Tesla V100-SXM2-16GB, pci bus id: 0000:8a:00.0, compute capability: 7.0
Done loading videos in 74.36149072647095 seconds.
Setting TensorFlow Mirrored Strategy with 1 GPUs...
Number of devices in strategy: 1
Creating TF Dataset...
Creating TF DISTRIBUTED Dataset...
2022-08-02 03:26:00.382202: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorSliceDataset/_2"
op: "TensorSliceDataset"
input: "Placeholder/_0"
input: "Placeholder/_1"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_UINT8
      type: DT_UINT8
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 364
  }
}
attr {
  key: "is_files"
  value {
    b: false
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\024TensorSliceDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
        dim {
          size: 461
        }
        dim {
          size: 224
        }
        dim {
          size: 224
        }
        dim {
          size: 3
        }
      }
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_UINT8
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_UINT8
        }
      }
    }
  }
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_UINT8
        }
      }
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_UINT8
        }
      }
    }
  }
}
Creating CNN Model on Each Active Replica (GPU)
Beginning Feature Extraction in GPU Mode...
2022-08-02 03:26:10.946619: W tensorflow/core/kernels/gpu_utils.cc:50] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.
2022-08-02 03:26:12.019819: I tensorflow/stream_executor/cuda/cuda_dnn.cc:379] Loaded cuDNN version 8400
2022-08-02 03:26:13.174565: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.
Done getting video frame feature representations in 246.25644493103027 seconds.
Formatting Results into Numpy Arrays...
Back from feature Extraction.
Features: (364, 461, 512)
Labels: (364, 1)
Splitting + batching features and labels for RNN ...
<PrefetchDataset element_spec=(TensorSpec(shape=(None, 461, 512), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.uint8, name=None))>
<PrefetchDataset element_spec=(TensorSpec(shape=(None, 461, 512), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.uint8, name=None))>
<PrefetchDataset element_spec=(TensorSpec(shape=(None, 461, 512), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.uint8, name=None))>
Training RNN ...
Epoch 1/15

8/8 [==============================] - 12s 445ms/step - loss: 0.6800 - accuracy: 0.6638 - val_loss: 0.4747 - val_accuracy: 0.7797
Epoch 2/15
8/8 [==============================] - 1s 150ms/step - loss: 0.3563 - accuracy: 0.8448 - val_loss: 0.4688 - val_accuracy: 0.7966
Epoch 3/15
8/8 [==============================] - 1s 151ms/step - loss: 0.2379 - accuracy: 0.9181 - val_loss: 0.4526 - val_accuracy: 0.7966
Epoch 4/15
8/8 [==============================] - 1s 157ms/step - loss: 0.1487 - accuracy: 0.9526 - val_loss: 0.5045 - val_accuracy: 0.7797
Epoch 5/15
8/8 [==============================] - 1s 154ms/step - loss: 0.0858 - accuracy: 0.9828 - val_loss: 0.4128 - val_accuracy: 0.7966
3/3 [==============================] - 0s 44ms/step - loss: 0.4711 - accuracy: 0.7397
CNN      Accuracy (Test)    Loss (Test)    F1 Score    Time to Extract Features (sec)    Videos/Second (Feat. Ext.)
-----  -----------------  -------------  ----------  --------------------------------  ----------------------------
vgg16           0.739726       0.471113    0.520548                           246.256                       1.47813