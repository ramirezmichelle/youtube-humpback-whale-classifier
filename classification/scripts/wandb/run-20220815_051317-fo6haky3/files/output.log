Memory growth is now the same across all 8 available GPUs.
Loading data...
Video 0 ...
Video 50 ...
Video 100 ...
Video 150 ...
Video 200 ...
Video 250 ...
Video 300 ...
Video 350 ...
Done loading videos in 59.4747040271759 seconds.
Setting TensorFlow Mirrored Strategy with 4 GPUs...
Number of devices in strategy: 4
Beginning Feature Extraction in GPU Mode...
Done getting video frame feature representations in 50.08365273475647 seconds.
Setting TensorFlow Mirrored Strategy with 4 GPUs...
Number of devices in strategy: 4
Beginning Feature Extraction in GPU Mode...
Done getting video frame feature representations in 22.826575994491577 seconds.
Setting TensorFlow Mirrored Strategy with 4 GPUs...
Number of devices in strategy: 4
Beginning Feature Extraction in GPU Mode...
Done getting video frame feature representations in 22.59495210647583 seconds.
Back from feature Extraction.
Train Features: (232, 461, 2048) || Train Labels: (232, 1)
Val Features: (59, 461, 2048) || Val Labels: (59, 1)
Test Features: (73, 461, 2048) || Test Labels: (73, 1)
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
Traceback (most recent call last):
  File "main.py", line 126, in <module>
    main()
  File "main.py", line 102, in main
    model, history = train_rnn(train_dataset, val_dataset, train_features.shape[2], log_on_wandb = is_wandb_enabled)
  File "/workspace/youtube-humpback-whale-classifier/classification/scripts/rnn.py", line 58, in train_rnn
    history = model.fit(train_dataset,
  File "/usr/local/lib/python3.8/dist-packages/wandb/integration/keras/keras.py", line 171, in new_v2
    for cbk in cbks:
TypeError: 'NoneType' object is not iterable