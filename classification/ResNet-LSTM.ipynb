{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c93efe",
   "metadata": {},
   "source": [
    "# ResNet-LSTM for Video Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4346a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import pickle\n",
    "import glob\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import seaborn as sns\n",
    "\n",
    " \n",
    "# adding video-download folder to the system path\n",
    "sys.path.insert(0, '/workspace/youtube-humpback-whale-classifier/video-download')\n",
    " \n",
    "# importing read_frames_hdf5 function\n",
    "from hdf5_data_loading import read_frames_hdf5\n",
    "\n",
    "#ngc workspace path (where we keep our data)\n",
    "workspace_path = '/mount/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5b0905b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmicheller\u001b[0m (\u001b[33mepg\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/youtube-humpback-whale-classifier/classification/wandb/run-20220727_171214-pygsrcpy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/epg/whale-classification-inception/runs/pygsrcpy\" target=\"_blank\">proud-fire-35</a></strong> to <a href=\"https://wandb.ai/epg/whale-classification-inception\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "#start wandb session for metric logging\n",
    "wandb.login() \n",
    "\n",
    "wandb.init(project=\"whale-classification-inception\")\n",
    "\n",
    "wandb.run.name = \"feature-ext-limited-memory-growth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b3f57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs available:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs available: \", len(tf.config.list_physical_devices('GPU'))) #1 if we select GPU mode in Colab Notebook, 0 if running on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f9ce469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 4 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 17:12:26.407538: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-27 17:12:31.347975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14649 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:85:00.0, compute capability: 7.0\n",
      "2022-07-27 17:12:31.351786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14649 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:86:00.0, compute capability: 7.0\n",
      "2022-07-27 17:12:31.353785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14649 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:89:00.0, compute capability: 7.0\n",
      "2022-07-27 17:12:31.357328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14649 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "#limit GPU memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256b6408",
   "metadata": {},
   "source": [
    "## Load Data with Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "602b1ae7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#load dataset in\n",
    "data = pd.read_csv(workspace_path + '/downloaded_videos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a30159b4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "labels = dict()\n",
    "for i, row in data.iterrows():\n",
    "    clip = row['renamed_title'].replace('_','_clip_').replace('.mp4','')\n",
    "    labels[clip] = int(row['relevant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "393d36bb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data.pop('relevant')\n",
    "X = data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b287c27c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from DataGenerator import DataGenerator\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 1, \n",
    "          'n_classes': 2,\n",
    "          'shuffle': False}\n",
    "\n",
    "# Datasets\n",
    "partition = {'train': [video.replace('_','_clip_').replace('.mp4','') for video in X_train.renamed_title.tolist()],\n",
    "             'validation': [video.replace('_','_clip_').replace('.mp4','') for video in X_test.renamed_title.tolist()]\n",
    "            }\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "951155a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataGenerator' object has no attribute 'squeeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m ConvNet\u001b[38;5;241m.\u001b[39mResNet50()\n\u001b[1;32m      7\u001b[0m features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m364\u001b[39m, \u001b[38;5;241m461\u001b[39m, \u001b[38;5;241m2048\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m----> 9\u001b[0m features \u001b[38;5;241m=\u001b[39m feature_extractor\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mtraining_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m())\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot features in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstop\u001b[38;5;241m-\u001b[39mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m features\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataGenerator' object has no attribute 'squeeze'"
     ]
    }
   ],
   "source": [
    "from cnn import CNN\n",
    "\n",
    "# Feature Extractor\n",
    "ConvNet = CNN(224)\n",
    "feature_extractor = ConvNet.ResNet50()\n",
    "\n",
    "features = np.empty((364, 461, 2048), dtype=np.float32)\n",
    "\n",
    "features = feature_extractor.predict(training_generator)\n",
    "\n",
    "print(f\"Got features in {stop-start} seconds.\")\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e187f34b",
   "metadata": {},
   "source": [
    "## Load Frames (No Data Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14e1f776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset in\n",
    "data = pd.read_csv(workspace_path + '/downloaded_videos.csv')\n",
    "y = data.pop('relevant')\n",
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "873a0633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading frames for video 0...\n",
      "Loading frames for video 50...\n",
      "Loading frames for video 100...\n",
      "Loading frames for video 150...\n",
      "Loading frames for video 200...\n",
      "Loading frames for video 250...\n",
      "Loading frames for video 300...\n",
      "Loading frames for video 350...\n",
      "Done loading frames in 1131.0881350040436 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(364, 461, 224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in frames for all videos\n",
    "start = time.time()\n",
    "\n",
    "N = X.shape[0] #number of videos in our dataset\n",
    "videos = np.empty((N, 461, 224, 224, 3), dtype=np.float32)\n",
    "labels = np.empty(N, dtype = np.uint8)\n",
    "\n",
    "for i, video in enumerate(list(X.renamed_title)):\n",
    "    if i % 50 == 0:\n",
    "        print(f'Loading frames for video {i}...')\n",
    "        \n",
    "    clip_name = video.replace(\"_\", \"_clip_\").replace(\".mp4\", \"\")\n",
    "    frames, frame_labels = read_frames_hdf5(clip_name) #returns frames array of shape (461, 224, 224, 3)\n",
    "    \n",
    "    videos[i, ...] = frames\n",
    "    labels[i] = frame_labels[0] #all frames have the same label since label is assigned to overall video\n",
    "\n",
    "stop = time.time()\n",
    "print(f'Done loading frames in {stop-start} seconds.')\n",
    "videos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662ce66e",
   "metadata": {},
   "source": [
    "## Get Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba5baba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"feature_extractor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#when we limit GPU memory growth,feature extractor takes up 700MiB / 16160MiB\n",
    "#instead of 15096MiB / 16160MiB, which nearly exhausts all our GPU memory on GPU 0\n",
    "from cnn import CNN\n",
    "\n",
    "# with tf.device('/CPU:0'):\n",
    "ConvNet = CNN(224)\n",
    "feature_extractor = ConvNet.ResNet50()\n",
    "\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a958b2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 17:37:53.652622: I tensorflow/stream_executor/cuda/cuda_dnn.cc:379] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video 50...\n",
      "Video 100...\n",
      "Video 150...\n",
      "Video 200...\n",
      "Video 250...\n",
      "Video 300...\n",
      "Video 350...\n",
      "Finished extracting features from all 364 videos in 465.5257749557495 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(364, 461, 2048)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try getting features and time\n",
    "# with tf.device('/CPU:0'):\n",
    "features = np.empty((N, 461, 2048), dtype=np.float32)\n",
    "start = time.time()\n",
    "\n",
    "for i, video in enumerate(videos):\n",
    "    if i % 50 == 0:\n",
    "        print(f\"Video {i}...\")\n",
    "    features[i, ...] = feature_extractor.predict_on_batch(video) #video has shape (461, 224, 224, 3)\n",
    "\n",
    "stop = time.time()\n",
    "print(f\"Finished extracting features from all {len(videos)} videos in {stop-start} seconds.\")\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d15034d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "`single GPU`: Finished extracting features from all 364 videos in 519.3584320545197 seconds.\n",
    "(364, 461, 2048)\n",
    "\n",
    "NVIDIA-SMI output after feature ext.\n",
    "\n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.6     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
    "| N/A   38C    P0    50W / 160W |  15516MiB / 16160MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   1  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
    "| N/A   39C    P0    52W / 160W |    446MiB / 16160MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   2  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
    "| N/A   39C    P0    53W / 160W |    446MiB / 16160MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   3  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
    "| N/A   37C    P0    52W / 160W |    446MiB / 16160MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "                                                                               \n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "+-----------------------------------------------------------------------------+\n",
    "\n",
    "`CPU only`: Finished extracting features from all 364 videos in 3518.14151930809 seconds.\n",
    "\n",
    "NVIDIA-SMI output after feature ext.\n",
    "\n",
    "Mon Jul 25 22:29:25 2022       \n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.6     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
    "| N/A   37C    P0    50W / 160W |    446MiB / 16160MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   1  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
    "| N/A   39C    P0    52W / 160W |    446MiB / 16160MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   2  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
    "| N/A   39C    P0    53W / 160W |    446MiB / 16160MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   3  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
    "| N/A   37C    P0    52W / 160W |    446MiB / 16160MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "                                                                               \n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "+-----------------------------------------------------------------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160c59c1",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51053144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364, 461, 2048)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adccde76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "train_index = list(X_train.index)\n",
    "test_index = list(X_test.index)\n",
    "\n",
    "# index data accordingly\n",
    "train_features, train_labels = features[train_index], labels[train_index]\n",
    "test_features, test_labels = features[test_index], labels[test_index]\n",
    "\n",
    "# reshape label arrays as horizontal arrays\n",
    "train_labels = np.reshape(train_labels, (train_labels.shape[0], 1))\n",
    "test_labels = np.reshape(test_labels, (test_labels.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b8e3d690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 461, 2048)\n",
      "(73, 461, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cb463c",
   "metadata": {},
   "source": [
    "## Train RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5206fa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13009cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/15\n",
      "8/8 [==============================] - 87s 9s/step - loss: 0.6166 - accuracy: 0.6940 - val_loss: 0.6309 - val_accuracy: 0.6102\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 60s 8s/step - loss: 0.4728 - accuracy: 0.7888 - val_loss: 0.4659 - val_accuracy: 0.7797\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 61s 8s/step - loss: 0.3400 - accuracy: 0.8664 - val_loss: 0.4870 - val_accuracy: 0.7458\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 60s 7s/step - loss: 0.2460 - accuracy: 0.9052 - val_loss: 0.4614 - val_accuracy: 0.7627\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 64s 8s/step - loss: 0.1387 - accuracy: 0.9569 - val_loss: 0.5898 - val_accuracy: 0.7119\n",
      "Done training.\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.5354 - accuracy: 0.7397\n",
      "Test Metrics - Loss: 0.5353636145591736, Accuracy: 0.7397260069847107\n"
     ]
    }
   ],
   "source": [
    "# recurrent_dropout does not allow training to use cuDNN kernel\n",
    "features_input       = keras.Input((461, 2048))\n",
    "x                    = keras.layers.Bidirectional(keras.layers.LSTM(32, return_sequences=True, recurrent_dropout=0.5))(features_input)\n",
    "x                    = keras.layers.Bidirectional(keras.layers.LSTM(32, return_sequences=True))(x)\n",
    "x                    = keras.layers.Bidirectional(keras.layers.LSTM(32, return_sequences=True, recurrent_dropout=0.5))(x)\n",
    "x                    = keras.layers.Bidirectional(keras.layers.LSTM(32))(x)\n",
    "\n",
    "output               = keras.layers.Dense(2, activation=\"softmax\")(x) #2 bc 2 class categories (0,1)\n",
    "model                = keras.Model(features_input, output)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "my_callbacks    = [keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", \n",
    "                                                 patience=3,\n",
    "                                                 mode=\"max\",\n",
    "                                                 min_delta = 0.01,\n",
    "                                                 restore_best_weights=True)]\n",
    "history = model.fit(train_features, \n",
    "                    train_labels,\n",
    "                    validation_split = 0.2,\n",
    "                    epochs = 15,\n",
    "                    callbacks = my_callbacks,\n",
    "                    verbose= 1)\n",
    "\n",
    "print('Done training.')\n",
    "\n",
    "loss, accuracy = model.evaluate(test_features, test_labels)\n",
    "print(f\"Test Metrics - Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b3685a",
   "metadata": {},
   "source": [
    "## Trying to Distribute Data + Run RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a99edbd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 23:17:29.071859: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_UINT8\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 291\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\027TensorSliceDataset:1273\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 461\n",
      "        }\n",
      "        dim {\n",
      "          size: 2048\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# global_batch_size = 91*4\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).batch(global_batch_size)\n",
    "# dist_dataset = strategy.experimental_distribute_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81d0c0ec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:3',)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 18:52:09.461372: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_438939\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\023FlatMapDataset:1215\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 24s 168ms/step - loss: 0.6002 - accuracy: 0.6838\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 2s 156ms/step - loss: 0.4380 - accuracy: 0.8144\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 2s 158ms/step - loss: 0.3579 - accuracy: 0.8385\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 2s 159ms/step - loss: 0.2598 - accuracy: 0.8969\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 2s 161ms/step - loss: 0.1619 - accuracy: 0.9450\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 2s 161ms/step - loss: 0.1263 - accuracy: 0.9553\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 2s 163ms/step - loss: 0.0747 - accuracy: 0.9759\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 2s 162ms/step - loss: 0.0464 - accuracy: 0.9828\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.1414 - accuracy: 0.9416\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 147ms/step - loss: 0.0721 - accuracy: 0.9794\n",
      "Done training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 18:52:48.197125: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_456275\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\023FlatMapDataset:1266\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 6s 79ms/step - loss: 0.6300 - accuracy: 0.8082\n",
      "Test Metrics - Loss: 0.6300287246704102, Accuracy: 0.8082191944122314\n"
     ]
    }
   ],
   "source": [
    "#training runs successfully when we specify just the first 3 GPUs (IDs 0,1,2)\n",
    "#once we add in GPU:3, we get a CUDNN_STATUS_BAD_PARAM error\n",
    "strategy = tf.distribute.MirroredStrategy(['/GPU:3'])\n",
    "\n",
    "with strategy.scope():\n",
    "    features_input       = keras.Input((461, 2048))\n",
    "    x                    = keras.layers.Bidirectional(keras.layers.LSTM(32, return_sequences=True))(features_input)\n",
    "    x                    = keras.layers.Bidirectional(keras.layers.LSTM(32, return_sequences=True))(x)\n",
    "    x                    = keras.layers.Bidirectional(keras.layers.LSTM(32, return_sequences=True))(x)\n",
    "    x                    = keras.layers.Bidirectional(keras.layers.LSTM(32))(x)\n",
    "\n",
    "    output               = keras.layers.Dense(2, activation=\"softmax\")(x) #2 bc 2 class categories (0,1)\n",
    "    model                = keras.Model(features_input, output)\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(train_features,\n",
    "                    train_labels,\n",
    "                    epochs = 10,\n",
    "                    verbose= 1)\n",
    "\n",
    "print('Done training.')\n",
    "\n",
    "loss, accuracy = model.evaluate(test_features, test_labels)\n",
    "print(f\"Test Metrics - Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad2f336",
   "metadata": {},
   "source": [
    "## Coursera Multi-GPU Strategy\n",
    "Resources\n",
    "- https://www.coursera.org/learn/custom-distributed-training-with-tensorflow/lecture/21zgD/multi-gpu-mirrored-strategy-code-walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "221bf21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291, 461, 2048)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "788f7631",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = train_features.shape[0]\n",
    "GLOBAL_BATCH_SIZE = 3 * 4\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d1a054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 20:19:02.173102: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_UINT8\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 291\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\027TensorSliceDataset:2246\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 461\n",
      "        }\n",
      "        dim {\n",
      "          size: 2048\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_42 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 20:19:02.685993: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_UINT8\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 73\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\027TensorSliceDataset:2249\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 461\n",
      "        }\n",
      "        dim {\n",
      "          size: 2048\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_43 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(3,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "Tensor(\"replica_1/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(3,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(3,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "Tensor(\"replica_1/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(3,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(2,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "Tensor(\"replica_1/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(1,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "Epoch 1, Loss: 0.5496175289154053, Accuracy: 75.94502258300781, Test Loss: 0.5175575613975525, Test Accuracy: 75.34246826171875\n",
      "Epoch 2, Loss: 0.3967094123363495, Accuracy: 83.16151428222656, Test Loss: 0.5271990299224854, Test Accuracy: 80.8219223022461\n",
      "Epoch 3, Loss: 0.3101663887500763, Accuracy: 86.2542953491211, Test Loss: 0.5358312129974365, Test Accuracy: 75.34246826171875\n",
      "Epoch 4, Loss: 0.22136366367340088, Accuracy: 93.12715148925781, Test Loss: 0.5731847882270813, Test Accuracy: 76.71232604980469\n",
      "Epoch 5, Loss: 0.21100135147571564, Accuracy: 92.09622192382812, Test Loss: 0.5845041275024414, Test Accuracy: 71.23287963867188\n",
      "Epoch 6, Loss: 0.13224773108959198, Accuracy: 95.18900299072266, Test Loss: 0.5845276713371277, Test Accuracy: 75.34246826171875\n",
      "Epoch 7, Loss: 0.09390924125909805, Accuracy: 96.90721893310547, Test Loss: 0.7768977284431458, Test Accuracy: 76.71232604980469\n",
      "Epoch 8, Loss: 0.07163644582033157, Accuracy: 97.59449768066406, Test Loss: 0.7391727566719055, Test Accuracy: 76.71232604980469\n",
      "Epoch 9, Loss: 0.04203179478645325, Accuracy: 98.62542724609375, Test Loss: 0.8369781374931335, Test Accuracy: 71.23287963867188\n",
      "Epoch 10, Loss: 0.013920804485678673, Accuracy: 100.0, Test Loss: 0.8146897554397583, Test Accuracy: 72.60273742675781\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "# Note that it generally has a minimum of 8 cores, but if your GPU has\n",
    "# less, you need to set this. In this case one of my GPUs has 4 cores\n",
    "# os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"] = \"4\"\n",
    "\n",
    "# If the list of devices is not specified in the\n",
    "# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\n",
    "# If you have *different* GPUs in your system, you probably have to set up cross_device_ops like this\n",
    "# strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "strategy = tf.distribute.MirroredStrategy(['/GPU:0', '/GPU:1'])\n",
    "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "\n",
    "# Get the data\n",
    "# fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "# (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# # Adding a dimension to the array -> new shape == (28, 28, 1)\n",
    "# # We are doing this because the first layer in our model is a convolutional\n",
    "# # layer and it requires a 4D input (batch_size, height, width, channels).\n",
    "# # batch_size dimension will be added later on.\n",
    "# train_images = train_images[..., None]\n",
    "# test_images = test_images[..., None]\n",
    "\n",
    "# # Normalize the images to [0, 1] range.\n",
    "# train_images = train_images / np.float32(255)\n",
    "# test_images = test_images / np.float32(255)\n",
    "\n",
    "# Batch the input data\n",
    "BUFFER_SIZE_TRAIN = train_features.shape[0]\n",
    "BUFFER_SIZE_TEST = test_features.shape[0]\n",
    "BATCH_SIZE_PER_REPLICA = 3\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "\n",
    "# Create Datasets from the batches\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).shuffle(BUFFER_SIZE_TRAIN).batch(GLOBAL_BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_features, test_labels)).shuffle(BUFFER_SIZE_TEST).batch(GLOBAL_BATCH_SIZE)\n",
    "\n",
    "# Create Distributed Datasets from the datasets\n",
    "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)\n",
    "\n",
    "# Create the model architecture\n",
    "def create_model():\n",
    "    features_input       = keras.Input((461, 2048))\n",
    "    x                    = keras.layers.Bidirectional(keras.layers.LSTM(32, return_sequences=True, recurrent_dropout=0.1))(features_input)\n",
    "    x                    = keras.layers.Bidirectional(keras.layers.LSTM(32, recurrent_dropout=0.1))(x)\n",
    "\n",
    "    output               = keras.layers.Dense(2)(x) #2 bc 2 class categories (0,1)\n",
    "    model                = keras.Model(features_input, output)\n",
    "    return model\n",
    "\n",
    "# Instead of model.compile, we're going to do custom training, so let's do that\n",
    "# within a strategy scope\n",
    "with strategy.scope():\n",
    "    # We will use sparse categorical crossentropy as always. But, instead of having the loss function\n",
    "    # manage the map reduce across GPUs for us, we'll do it ourselves with a simple algorithm.\n",
    "    # Remember -- the map reduce is how the losses get aggregated\n",
    "    # Set reduction to `none` so we can do the reduction afterwards and divide byglobal batch size.\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "    def compute_loss(labels, predictions):\n",
    "        # Compute Loss uses the loss object to compute the loss\n",
    "        # Notice that per_example_loss will have an entry per GPU\n",
    "        # so in this case there'll be 2 -- i.e. the loss for each replica\n",
    "        per_example_loss = loss_object(labels, predictions)\n",
    "        # You can print it to see it -- you'll get output like this:\n",
    "        # Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
    "        # Tensor(\"replica_1/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
    "        # Note in particular that replica_0 isn't named in the weighted_loss -- the first is unnamed, the second is replica_1 etc\n",
    "        print(per_example_loss)\n",
    "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
    "\n",
    "    # We'll just reduce by getting the average of the losses\n",
    "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "\n",
    "    # Accuracy on train and test will be SparseCategoricalAccuracy\n",
    "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "    # Optimizer will be Adam\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    # Create the model within the scope\n",
    "    model = create_model()\n",
    "\n",
    "\n",
    "###########################\n",
    "# Training Steps Functions\n",
    "###########################\n",
    "\n",
    "# `run` replicates the provided computation and runs it\n",
    "# with the distributed input.\n",
    "@tf.function\n",
    "def distributed_train_step(dataset_inputs):\n",
    "    per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n",
    "    #tf.print(per_replica_losses.values)\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "\n",
    "def train_step(inputs):\n",
    "    images, labels = inputs\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = compute_loss(labels, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_accuracy.update_state(labels, predictions)\n",
    "    return loss\n",
    "\n",
    "#######################\n",
    "# Test Steps Functions\n",
    "#######################\n",
    "@tf.function\n",
    "def distributed_test_step(dataset_inputs):\n",
    "    return strategy.run(test_step, args=(dataset_inputs,))\n",
    "\n",
    "def test_step(inputs):\n",
    "    images, labels = inputs\n",
    "\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss.update_state(t_loss)\n",
    "    test_accuracy.update_state(labels, predictions)\n",
    "\n",
    "\n",
    "###############\n",
    "# TRAINING LOOP\n",
    "###############\n",
    "\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    # Do Training\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for batch in train_dist_dataset:\n",
    "        total_loss += distributed_train_step(batch)\n",
    "        num_batches += 1\n",
    "    train_loss = total_loss / num_batches\n",
    "\n",
    "    # Do Testing\n",
    "    for batch in test_dist_dataset:\n",
    "        distributed_test_step(batch)\n",
    "\n",
    "    template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \" \"Test Accuracy: {}\")\n",
    "\n",
    "    print (template.format(epoch+1, train_loss, train_accuracy.result()*100, test_loss.result(), test_accuracy.result()*100))\n",
    "\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "695118e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvcc --version\n",
    "\n",
    "# Cuda compilation tools, release 11.6, V11.6.124\n",
    "# Build cuda_11.6.r11.6/compiler.31057947_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ea9c6",
   "metadata": {},
   "source": [
    "## Coursera Tutorial (Original Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0702412",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3202dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ae76231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = train_images[..., None]\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9cac9f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 19:51:12.379169: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_UINT8\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 60000\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\027TensorSliceDataset:1995\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 28\n",
      "        }\n",
      "        dim {\n",
      "          size: 28\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022-07-27 19:51:12.429704: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_UINT8\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 10000\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\027TensorSliceDataset:1998\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 28\n",
      "        }\n",
      "        dim {\n",
      "          size: 28\n",
      "        }\n",
      "        dim {\n",
      "          size: 1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_UINT8\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "Tensor(\"replica_1/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "Tensor(\"replica_1/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "Tensor(\"replica_1/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "Epoch 1, Loss: 0.5759216547012329, Accuracy: 79.16999816894531, Test Loss: 0.429978609085083, Test Accuracy: 83.9800033569336\n",
      "Epoch 2, Loss: 0.365640252828598, Accuracy: 86.96333312988281, Test Loss: 0.36686524748802185, Test Accuracy: 87.22000122070312\n",
      "Epoch 3, Loss: 0.32499638199806213, Accuracy: 88.23833465576172, Test Loss: 0.33308252692222595, Test Accuracy: 88.54000091552734\n",
      "Epoch 4, Loss: 0.2925156354904175, Accuracy: 89.5133285522461, Test Loss: 0.31743207573890686, Test Accuracy: 88.79000091552734\n",
      "Epoch 5, Loss: 0.27096027135849, Accuracy: 90.09666442871094, Test Loss: 0.2977234721183777, Test Accuracy: 89.42000579833984\n",
      "Epoch 6, Loss: 0.2564971148967743, Accuracy: 90.79166412353516, Test Loss: 0.2951880991458893, Test Accuracy: 89.52000427246094\n",
      "Epoch 7, Loss: 0.23627105355262756, Accuracy: 91.40999603271484, Test Loss: 0.27628055214881897, Test Accuracy: 89.97000122070312\n",
      "Epoch 8, Loss: 0.22289909422397614, Accuracy: 91.85166931152344, Test Loss: 0.2723405361175537, Test Accuracy: 90.31999969482422\n",
      "Epoch 9, Loss: 0.2036641538143158, Accuracy: 92.5183334350586, Test Loss: 0.2900109887123108, Test Accuracy: 89.36000061035156\n",
      "Epoch 10, Loss: 0.19559834897518158, Accuracy: 92.80166625976562, Test Loss: 0.28375181555747986, Test Accuracy: 89.9000015258789\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "# Note that it generally has a minimum of 8 cores, but if your GPU has\n",
    "# less, you need to set this. In this case one of my GPUs has 4 cores\n",
    "os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"] = \"4\"\n",
    "\n",
    "# If the list of devices is not specified in the\n",
    "# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\n",
    "# If you have *different* GPUs in your system, you probably have to set up cross_device_ops like this\n",
    "strategy = tf.distribute.MirroredStrategy(['/GPU:0', '/GPU:1'],cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "\n",
    "# Get the data\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Adding a dimension to the array -> new shape == (28, 28, 1)\n",
    "# We are doing this because the first layer in our model is a convolutional\n",
    "# layer and it requires a 4D input (batch_size, height, width, channels).\n",
    "# batch_size dimension will be added later on.\n",
    "train_images = train_images[..., None]\n",
    "test_images = test_images[..., None]\n",
    "\n",
    "# Normalize the images to [0, 1] range.\n",
    "train_images = train_images / np.float32(255)\n",
    "test_images = test_images / np.float32(255)\n",
    "\n",
    "# Batch the input data\n",
    "BUFFER_SIZE = len(train_images)\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "\n",
    "# Create Datasets from the batches\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\n",
    "\n",
    "# Create Distributed Datasets from the datasets\n",
    "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)\n",
    "\n",
    "# Create the model architecture\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Instead of model.compile, we're going to do custom training, so let's do that\n",
    "# within a strategy scope\n",
    "with strategy.scope():\n",
    "    # We will use sparse categorical crossentropy as always. But, instead of having the loss function\n",
    "    # manage the map reduce across GPUs for us, we'll do it ourselves with a simple algorithm.\n",
    "    # Remember -- the map reduce is how the losses get aggregated\n",
    "    # Set reduction to `none` so we can do the reduction afterwards and divide byglobal batch size.\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "    def compute_loss(labels, predictions):\n",
    "        # Compute Loss uses the loss object to compute the loss\n",
    "        # Notice that per_example_loss will have an entry per GPU\n",
    "        # so in this case there'll be 2 -- i.e. the loss for each replica\n",
    "        per_example_loss = loss_object(labels, predictions)\n",
    "        # You can print it to see it -- you'll get output like this:\n",
    "        # Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
    "        # Tensor(\"replica_1/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
    "        # Note in particular that replica_0 isn't named in the weighted_loss -- the first is unnamed, the second is replica_1 etc\n",
    "        print(per_example_loss)\n",
    "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
    "\n",
    "    # We'll just reduce by getting the average of the losses\n",
    "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "\n",
    "    # Accuracy on train and test will be SparseCategoricalAccuracy\n",
    "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "    # Optimizer will be Adam\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    # Create the model within the scope\n",
    "    model = create_model()\n",
    "\n",
    "\n",
    "###########################\n",
    "# Training Steps Functions\n",
    "###########################\n",
    "\n",
    "# `run` replicates the provided computation and runs it\n",
    "# with the distributed input.\n",
    "@tf.function\n",
    "def distributed_train_step(dataset_inputs):\n",
    "    per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n",
    "    #tf.print(per_replica_losses.values)\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "\n",
    "def train_step(inputs):\n",
    "    images, labels = inputs\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = compute_loss(labels, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_accuracy.update_state(labels, predictions)\n",
    "    return loss\n",
    "\n",
    "#######################\n",
    "# Test Steps Functions\n",
    "#######################\n",
    "@tf.function\n",
    "def distributed_test_step(dataset_inputs):\n",
    "    return strategy.run(test_step, args=(dataset_inputs,))\n",
    "\n",
    "def test_step(inputs):\n",
    "    images, labels = inputs\n",
    "\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss.update_state(t_loss)\n",
    "    test_accuracy.update_state(labels, predictions)\n",
    "\n",
    "\n",
    "###############\n",
    "# TRAINING LOOP\n",
    "###############\n",
    "\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    # Do Training\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for batch in train_dist_dataset:\n",
    "        total_loss += distributed_train_step(batch)\n",
    "        num_batches += 1\n",
    "    train_loss = total_loss / num_batches\n",
    "\n",
    "    # Do Testing\n",
    "    for batch in test_dist_dataset:\n",
    "        distributed_test_step(batch)\n",
    "\n",
    "    template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \" \"Test Accuracy: {}\")\n",
    "\n",
    "    print (template.format(epoch+1, train_loss, train_accuracy.result()*100, test_loss.result(), test_accuracy.result()*100))\n",
    "\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c57f1f",
   "metadata": {},
   "source": [
    "## WandB Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b49093b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Logging WandB metrics.\n"
     ]
    }
   ],
   "source": [
    "#log training and validation metrics on wandb\n",
    "for epoch, train_loss in enumerate(history.history['loss']):\n",
    "    wandb.log({'training_loss': train_loss, \"epoch\": epoch})\n",
    "    \n",
    "for epoch, train_acc in enumerate(history.history['accuracy']):\n",
    "    wandb.log({'training_accuracy': train_acc, \"epoch\": epoch})\n",
    "    \n",
    "for epoch, val_loss in enumerate(history.history['val_loss']):\n",
    "    wandb.log({'val_loss': val_loss, \"epoch\": epoch})\n",
    "    \n",
    "for epoch, val_acc in enumerate(history.history['val_accuracy']):\n",
    "    wandb.log({'val_accuracy': val_acc, \"epoch\": epoch})\n",
    "    \n",
    "print('Done Logging WandB metrics.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e72d4001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">helpful-dream-34</strong>: <a href=\"https://wandb.ai/epg/whale-classification-inception/runs/3dnifiv1\" target=\"_blank\">https://wandb.ai/epg/whale-classification-inception/runs/3dnifiv1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220727_135824-3dnifiv1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bcc6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
