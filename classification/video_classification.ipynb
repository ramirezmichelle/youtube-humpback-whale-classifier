{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "906e92fb",
   "metadata": {},
   "source": [
    "# Classifying YouTube Videos for Humpback Whale Encounters - Keras CNN-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adbf1a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bedc16e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import pickle\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import seaborn as sns\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2166e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngc workspace path (where we keep our data)\n",
    "workspace_path = '/mount/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c994d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start wandb session for metric logging\n",
    "wandb.login() \n",
    "\n",
    "wandb.init(project=\"whale-classification-inception\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07285b7d",
   "metadata": {},
   "source": [
    "# Inception V3 (CNN-RNN) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d881120c",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf385a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "MAX_NUM_FRAMES = 461\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "430e51ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(461, 224, 224, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read all frames in for 1 video from workspace 'frames' directory\n",
    "frames = []\n",
    "for i in range(461):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    #read in .jpg file as array for video clip 0000\n",
    "    img = cv2.imread(workspace_path + f'/frames/clip_0000_frame_{i}.jpg')\n",
    "    frames.append(img)\n",
    "\n",
    "frames = np.array(frames)\n",
    "frames.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529497ac",
   "metadata": {},
   "source": [
    "461 frames of size 224 x 224 with RGB color channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5508492",
   "metadata": {},
   "source": [
    "# Load Frames + Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "683ba998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction import load_frames, prepare_all_videos\n",
    "from cnn import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f97a76a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 461, 224, 224, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = load_frames('video_0033.mp4', MAX_NUM_FRAMES)\n",
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e577545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 13:18:08.244923: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-08 13:18:13.471221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14649 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:06:00.0, compute capability: 7.0\n",
      "2022-07-08 13:18:13.475227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14649 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:0b:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 4s 0us/step\n",
      "87924736/87910968 [==============================] - 4s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fc5772a7f70>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvNet = CNN(IMG_SIZE)\n",
    "feature_extractor = ConvNet.InceptionV3()\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "434c529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(workspace_path + '/downloaded_videos.csv')\n",
    "y = data.pop('relevant')\n",
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be05e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trial = X[0:5]\n",
    "y_trial = y[0:5]\n",
    "(frame_features, frame_masks), labels = prepare_all_videos(X_trial, y_trial, MAX_NUM_FRAMES, NUM_FEATURES, feature_extractor)\n",
    "\n",
    "#the error is probably bc of the label formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6440816f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 461, 2048)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Frame features shape: ', frame_features.shape)\n",
    "print('Frame masks shape: ', frame_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f2759cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
