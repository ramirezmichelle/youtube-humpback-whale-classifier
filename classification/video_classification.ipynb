{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc8ed2a6",
   "metadata": {},
   "source": [
    "# Classifying YouTube Videos for Humpback Whale Encounters - Keras CNN-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0e24491",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "945d6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import pickle\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc7f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngc workspace path (where we keep our data)\n",
    "workspace_path = '/mount/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eff231",
   "metadata": {},
   "source": [
    "# Start WandB Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "408fd3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmicheller\u001b[0m (\u001b[33mepg\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/youtube-humpback-whale-classifier/classification/wandb/run-20220711_214236-1tn4gbd3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/epg/whale-classification-inception/runs/1tn4gbd3\" target=\"_blank\">grateful-oath-4</a></strong> to <a href=\"https://wandb.ai/epg/whale-classification-inception\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/epg/whale-classification-inception/runs/1tn4gbd3?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fa8d0d03b80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "#start wandb session for metric logging\n",
    "wandb.login() \n",
    "\n",
    "wandb.init(project=\"whale-classification-inception\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d1c350",
   "metadata": {},
   "source": [
    "# Set GPU Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7505432a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs available:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs available: \", len(tf.config.list_physical_devices('GPU'))) #1 if we select GPU mode in Colab Notebook, 0 if running on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "854ea31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n",
      "/device:GPU:1\n"
     ]
    }
   ],
   "source": [
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "\n",
    "for gpu in gpus:\n",
    "    print(gpu.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa3768",
   "metadata": {},
   "source": [
    "# Inception V3 (CNN-RNN) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aa26ea",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5343d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "MAX_NUM_FRAMES = 461\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299bd329",
   "metadata": {},
   "source": [
    "461 frames of size 224 x 224 with RGB color channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3eacf",
   "metadata": {},
   "source": [
    "# Load Frames + Extract Features with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "570c3f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction import load_frames, prepare_all_videos\n",
    "from cnn import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1792d093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fa8d05d2790>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create CNN Feature Extractor\n",
    "ConvNet = CNN(IMG_SIZE)\n",
    "feature_extractor = ConvNet.InceptionV3()\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9577ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset in\n",
    "data = pd.read_csv(workspace_path + '/downloaded_videos.csv')\n",
    "y = data.pop('relevant')\n",
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da594a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_0000.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-11 21:43:32.420158: I tensorflow/stream_executor/cuda/cuda_dnn.cc:379] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_0134.mp4\n",
      "video_0248.mp4\n",
      "video_0357.mp4\n",
      "Time to extract frames with single GPU: 18351.396564483643s\n"
     ]
    }
   ],
   "source": [
    "#begin keeping track of time to extract ALL frames using a single GPU\n",
    "start = time.time()\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    (frame_features, frame_masks), labels = prepare_all_videos(X, y, MAX_NUM_FRAMES, NUM_FEATURES, feature_extractor)\n",
    "    \n",
    "stop = time.time()\n",
    "\n",
    "print(f\"Time to extract frames with single GPU: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af83611c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.097610156801012"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#took 5 hours to extract features from frames with the GPU context set above\n",
    "(stop-start)/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c421545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame features shape:  (364, 461, 2048)\n",
      "Frame masks shape:  (364, 461)\n",
      "Number of Labels:  364\n"
     ]
    }
   ],
   "source": [
    "print('Frame features shape: ', frame_features.shape)\n",
    "print('Frame masks shape: ', frame_masks.shape)\n",
    "print('Number of Labels: ', len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5805b8aa",
   "metadata": {},
   "source": [
    "# Training RNN Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afbafb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn import RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce28d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ada3c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 \n",
      "\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6074 - accuracy: 0.7260\n",
      "Fold 1 \n",
      "\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6143 - accuracy: 0.7397\n",
      "Fold 2 \n",
      "\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5738 - accuracy: 0.7123\n",
      "Fold 3 \n",
      "\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6128 - accuracy: 0.7123\n",
      "Fold 4 \n",
      "\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5561 - accuracy: 0.8056\n"
     ]
    }
   ],
   "source": [
    "#training RNN with 5 fold cross validation\n",
    "\n",
    "skfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state=42)\n",
    "fold = 0\n",
    "\n",
    "test_acc_per_fold       = dict()\n",
    "test_loss_per_fold      = dict()\n",
    "fold_train_test_indices = dict() #{'fold_model_name': [fold_train_index_list, fold_test_index_list]}\n",
    "\n",
    "for train_index, test_index in skfold.split(X, y):\n",
    "    \n",
    "    print(f'Fold {fold} \\n')\n",
    "    \n",
    "    #index data accordingly\n",
    "    train_features, train_masks, train_labels = frame_features[train_index], frame_masks[train_index], np.array(labels)[train_index]\n",
    "    test_features, test_masks, test_labels = frame_features[test_index], frame_masks[test_index], np.array(labels)[test_index]\n",
    "    \n",
    "    #reshape label arrays as horizontal arrays\n",
    "    train_labels = np.reshape(train_labels, (train_labels.shape[0], 1))\n",
    "    test_labels = np.reshape(test_labels, (test_labels.shape[0], 1))\n",
    "    \n",
    "    #create and compile model\n",
    "    rnn_model.build_model(MAX_NUM_FRAMES, NUM_FEATURES)\n",
    "    rnn_model.compile_model(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n",
    "    \n",
    "    #train and evaluate the model\n",
    "    rnn_model.fit(train_features, train_masks, train_labels, f'rnn_model_{fold}')\n",
    "    loss, accuracy = rnn_model.evaluate(test_features, test_masks, test_labels)\n",
    "    \n",
    "    #store the test accuracies and loss for each fold model\n",
    "    test_acc_per_fold[fold]       = accuracy\n",
    "    test_loss_per_fold[fold]      = loss\n",
    "    fold_train_test_indices[fold] = [train_index, test_index]\n",
    "    \n",
    "    fold += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ef810b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364, 11)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c23f31",
   "metadata": {},
   "source": [
    "# Fitting Model without Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c59fecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split data into 80% train, 20% test. Both test and train contain balanced class proportions (half rel, half not rel) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6e52fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6388 - accuracy: 0.7123\n",
      "Loss: 0.6387816667556763, Accuracy: 0.7123287916183472\n",
      "F1: [0.75862069 0.6440678 ], Precision: [0.67346939 0.79166667], Recall: [0.86842105 0.54285714]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "rnn_model = RNN()\n",
    "\n",
    "train_index = list(X_train.index)\n",
    "test_index = list(X_test.index)\n",
    "\n",
    "#index data accordingly\n",
    "train_features, train_masks, train_labels = frame_features[train_index], frame_masks[train_index], np.array(labels)[train_index]\n",
    "test_features, test_masks, test_labels = frame_features[test_index], frame_masks[test_index], np.array(labels)[test_index]\n",
    "\n",
    "#reshape label arrays as horizontal arrays\n",
    "train_labels = np.reshape(train_labels, (train_labels.shape[0], 1))\n",
    "test_labels = np.reshape(test_labels, (test_labels.shape[0], 1))\n",
    "\n",
    "#create and compile model\n",
    "rnn_model.build_model(MAX_NUM_FRAMES, NUM_FEATURES)\n",
    "rnn_model.compile_model(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n",
    "\n",
    "#train model\n",
    "rnn_model.fit(train_features, train_masks, train_labels, f'rnn_model_{fold}')\n",
    "\n",
    "#evaluate model on test set\n",
    "loss, accuracy = rnn_model.evaluate(test_features, test_masks, test_labels)\n",
    "\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
    "\n",
    "#get f1, precision, recall, support metrics\n",
    "y_pred = rnn_model.predict(test_features, test_masks)\n",
    "y_true = test_labels.flatten()\n",
    "\n",
    "cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "precision, recall, f1, support =  metrics.precision_recall_fscore_support(y_true, y_pred)\n",
    "\n",
    "print(f\"F1: {f1}, Precision: {precision}, Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6ae77637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot confusion matrix\n",
    "sns.heatmap(cm, annot = True, fmt = \".3f\", square = True, cmap = plt.cm.Blues)\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Inception CNN-RNN Predictions Results')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "980b7ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▁</td></tr><tr><td>loss</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.71233</td></tr><tr><td>loss</td><td>0.63878</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">grateful-oath-4</strong>: <a href=\"https://wandb.ai/epg/whale-classification-inception/runs/1tn4gbd3\" target=\"_blank\">https://wandb.ai/epg/whale-classification-inception/runs/1tn4gbd3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220711_214236-1tn4gbd3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.log({'accuracy': accuracy, 'loss': loss})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eda9cd",
   "metadata": {},
   "source": [
    "## TF Distribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    # Make a simple 2-layer densely-connected neural network.\n",
    "    inputs = keras.Input(shape=(784,))\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(inputs)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    outputs = keras.layers.Dense(10)(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    batch_size = 32\n",
    "    num_val_samples = 10000\n",
    "\n",
    "    # Return the MNIST dataset in the form of a [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset).\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Preprocess the data (these are Numpy arrays)\n",
    "    x_train = x_train.reshape(-1, 784).astype(\"float32\") / 255\n",
    "    x_test = x_test.reshape(-1, 784).astype(\"float32\") / 255\n",
    "    y_train = y_train.astype(\"float32\")\n",
    "    y_test = y_test.astype(\"float32\")\n",
    "\n",
    "    # Reserve num_val_samples samples for validation\n",
    "    x_val = x_train[-num_val_samples:]\n",
    "    y_val = y_train[-num_val_samples:]\n",
    "    x_train = x_train[:-num_val_samples]\n",
    "    y_train = y_train[:-num_val_samples]\n",
    "    return (\n",
    "        tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size),\n",
    "        tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size),\n",
    "        tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size),\n",
    "    )\n",
    "\n",
    "\n",
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    model = get_compiled_model()\n",
    "\n",
    "# Train the model on all available devices.\n",
    "train_dataset, val_dataset, test_dataset = get_dataset()\n",
    "model.fit(train_dataset, epochs=2, validation_data=val_dataset)\n",
    "\n",
    "# Test the model on all available devices.\n",
    "model.evaluate(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
