{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e921b98",
   "metadata": {},
   "source": [
    "# Implementing C3D Model for Video Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05454b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import pickle\n",
    "import glob\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import seaborn as sns\n",
    "\n",
    " \n",
    "# adding video-download folder to the system path\n",
    "sys.path.insert(0, '/workspace/youtube-humpback-whale-classifier/video-download')\n",
    " \n",
    "# importing read_frames_hdf5 function\n",
    "from hdf5_data_loading import read_frames_hdf5\n",
    "\n",
    "#ngc workspace path (where we keep our data)\n",
    "workspace_path = '/mount/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b1499d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmicheller\u001b[0m (\u001b[33mepg\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/youtube-humpback-whale-classifier/classification/wandb/run-20220725_233342-2vjofs3a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/epg/whale-classification-inception/runs/2vjofs3a\" target=\"_blank\">devout-forest-25</a></strong> to <a href=\"https://wandb.ai/epg/whale-classification-inception\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "#start wandb session for metric logging\n",
    "wandb.login() \n",
    "\n",
    "wandb.init(project=\"whale-classification-inception\")\n",
    "\n",
    "wandb.run.name = \"c3d-training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df570caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs available:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs available: \", len(tf.config.list_physical_devices('GPU'))) #1 if we select GPU mode in Colab Notebook, 0 if running on local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2734cf06",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebc0fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset in\n",
    "data = pd.read_csv(workspace_path + '/downloaded_videos.csv')\n",
    "y = data.pop('relevant')\n",
    "X = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e16b7ef",
   "metadata": {},
   "source": [
    "## Load Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08735eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading frames for video 0...\n",
      "Loading frames for video 50...\n",
      "Loading frames for video 100...\n",
      "Loading frames for video 150...\n",
      "Loading frames for video 200...\n",
      "Loading frames for video 250...\n",
      "Loading frames for video 300...\n",
      "Loading frames for video 350...\n",
      "Done loading frames in 172.62159085273743 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(364, 30, 224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in frames for all videos\n",
    "start = time.time()\n",
    "\n",
    "N = X.shape[0] #number of videos in our dataset\n",
    "videos = np.empty((N, 30, 224, 224, 3), dtype=np.uint8)\n",
    "labels = np.empty(N, dtype = np.uint8)\n",
    "\n",
    "for i, video in enumerate(list(X.renamed_title)):\n",
    "    if i % 50 == 0:\n",
    "        print(f'Loading frames for video {i}...')\n",
    "        \n",
    "    clip_name = video.replace(\"_\", \"_clip_\").replace(\".mp4\", \"\")\n",
    "    frames, frame_labels = read_frames_hdf5(clip_name) #returns frames array of shape (461, 224, 224, 3)\n",
    "    \n",
    "    videos[i, ...] = frames[15:45] #shortened videos bc of memory issue - each video is reduced to 30 frames\n",
    "    labels[i] = frame_labels[0] #all frames have the same label since label is assigned to overall video\n",
    "\n",
    "stop = time.time()\n",
    "print(f'Done loading frames in {stop-start} seconds.')\n",
    "videos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32350c09",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fa96116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "train_index = list(X_train.index)\n",
    "test_index = list(X_test.index)\n",
    "\n",
    "# index data accordingly\n",
    "train_videos, train_labels = videos[train_index], labels[train_index]\n",
    "test_videos, test_labels = videos[test_index], labels[test_index]\n",
    "\n",
    "# reshape label arrays as horizontal arrays\n",
    "train_labels = np.reshape(train_labels, (train_labels.shape[0], 1))\n",
    "test_labels = np.reshape(test_labels, (test_labels.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9767d7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 30, 224, 224, 3)\n",
      "(73, 30, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_videos.shape)\n",
    "print(test_videos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d213fd30",
   "metadata": {},
   "source": [
    "## Converting Data into TF Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc2bf57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 23:37:27.760440: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-25 23:37:32.468881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14649 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:85:00.0, compute capability: 7.0\n",
      "2022-07-25 23:37:32.477385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14649 MB memory:  -> device: 1, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:86:00.0, compute capability: 7.0\n",
      "2022-07-25 23:37:32.483364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14649 MB memory:  -> device: 2, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:89:00.0, compute capability: 7.0\n",
      "2022-07-25 23:37:32.485297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 14649 MB memory:  -> device: 3, name: Tesla V100-SXM2-16GB-N, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 30, 224, 224, 3), dtype=tf.uint8, name=None), TensorSpec(shape=(None, 1), dtype=tf.uint8, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tf = tf.data.Dataset.from_tensor_slices((train_videos, train_labels)).batch(10)\n",
    "train_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c475c70",
   "metadata": {},
   "source": [
    "`GPU keeps allocating 15516MiB everytime we load any sort of data, which leads to running out of memory at model training`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743b4d1b",
   "metadata": {},
   "source": [
    "## Build C3D Video Classification Model\n",
    "\n",
    "Resources\n",
    "- https://towardsdatascience.com/step-by-step-implementation-3d-convolutional-neural-network-in-keras-12efbdd7b130\n",
    "- https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7410867&tag=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eb31c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "# print(os.getenv('TF_GPU_ALLOCATOR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d37f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aebecff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ready\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 30, 224, 224, 3)  0         \n",
      "                             ]                                   \n",
      "                                                                 \n",
      " conv3d_8 (Conv3D)           (None, 28, 222, 222, 64)  5248      \n",
      "                                                                 \n",
      " max_pooling3d_5 (MaxPooling  (None, 27, 221, 222, 64)  0        \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_9 (Conv3D)           (None, 25, 219, 220, 128  221312    \n",
      "                             )                                   \n",
      "                                                                 \n",
      " max_pooling3d_6 (MaxPooling  (None, 24, 218, 219, 128  0        \n",
      " 3D)                         )                                   \n",
      "                                                                 \n",
      " conv3d_10 (Conv3D)          (None, 22, 216, 217, 256  884992    \n",
      "                             )                                   \n",
      "                                                                 \n",
      " conv3d_11 (Conv3D)          (None, 20, 214, 215, 256  1769728   \n",
      "                             )                                   \n",
      "                                                                 \n",
      " max_pooling3d_7 (MaxPooling  (None, 19, 213, 214, 256  0        \n",
      " 3D)                         )                                   \n",
      "                                                                 \n",
      " conv3d_12 (Conv3D)          (None, 17, 211, 212, 512  3539456   \n",
      "                             )                                   \n",
      "                                                                 \n",
      " conv3d_13 (Conv3D)          (None, 15, 209, 210, 512  7078400   \n",
      "                             )                                   \n",
      "                                                                 \n",
      " max_pooling3d_8 (MaxPooling  (None, 14, 208, 209, 512  0        \n",
      " 3D)                         )                                   \n",
      "                                                                 \n",
      " conv3d_14 (Conv3D)          (None, 12, 206, 207, 512  7078400   \n",
      "                             )                                   \n",
      "                                                                 \n",
      " conv3d_15 (Conv3D)          (None, 10, 204, 205, 512  7078400   \n",
      "                             )                                   \n",
      "                                                                 \n",
      " max_pooling3d_9 (MaxPooling  (None, 9, 203, 204, 512)  0        \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 190826496)         0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 190826497 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 218,482,433\n",
      "Trainable params: 218,482,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 23:41:55.525667: I tensorflow/stream_executor/cuda/cuda_dnn.cc:379] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 104s 8s/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 2/16\n",
      "10/10 [==============================] - 33s 3s/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 3/16\n",
      "10/10 [==============================] - 22s 2s/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 4/16\n",
      "10/10 [==============================] - 22s 2s/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 5/16\n",
      "10/10 [==============================] - 22s 2s/step - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 6/16\n",
      " 7/10 [====================>.........] - ETA: 6s - loss: nan - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m c3d_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     30\u001b[0m c3d_model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m---> 32\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mc3d_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "fake_data = tf.random.normal((10, 30, 224, 224, 3))\n",
    "fake_label = tf.random.normal((10,))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((fake_data, fake_label)).batch(1)\n",
    "print(\"Data ready\")\n",
    "\n",
    "inputs = keras.Input(shape=(30, 224, 224, 3)) #full shape w/ batch dim = (None, 30, 224, 224, 3)\n",
    "x = Conv3D(64, kernel_size=(3,3,3), strides=(1,1,1))(inputs)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 1), strides=(1,1,1))(x)\n",
    "x = Conv3D(128, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2), strides=(1,1,1))(x)\n",
    "x = Conv3D(256, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = Conv3D(256, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2), strides=(1,1,1))(x)\n",
    "x = Conv3D(512, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = Conv3D(512, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2), strides=(1,1,1))(x)\n",
    "x = Conv3D(512, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = Conv3D(512, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2), strides=(1,1,1))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "output = Dense(1, activation=\"softmax\")(x)\n",
    "\n",
    "c3d_model = keras.Model(inputs, output)\n",
    "c3d_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "c3d_model.summary()\n",
    "\n",
    "history = c3d_model.fit(dataset,\n",
    "                        epochs = 16,\n",
    "                        verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "927e7f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 15:29:15.737747: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.97GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-25 15:29:32.201582: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.63GiB (rounded to 2826854400)requested by op model_1/conv3d_11/Conv3D\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-07-25 15:29:32.201657: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
      "2022-07-25 15:29:32.201680: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 61, Chunks in use: 60. 15.2KiB allocated for chunks. 15.0KiB in use in bin. 1.8KiB client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201695: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 7, Chunks in use: 7. 3.5KiB allocated for chunks. 3.5KiB in use in bin. 3.3KiB client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201709: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 13, Chunks in use: 13. 13.2KiB allocated for chunks. 13.2KiB in use in bin. 13.0KiB client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201724: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 24, Chunks in use: 24. 48.0KiB allocated for chunks. 48.0KiB in use in bin. 48.0KiB client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201738: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201750: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201766: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 19, Chunks in use: 18. 358.5KiB allocated for chunks. 338.2KiB in use in bin. 313.5KiB client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201779: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201791: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201803: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201816: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201830: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 4, Chunks in use: 4. 3.38MiB allocated for chunks. 3.38MiB in use in bin. 3.38MiB client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201843: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 2, Chunks in use: 2. 3.30MiB allocated for chunks. 3.30MiB in use in bin. 1.69MiB client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201857: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 2, Chunks in use: 2. 6.75MiB allocated for chunks. 6.75MiB in use in bin. 6.75MiB client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201872: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 8, Chunks in use: 8. 52.19MiB allocated for chunks. 52.19MiB in use in bin. 40.50MiB client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201888: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 14, Chunks in use: 14. 164.50MiB allocated for chunks. 164.50MiB in use in bin. 142.50MiB client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201903: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 17, Chunks in use: 16. 457.82MiB allocated for chunks. 432.00MiB in use in bin. 432.00MiB client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201918: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 3, Chunks in use: 3. 118.67MiB allocated for chunks. 118.67MiB in use in bin. 105.68MiB client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201939: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 6, Chunks in use: 6. 384.00MiB allocated for chunks. 384.00MiB in use in bin. 384.00MiB client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201952: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201966: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 9, Chunks in use: 7. 13.14GiB allocated for chunks. 10.46GiB in use in bin. 10.42GiB client-requested in use in bin.\n",
      "2022-07-25 15:29:32.201979: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 2.63GiB was 256.00MiB, Chunk State: \n",
      "2022-07-25 15:29:32.201998: I tensorflow/core/common_runtime/bfc_allocator.cc:1039]   Size: 985.57MiB | Requested Size: 37.82MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.95GiB | Requested Size: 2.95GiB | in_use: 1 | bin_num: -1\n",
      "2022-07-25 15:29:32.202018: I tensorflow/core/common_runtime/bfc_allocator.cc:1039]   Size: 1.72GiB | Requested Size: 1.64GiB | in_use: 0 | bin_num: 20, prev:   Size: 970.22MiB | Requested Size: 970.22MiB | in_use: 1 | bin_num: -1, next:   Size: 1.72GiB | Requested Size: 1.72GiB | in_use: 1 | bin_num: -1\n",
      "2022-07-25 15:29:32.202028: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 15361376256\n",
      "2022-07-25 15:29:32.202042: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef2f8000000 of size 1314109440 next 1\n",
      "2022-07-25 15:29:32.202053: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653b800 of size 1280 next 2\n",
      "2022-07-25 15:29:32.202063: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653bd00 of size 512 next 3\n",
      "2022-07-25 15:29:32.202074: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653bf00 of size 256 next 4\n",
      "2022-07-25 15:29:32.202084: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c000 of size 256 next 5\n",
      "2022-07-25 15:29:32.202094: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c100 of size 256 next 6\n",
      "2022-07-25 15:29:32.202104: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c200 of size 256 next 7\n",
      "2022-07-25 15:29:32.202114: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c300 of size 256 next 8\n",
      "2022-07-25 15:29:32.202125: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c400 of size 256 next 9\n",
      "2022-07-25 15:29:32.202135: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c500 of size 256 next 12\n",
      "2022-07-25 15:29:32.202145: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c600 of size 256 next 13\n",
      "2022-07-25 15:29:32.202156: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c700 of size 512 next 14\n",
      "2022-07-25 15:29:32.202166: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653c900 of size 256 next 17\n",
      "2022-07-25 15:29:32.202176: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653ca00 of size 256 next 18\n",
      "2022-07-25 15:29:32.202187: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653cb00 of size 1024 next 19\n",
      "2022-07-25 15:29:32.202197: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653cf00 of size 256 next 22\n",
      "2022-07-25 15:29:32.202207: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653d000 of size 256 next 23\n",
      "2022-07-25 15:29:32.202218: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653d100 of size 1024 next 26\n",
      "2022-07-25 15:29:32.202228: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653d500 of size 256 next 27\n",
      "2022-07-25 15:29:32.202238: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653d600 of size 256 next 28\n",
      "2022-07-25 15:29:32.202248: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653d700 of size 2048 next 29\n",
      "2022-07-25 15:29:32.202259: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653df00 of size 256 next 32\n",
      "2022-07-25 15:29:32.202269: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653e000 of size 256 next 33\n",
      "2022-07-25 15:29:32.202283: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653e100 of size 2048 next 36\n",
      "2022-07-25 15:29:32.202294: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653e900 of size 2048 next 38\n",
      "2022-07-25 15:29:32.202307: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653f100 of size 2048 next 40\n",
      "2022-07-25 15:29:32.202317: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653f900 of size 256 next 41\n",
      "2022-07-25 15:29:32.202331: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653fa00 of size 256 next 42\n",
      "2022-07-25 15:29:32.202346: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34653fb00 of size 27392 next 10\n",
      "2022-07-25 15:29:32.202358: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346546600 of size 20736 next 11\n",
      "2022-07-25 15:29:32.202368: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654b700 of size 256 next 43\n",
      "2022-07-25 15:29:32.202383: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654b800 of size 256 next 44\n",
      "2022-07-25 15:29:32.202394: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654b900 of size 16384 next 46\n",
      "2022-07-25 15:29:32.202407: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654f900 of size 256 next 49\n",
      "2022-07-25 15:29:32.202418: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654fa00 of size 256 next 50\n",
      "2022-07-25 15:29:32.202431: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654fb00 of size 256 next 51\n",
      "2022-07-25 15:29:32.202441: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654fc00 of size 256 next 52\n",
      "2022-07-25 15:29:32.202455: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654fd00 of size 256 next 53\n",
      "2022-07-25 15:29:32.202465: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654fe00 of size 256 next 54\n",
      "2022-07-25 15:29:32.202478: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34654ff00 of size 256 next 55\n",
      "2022-07-25 15:29:32.202494: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346550000 of size 256 next 56\n",
      "2022-07-25 15:29:32.202508: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346550100 of size 256 next 57\n",
      "2022-07-25 15:29:32.202518: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346550200 of size 256 next 58\n",
      "2022-07-25 15:29:32.202531: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346550300 of size 256 next 59\n",
      "2022-07-25 15:29:32.202542: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346550400 of size 20736 next 60\n",
      "2022-07-25 15:29:32.202555: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346555500 of size 256 next 61\n",
      "2022-07-25 15:29:32.202565: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346555600 of size 1728768 next 16\n",
      "2022-07-25 15:29:32.202580: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3466fb700 of size 884736 next 15\n",
      "2022-07-25 15:29:32.202594: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3467d3700 of size 512 next 62\n",
      "2022-07-25 15:29:32.202605: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3467d3900 of size 7077376 next 21\n",
      "2022-07-25 15:29:32.202620: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef346e93700 of size 3538944 next 20\n",
      "2022-07-25 15:29:32.202630: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471f3700 of size 1024 next 63\n",
      "2022-07-25 15:29:32.202643: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471f3b00 of size 1024 next 65\n",
      "2022-07-25 15:29:32.202654: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471f3f00 of size 2048 next 67\n",
      "2022-07-25 15:29:32.202667: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471f4700 of size 2048 next 69\n",
      "2022-07-25 15:29:32.202677: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471f4f00 of size 2048 next 71\n",
      "2022-07-25 15:29:32.202690: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471f5700 of size 2048 next 73\n",
      "2022-07-25 15:29:32.202701: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471f5f00 of size 16384 next 74\n",
      "2022-07-25 15:29:32.202714: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471f9f00 of size 16384 next 76\n",
      "2022-07-25 15:29:32.202725: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3471fdf00 of size 20736 next 77\n",
      "2022-07-25 15:29:32.202738: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef347203000 of size 256 next 78\n",
      "2022-07-25 15:29:32.202749: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef347203100 of size 884736 next 79\n",
      "2022-07-25 15:29:32.202762: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3472db100 of size 512 next 80\n",
      "2022-07-25 15:29:32.202773: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3472db300 of size 6128640 next 25\n",
      "2022-07-25 15:29:32.202783: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3478b3700 of size 7077888 next 24\n",
      "2022-07-25 15:29:32.202796: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef347f73700 of size 7077888 next 64\n",
      "2022-07-25 15:29:32.202812: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef348633700 of size 9699328 next 45\n",
      "2022-07-25 15:29:32.202827: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef348f73700 of size 11534336 next 31\n",
      "2022-07-25 15:29:32.202838: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef349a73700 of size 14155776 next 30\n",
      "2022-07-25 15:29:32.202852: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34a7f3700 of size 14155776 next 66\n",
      "2022-07-25 15:29:32.202863: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34b573700 of size 1024 next 81\n",
      "2022-07-25 15:29:32.202876: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34b573b00 of size 14154752 next 35\n",
      "2022-07-25 15:29:32.202892: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34c2f3700 of size 28311552 next 34\n",
      "2022-07-25 15:29:32.202907: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34ddf3700 of size 28311552 next 37\n",
      "2022-07-25 15:29:32.202917: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef34f8f3700 of size 28311552 next 39\n",
      "2022-07-25 15:29:32.202928: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3513f3700 of size 28311552 next 68\n",
      "2022-07-25 15:29:32.202941: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef352ef3700 of size 28311552 next 70\n",
      "2022-07-25 15:29:32.202952: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3549f3700 of size 28311552 next 72\n",
      "2022-07-25 15:29:32.202965: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3564f3700 of size 1024 next 82\n",
      "2022-07-25 15:29:32.202979: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3564f3b00 of size 14155776 next 83\n",
      "2022-07-25 15:29:32.202990: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef357273b00 of size 2048 next 84\n",
      "2022-07-25 15:29:32.203004: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef357274300 of size 35124224 next 48\n",
      "2022-07-25 15:29:32.203019: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3593f3700 of size 67108864 next 47\n",
      "2022-07-25 15:29:32.203034: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef35d3f3700 of size 67108864 next 75\n",
      "2022-07-25 15:29:32.203045: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3613f3700 of size 2048 next 85\n",
      "2022-07-25 15:29:32.203055: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3613f3f00 of size 28311552 next 86\n",
      "2022-07-25 15:29:32.203065: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef362ef3f00 of size 2048 next 87\n",
      "2022-07-25 15:29:32.203075: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef362ef4700 of size 28311552 next 88\n",
      "2022-07-25 15:29:32.203089: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3649f4700 of size 2048 next 89\n",
      "2022-07-25 15:29:32.203100: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3649f4f00 of size 8388608 next 90\n",
      "2022-07-25 15:29:32.203114: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3651f4f00 of size 16384 next 91\n",
      "2022-07-25 15:29:32.203124: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3651f8f00 of size 67108864 next 92\n",
      "2022-07-25 15:29:32.203138: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691f8f00 of size 16384 next 93\n",
      "2022-07-25 15:29:32.203148: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fcf00 of size 256 next 94\n",
      "2022-07-25 15:29:32.203162: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd000 of size 256 next 95\n",
      "2022-07-25 15:29:32.203173: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd100 of size 256 next 96\n",
      "2022-07-25 15:29:32.203186: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd200 of size 256 next 97\n",
      "2022-07-25 15:29:32.203196: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd300 of size 256 next 98\n",
      "2022-07-25 15:29:32.203210: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd400 of size 256 next 99\n",
      "2022-07-25 15:29:32.203220: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd500 of size 256 next 100\n",
      "2022-07-25 15:29:32.203234: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd600 of size 256 next 106\n",
      "2022-07-25 15:29:32.203244: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd700 of size 512 next 107\n",
      "2022-07-25 15:29:32.203255: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fd900 of size 1024 next 111\n",
      "2022-07-25 15:29:32.203269: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fdd00 of size 1024 next 115\n",
      "2022-07-25 15:29:32.203280: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fe100 of size 2048 next 113\n",
      "2022-07-25 15:29:32.203290: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691fe900 of size 2048 next 118\n",
      "2022-07-25 15:29:32.203303: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691ff100 of size 2048 next 120\n",
      "2022-07-25 15:29:32.203314: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3691ff900 of size 2048 next 122\n",
      "2022-07-25 15:29:32.203327: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369200100 of size 30720 next 101\n",
      "2022-07-25 15:29:32.203341: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369207900 of size 20736 next 102\n",
      "2022-07-25 15:29:32.203355: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef36920ca00 of size 16384 next 123\n",
      "2022-07-25 15:29:32.203370: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369210a00 of size 256 next 127\n",
      "2022-07-25 15:29:32.203380: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369210b00 of size 256 next 128\n",
      "2022-07-25 15:29:32.203393: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369210c00 of size 256 next 129\n",
      "2022-07-25 15:29:32.203404: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369210d00 of size 20736 next 130\n",
      "2022-07-25 15:29:32.203417: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369215e00 of size 256 next 131\n",
      "2022-07-25 15:29:32.203432: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369215f00 of size 1731328 next 108\n",
      "2022-07-25 15:29:32.203446: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3693bca00 of size 884736 next 103\n",
      "2022-07-25 15:29:32.203457: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369494a00 of size 512 next 132\n",
      "2022-07-25 15:29:32.203467: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369494c00 of size 7077376 next 110\n",
      "2022-07-25 15:29:32.203481: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369b54a00 of size 3538944 next 112\n",
      "2022-07-25 15:29:32.203492: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369eb4a00 of size 1024 next 133\n",
      "2022-07-25 15:29:32.203505: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369eb4e00 of size 1024 next 135\n",
      "2022-07-25 15:29:32.203533: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369eb5200 of size 2048 next 137\n",
      "2022-07-25 15:29:32.203545: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369eb5a00 of size 2048 next 139\n",
      "2022-07-25 15:29:32.203558: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369eb6200 of size 2048 next 141\n",
      "2022-07-25 15:29:32.203569: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369eb6a00 of size 2048 next 143\n",
      "2022-07-25 15:29:32.203582: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369eb7200 of size 16384 next 144\n",
      "2022-07-25 15:29:32.203592: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369ebb200 of size 16384 next 146\n",
      "2022-07-25 15:29:32.203607: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369ebf200 of size 20736 next 147\n",
      "2022-07-25 15:29:32.203618: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369ec4300 of size 256 next 148\n",
      "2022-07-25 15:29:32.203628: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369ec4400 of size 884736 next 149\n",
      "2022-07-25 15:29:32.203642: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369f9c400 of size 512 next 150\n",
      "2022-07-25 15:29:32.203652: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef369f9c600 of size 6128640 next 117\n",
      "2022-07-25 15:29:32.203666: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef36a574a00 of size 7077888 next 116\n",
      "2022-07-25 15:29:32.203677: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef36ac34a00 of size 7077888 next 134\n",
      "2022-07-25 15:29:32.203690: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef36b2f4a00 of size 9699328 next 125\n",
      "2022-07-25 15:29:32.203701: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef36bc34a00 of size 11534336 next 109\n",
      "2022-07-25 15:29:32.203714: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef36c734a00 of size 14155776 next 114\n",
      "2022-07-25 15:29:32.203729: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef36d4b4a00 of size 14155776 next 136\n",
      "2022-07-25 15:29:32.203743: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef36e234a00 of size 1024 next 151\n",
      "2022-07-25 15:29:32.203754: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef36e234e00 of size 14154752 next 104\n",
      "2022-07-25 15:29:32.203767: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef36efb4a00 of size 28311552 next 105\n",
      "2022-07-25 15:29:32.203778: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef370ab4a00 of size 28311552 next 119\n",
      "2022-07-25 15:29:32.203791: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3725b4a00 of size 28311552 next 121\n",
      "2022-07-25 15:29:32.203801: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3740b4a00 of size 28311552 next 138\n",
      "2022-07-25 15:29:32.203814: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef375bb4a00 of size 28311552 next 140\n",
      "2022-07-25 15:29:32.203825: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3776b4a00 of size 28311552 next 142\n",
      "2022-07-25 15:29:32.203838: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3791b4a00 of size 1024 next 152\n",
      "2022-07-25 15:29:32.203849: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3791b4e00 of size 14155776 next 153\n",
      "2022-07-25 15:29:32.203862: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef379f34e00 of size 2048 next 154\n",
      "2022-07-25 15:29:32.203872: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef379f35600 of size 35124224 next 126\n",
      "2022-07-25 15:29:32.203885: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef37c0b4a00 of size 67108864 next 124\n",
      "2022-07-25 15:29:32.203896: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3800b4a00 of size 67108864 next 145\n",
      "2022-07-25 15:29:32.203906: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3840b4a00 of size 2048 next 155\n",
      "2022-07-25 15:29:32.203920: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3840b5200 of size 28311552 next 156\n",
      "2022-07-25 15:29:32.203935: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef385bb5200 of size 2048 next 157\n",
      "2022-07-25 15:29:32.203946: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef385bb5a00 of size 28311552 next 158\n",
      "2022-07-25 15:29:32.203959: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3876b5a00 of size 2048 next 159\n",
      "2022-07-25 15:29:32.203974: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3876b6200 of size 8388608 next 160\n",
      "2022-07-25 15:29:32.203985: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef387eb6200 of size 16384 next 161\n",
      "2022-07-25 15:29:32.203998: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef387eba200 of size 67108864 next 162\n",
      "2022-07-25 15:29:32.204008: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef38beba200 of size 16384 next 163\n",
      "2022-07-25 15:29:32.204022: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef38bebe200 of size 256 next 164\n",
      "2022-07-25 15:29:32.204032: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef38bebe300 of size 256 next 165\n",
      "2022-07-25 15:29:32.204042: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef38bebe400 of size 256 next 166\n",
      "2022-07-25 15:29:32.204056: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef38bebe500 of size 256 next 167\n",
      "2022-07-25 15:29:32.204066: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef38bebe600 of size 256 next 168\n",
      "2022-07-25 15:29:32.204080: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef38bebe700 of size 256 next 169\n",
      "2022-07-25 15:29:32.204095: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef38bebe800 of size 256 next 170\n",
      "2022-07-25 15:29:32.204105: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef38bebe900 of size 256 next 172\n",
      "2022-07-25 15:29:32.204118: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7ef38bebea00 of size 20736 next 178\n",
      "2022-07-25 15:29:32.204129: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef38bec3b00 of size 256 next 179\n",
      "2022-07-25 15:29:32.204142: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef38bec3c00 of size 256 next 180\n",
      "2022-07-25 15:29:32.204152: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7ef38bec3d00 of size 256 next 181\n",
      "2022-07-25 15:29:32.204166: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef38bec3e00 of size 256 next 183\n",
      "2022-07-25 15:29:32.204180: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7ef38bec3f00 of size 27073280 next 173\n",
      "2022-07-25 15:29:32.204191: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef38d895a00 of size 256 next 174\n",
      "2022-07-25 15:29:32.204204: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef38d895b00 of size 256 next 175\n",
      "2022-07-25 15:29:32.204215: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef38d895c00 of size 256 next 176\n",
      "2022-07-25 15:29:32.204229: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef38d895d00 of size 54190080 next 177\n",
      "2022-07-25 15:29:32.204244: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef390c43d00 of size 1059803136 next 171\n",
      "2022-07-25 15:29:32.204259: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef3cfef8d00 of size 1059803136 next 182\n",
      "2022-07-25 15:29:32.204270: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef40f1add00 of size 1017349632 next 184\n",
      "2022-07-25 15:29:32.204283: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7ef44bbe6300 of size 1850112000 next 185\n",
      "2022-07-25 15:29:32.204294: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef4ba04db00 of size 1850112000 next 186\n",
      "2022-07-25 15:29:32.204308: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef5284b5300 of size 1759961088 next 187\n",
      "2022-07-25 15:29:32.204323: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7ef591323300 of size 3167797248 next 188\n",
      "2022-07-25 15:29:32.204338: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7ef64e02f300 of size 1033440512 next 18446744073709551615\n",
      "2022-07-25 15:29:32.204348: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
      "2022-07-25 15:29:32.204363: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 60 Chunks of size 256 totalling 15.0KiB\n",
      "2022-07-25 15:29:32.204378: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 7 Chunks of size 512 totalling 3.5KiB\n",
      "2022-07-25 15:29:32.204393: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 12 Chunks of size 1024 totalling 12.0KiB\n",
      "2022-07-25 15:29:32.204408: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-07-25 15:29:32.204423: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 24 Chunks of size 2048 totalling 48.0KiB\n",
      "2022-07-25 15:29:32.204438: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 10 Chunks of size 16384 totalling 160.0KiB\n",
      "2022-07-25 15:29:32.204453: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 6 Chunks of size 20736 totalling 121.5KiB\n",
      "2022-07-25 15:29:32.204468: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 27392 totalling 26.8KiB\n",
      "2022-07-25 15:29:32.204480: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 30720 totalling 30.0KiB\n",
      "2022-07-25 15:29:32.204492: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 4 Chunks of size 884736 totalling 3.38MiB\n",
      "2022-07-25 15:29:32.204506: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1728768 totalling 1.65MiB\n",
      "2022-07-25 15:29:32.204521: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1731328 totalling 1.65MiB\n",
      "2022-07-25 15:29:32.204532: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 3538944 totalling 6.75MiB\n",
      "2022-07-25 15:29:32.204547: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 6128640 totalling 11.69MiB\n",
      "2022-07-25 15:29:32.204562: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 7077376 totalling 13.50MiB\n",
      "2022-07-25 15:29:32.204577: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 4 Chunks of size 7077888 totalling 27.00MiB\n",
      "2022-07-25 15:29:32.204592: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 8388608 totalling 16.00MiB\n",
      "2022-07-25 15:29:32.204607: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 9699328 totalling 18.50MiB\n",
      "2022-07-25 15:29:32.204622: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 11534336 totalling 22.00MiB\n",
      "2022-07-25 15:29:32.204637: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 14154752 totalling 27.00MiB\n",
      "2022-07-25 15:29:32.204649: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 6 Chunks of size 14155776 totalling 81.00MiB\n",
      "2022-07-25 15:29:32.204664: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 16 Chunks of size 28311552 totalling 432.00MiB\n",
      "2022-07-25 15:29:32.204676: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 35124224 totalling 66.99MiB\n",
      "2022-07-25 15:29:32.204691: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 54190080 totalling 51.68MiB\n",
      "2022-07-25 15:29:32.204706: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 6 Chunks of size 67108864 totalling 384.00MiB\n",
      "2022-07-25 15:29:32.204721: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1017349632 totalling 970.22MiB\n",
      "2022-07-25 15:29:32.204736: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 1059803136 totalling 1.97GiB\n",
      "2022-07-25 15:29:32.204750: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1314109440 totalling 1.22GiB\n",
      "2022-07-25 15:29:32.204762: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1759961088 totalling 1.64GiB\n",
      "2022-07-25 15:29:32.204776: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1850112000 totalling 1.72GiB\n",
      "2022-07-25 15:29:32.204791: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 3167797248 totalling 2.95GiB\n",
      "2022-07-25 15:29:32.204807: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 11.59GiB\n",
      "2022-07-25 15:29:32.204821: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 15361376256 memory_limit_: 15361376256 available bytes: 0 curr_region_allocation_bytes_: 30722752512\n",
      "2022-07-25 15:29:32.204842: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
      "Limit:                     15361376256\n",
      "InUse:                     12450729472\n",
      "MaxInUse:                  14343453696\n",
      "NumAllocs:                         356\n",
      "MaxAllocSize:               3296526336\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-07-25 15:29:32.204870: W tensorflow/core/common_runtime/bfc_allocator.cc:474] **************************************___________*********************************************______\n",
      "2022-07-25 15:29:32.204927: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops_3d.cc:186 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[3,256,20,214,215] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/conv3d_11/Conv3D' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 707, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 502, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 491, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 398, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 722, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 389, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_16441/3605177120.py\", line 34, in <cell line: 34>\n      history = c3d_model.fit(train_tf,\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_1/conv3d_11/Conv3D'\nOOM when allocating tensor with shape[3,256,20,214,215] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/conv3d_11/Conv3D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2839]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m c3d_model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel(inputs, output)\n\u001b[1;32m     31\u001b[0m c3d_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 34\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mc3d_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# history = c3d_model.fit(train_videos, \u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#                         train_labels,\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#                         validation_split = 0.2,\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#                         epochs = 16,\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#                         verbose= 1)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone training.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/conv3d_11/Conv3D' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 707, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 502, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 491, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 398, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 722, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 389, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_16441/3605177120.py\", line 34, in <cell line: 34>\n      history = c3d_model.fit(train_tf,\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_1/conv3d_11/Conv3D'\nOOM when allocating tensor with shape[3,256,20,214,215] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/conv3d_11/Conv3D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2839]"
     ]
    }
   ],
   "source": [
    "#creating C3D Model\n",
    "\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# with strategy.scope():\n",
    "inputs = keras.Input(shape=(30, 224, 224, 3)) #full shape w/ batch dim = (None, 30, 224, 224, 3) \n",
    "\n",
    "x = Conv3D(64, kernel_size=(3,3,3), strides=(1,1,1))(inputs)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 1), strides=(1,1,1))(x)\n",
    "\n",
    "x = Conv3D(128, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2), strides=(1,1,1))(x)\n",
    "\n",
    "x = Conv3D(256, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = Conv3D(256, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2), strides=(1,1,1))(x)\n",
    "\n",
    "x = Conv3D(512, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = Conv3D(512, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2), strides=(1,1,1))(x)\n",
    "\n",
    "x = Conv3D(512, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = Conv3D(512, kernel_size=(3,3,3), strides=(1,1,1))(x)\n",
    "x = MaxPooling3D(pool_size=(2, 2, 2), strides=(1,1,1))(x)\n",
    "\n",
    "x = Dense(4096, activation=\"relu\")(x)\n",
    "output = Dense(4096, activation=\"softmax\")(x)\n",
    "\n",
    "c3d_model = keras.Model(inputs, output)\n",
    "\n",
    "c3d_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "history = c3d_model.fit(train_tf,\n",
    "                        epochs = 16,\n",
    "                        verbose= 1)\n",
    "\n",
    "# history = c3d_model.fit(train_videos, \n",
    "#                         train_labels,\n",
    "#                         validation_split = 0.2,\n",
    "#                         epochs = 16,\n",
    "#                         verbose= 1)\n",
    "\n",
    "print('Done training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29235c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
